{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from scipy.stats import entropy, kurtosis\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# !pip install pyod\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('max_columns', None)\n",
    "# pd.set_option('max_rows', None)\n",
    "pd.set_option('float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x           y  z          t   terror        q  flag  event_id  \\\n",
      "0 -142.500000 -147.500000  0 767.879000 2.029660 1.050520     0         7   \n",
      "\n",
      "   hit_id  \n",
      "0       1  \n",
      "(9473201, 9)\n",
      "   event_id  nhit  nhitreal     energymc   thetamc     phimc       xcmc  \\\n",
      "0         7   426        70 48348.900000 63.168600 11.098200 -40.830000   \n",
      "\n",
      "        ycmc  \n",
      "0 114.030000  \n",
      "(13315, 8)\n",
      "            x           y  z          t   terror        q  event_id  hit_id\n",
      "0 -142.500000 -127.500000  0 848.061000 1.998400 1.150670         9       1\n",
      "(4086511, 8)\n"
     ]
    }
   ],
   "source": [
    "pathf = os.path.join(\"..\", \"data\", \"particles\")\n",
    "\n",
    "trainpd = pd.read_csv(os.path.join(pathf, \"train.csv\"))\n",
    "print(trainpd.head(1))\n",
    "trainshape = trainpd.shape\n",
    "print(trainshape)\n",
    "eventpd = pd.read_csv(os.path.join(pathf, \"event.csv\"))\n",
    "print(eventpd.head(1))\n",
    "print(eventpd.shape)\n",
    "testpd = pd.read_csv(os.path.join(pathf, \"test.csv\"))\n",
    "testshape = testpd.shape\n",
    "print(testpd.head(1))\n",
    "print(testpd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (k(q,mc)*(t0+L))^2 + dis^2 -dis*cos(phi)*sin(thmc)*(t0+L) = (t+L)^2\n",
    "# t0 方程 \n",
    "# a = k(q,mc)^2\n",
    "# b = 2*L*k(q,mc)^2 -dis*cos(phi)*sin(thmc)\n",
    "# c = L^2 * k(q,mc)^2 + dis^2 - dis*cos(phi)*sin(thmc)*L - (t+L)^2 \n",
    "# t0 = (-b +- (b^2 - 4*a*c)^(1/2))/2*a\n",
    "data = pd.concat([trainpd, testpd], ignore_index=True)\n",
    "data = pd.merge(data, eventpd, on='event_id', how='left')\n",
    "\n",
    "data['fx'] = data['x'] - data['xcmc']\n",
    "data['fy'] = data['y'] - data['ycmc']\n",
    "data['phimc'] = data['phimc'] * np.pi / 180.\n",
    "data['fphi'] = np.arctan2(data['fy'], data['fx']) - data['phimc']\n",
    "data['fdis'] = np.sqrt(data['fx'] ** 2 + data['fy'] ** 2)\n",
    "data['thetamc'] = data['thetamc'] * np.pi / 180.\n",
    "\n",
    "data['fsinthmc'] = np.sin(data['thetamc'])\n",
    "data['fsinthmc_v'] = 1.0/data['fsinthmc']\n",
    "data['fcosphi'] = np.cos(data['fphi'])\n",
    "data['fcosphi_v'] = 1.0/data['fcosphi']\n",
    "\n",
    "data['fcosthmc'] = np.cos(data['thetamc'])\n",
    "data['fcosthmc_v'] = 1.0/data['fcosthmc']\n",
    "data['fsinphi'] = np.sin(data['fphi'])\n",
    "data['fsinphi_v'] = 1.0/data['fsinphi']\n",
    "\n",
    "data['ftanphi'] = np.tan(data['fphi'])\n",
    "data['ftanphi_v'] = 1.0/data['ftanphi']\n",
    "data['ftanthmc'] = np.tan(data['thetamc'])\n",
    "data['ftanthmc_v'] = 1.0/data['ftanthmc']\n",
    "\n",
    "\n",
    "# data['ft2'] = data['t'] ** 2\n",
    "# data['fdis2'] = data['fdis'] ** 2\n",
    "\n",
    "data['fttrue'] = data['t'] / data['terror']\n",
    "data['terror_v'] = 1.0 / data['terror']\n",
    "data['terror_v2'] =data['terror_v'] ** 2 \n",
    "data['fttrue_v'] = 1.0 / data['fttrue']\n",
    "data['fttrue2'] = data['fttrue'] ** 2\n",
    "data['fttrue2_v'] = 1.0 / data['fttrue2'] \n",
    "data['nhitratio'] = data['nhit'] / data['nhitreal']\n",
    "data['nhitratio_v'] = data['nhitratio']\n",
    "data['energymc_v'] = 1.0 / data['energymc']\n",
    "data['fenergymc2'] = data['energymc'] ** 2\n",
    "data['fenergymc2_v'] = 1.0 / data['fenergymc2'] \n",
    "# data['q_v'] = 1.0 / data['q']\n",
    "data['q2'] = data['q']\n",
    "# data['q2_v'] = 1.0 / data['q2']\n",
    "\n",
    "del data['fx']\n",
    "del data['fy']\n",
    "del data['x']\n",
    "del data['y']\n",
    "del data['z']\n",
    "del data['xcmc']\n",
    "del data['ycmc']\n",
    "del data['fphi']\n",
    "del data['phimc']\n",
    "del data['nhitreal']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_new = pd.DataFrame()\n",
    "info_new[\"event_id\"] = data.groupby([\"event_id\"])[\"event_id\"].mean()\n",
    "info_new[\"fdis_mean\"] = data.groupby([\"event_id\"])[\"fdis\"].mean()\n",
    "info_new[\"fdis_std\"] = data.groupby([\"event_id\"])[\"fdis\"].std()\n",
    "info_new[\"fdis_stdmean\"] = info_new[\"fdis_std\"] / info_new[\"fdis_mean\"]\n",
    "info_new[\"ft_min\"] = data.groupby([\"event_id\"])[\"t\"].min()\n",
    "info_new[\"ft_max\"] = data.groupby([\"event_id\"])[\"t\"].max()\n",
    "info_new[\"t_mean\"] = data.groupby([\"event_id\"])[\"t\"].mean()\n",
    "info_new[\"ft_std\"] = data.groupby([\"event_id\"])[\"t\"].std()\n",
    "info_new[\"ft_stdmean\"] = info_new[\"ft_std\"] / info_new[\"t_mean\"]\n",
    "info_new[\"ft_mean\"] = (info_new['t_mean']-info_new['ft_min']) / (info_new['ft_max']-info_new['ft_min'])\n",
    "info_new.reset_index(drop=True, inplace=True)\n",
    "data = pd.merge(data, info_new, on='event_id', how='left')\n",
    "\n",
    "# data['ft_rel'] = (data['t']-data['ft_min']) / (data['ft_max']-data['ft_min'])\n",
    "data['ft_rel'] = data['t'] / data['ft_std']\n",
    "# data['ft_rel_std'] = data['ft_rel'] / data['ft_std']\n",
    "data['ft2_rel'] = data['ft_rel'] ** 2\n",
    "# data['ft2_rel_std'] = data['ft_rel_std'] ** 2\n",
    "data['ft_rel_v'] = 1.0 / data['ft_rel']\n",
    "data['ft2_rel_v'] = 1.0 / data['ft2_rel'] \n",
    "# (k(q,mc)*(t0+L))^2 + dis^2 -dis*cos(phi)*sin(thmc)*(t0+L) = (t+L)^2\n",
    "data = data.sort_values(by=['event_id', 'ft_rel']).reset_index(drop=True)\n",
    "# for i in [4, 6, 8, 10, 12]:\n",
    "for i in [7, 8, 11,17, 47]:\n",
    "    data[f'ft_{i}diff'] = data.groupby('event_id')['ft_rel'].diff(periods=i).fillna(0)\n",
    "    \n",
    "data['fdis_rel'] = data['fdis'] / data['fdis_mean']\n",
    "data['fdis_rel_std'] = data['fdis_rel'] / data['fdis_std']\n",
    "data['fdis2_rel'] = data['fdis_rel'] ** 2\n",
    "data['fdis2_rel_std'] = data['fdis_rel_std'] ** 2\n",
    "\n",
    "data['fdis_t_rel'] = data['fdis_rel'] / data['ft_rel']\n",
    "data['fdis_tmean_rel'] = data['fdis_rel'] / data['ft_mean']\n",
    "data['fdis_t_rel'].fillna(0, inplace=True)\n",
    "# data['fdis-t_rel'] = data['fdis_rel'] * data['ft_rel']\n",
    "# data['fdis-tmean_rel'] = data['fdis_rel'] * data['ft_mean']\n",
    "# data['fdis_t_normal'] = data['fdis_rel'] / data['ft_normal']\n",
    "# data['fdis_t_normal'].fillna(0, inplace=True)\n",
    "# data['fdis-t_normal'] = data['fdis_rel'] * data['ft_normal']\n",
    "\n",
    "# data = data.sort_values(by=['event_id', 'fdis_rel']).reset_index(drop=True)\n",
    "# for i in [5, 6, 7, 8, 10, 11,12]:\n",
    "#     data[f'fdis_rel_{i}diff'] = data.groupby('event_id')['fdis_rel'].diff(periods=i).fillna(0)\n",
    "data['fx_normal'] = data['fcosphi'] * data['fdis_rel']\n",
    "# data['fy_normal'] = data['fsinphi'] * data['fdis_rel']\n",
    "\n",
    "data['fcossin'] = data['fcosphi'] * data['fsinthmc']\n",
    "data['fdis_relcossin'] =  data['fdis_rel'] * data['fcossin']\n",
    "data['fdis2_relcossin'] = data['fdis2_rel'] * data['fcossin']\n",
    "# data['fdis2_rel_stdcossin'] = data['fdis2_rel_std'] * data['fcossin']\n",
    "data['ft2_relcossin'] = data['ft2_rel'] * data['fcossin']\n",
    "\n",
    "data['fsincos'] = data['fsinphi'] * data['fcosthmc']\n",
    "# data['fdis_relsincos'] = data['fdis_rel'] * data['fsincos']\n",
    "# data['fdis2_relsincos'] = data['fdis2_rel'] * data['fsincos']\n",
    "# data['fdis2_rel_stdsincos'] = data['fdis2_rel_std'] * data['fsincos']\n",
    "# data['ft_relsincos'] =  data['ft_rel'] * data['fsincos']\n",
    "# data['ft2_relsincos'] = data['ft2_rel'] * data['fsincos']\n",
    "\n",
    "data['fsinsin'] = data['fsinphi'] * data['fsinthmc']\n",
    "# data['fdis_relsinsin'] =  data['fdis_rel'] * data['fsinsin']\n",
    "# data['fdis2_relsinsin'] = data['fdis2_rel'] * data['fsinsin']\n",
    "# data['fdis2_rel_stdsinsin'] = data['fdis2_rel_std'] * data['fsinsin']\n",
    "# data['ft_relsinsin'] =  data['ft_rel'] * data['fsinsin']\n",
    "# data['ft2_relsinsin'] = data['ft2_rel'] * data['fsinsin']\n",
    "\n",
    "data['fcoscos'] = data['fcosphi'] * data['fcosthmc']\n",
    "\n",
    "data['ft_relsinsin'] = data['ft_rel'] * data['fsinsin']\n",
    "data['ft_relcoscos'] = data['ft_rel'] * data['fcoscos']\n",
    "data['ft_relsincos'] = data['ft_rel'] * data['fsincos']\n",
    "data['ft_relcossin'] = data['ft_rel'] * data['fcossin']\n",
    "\n",
    "data['ft_rel_errcoscos'] = data['ft_relcoscos'] * data['terror']\n",
    "data['fdis2_rel_stdcoscos'] = data['fdis2_rel_std'] * data['fcoscos']\n",
    "data['ft2_relcoscos'] = data['ft2_rel'] * data['fcoscos']\n",
    "\n",
    "data['fdis_t_relcossin'] = data['fdis_relcossin'] / data['ft_rel']\n",
    "data['fdis_t_relcossin'].fillna(0, inplace=True)\n",
    "data['fdis-t_relcossin'] = data['fdis_relcossin'] * data['ft_rel']\n",
    "\n",
    "# # 要保留\n",
    "# del data['ft_7diff']\n",
    "# del data['ft_8diff']\n",
    "# del data['ft_11diff']\n",
    "# del data['ft_17diff']\n",
    "# del data['fdis_t_rel']\n",
    "# del data['fttrue2']\n",
    "# del data['ft_rel_errcoscos']\n",
    "# del data['fdis_t_relcossin']\n",
    "# del data['fdis-t_relcossin']\n",
    "# del data['q2']\n",
    "# del data['q']\n",
    "# del data['ft_47diff']\n",
    "# del data['ft2_rel_v']\n",
    "# del data['fttrue2_v']\n",
    "# del data['fttrue_v']\n",
    "# del data['fsinthmc_v']\n",
    "# del data['ft_rel']\n",
    "\n",
    "del data['t']\n",
    "del data['ft_relcossin']\n",
    "del data['ft2_rel']\n",
    "del data['ft_relcoscos']\n",
    "del data['ft_rel_v']\n",
    "del data['fcosphi_v']\n",
    "del data['ft2_relcossin']\n",
    "del data['ft2_relcoscos']\n",
    "del data['ftanphi']\n",
    "del data['ft_relsincos']\n",
    "del data['ft_relsinsin']\n",
    "del data['fttrue']\n",
    "del data['ftanphi_v']\n",
    "del data['fsinphi_v']\n",
    "\n",
    "# 要保留但不明显\n",
    "del data['fdis']\n",
    "del data['fdis2_rel']\n",
    "del data['fdis_tmean_rel']\n",
    "del data['terror_v2']\n",
    "del data['nhitratio']\n",
    "del data['fdis2_relcossin']\n",
    "del data['fdis2_rel_stdcoscos']\n",
    "del data['ftanthmc']\n",
    "del data['energymc_v']\n",
    "del data['nhitratio_v']\n",
    "del data['fdis_rel_std']\n",
    "del data['fenergymc2']\n",
    "del data['fdis2_rel_std']\n",
    "del data['fdis_stdmean']\n",
    "\n",
    "# 真删除\n",
    "del data['fx_normal']\n",
    "del data['fcossin']\n",
    "del data['fdis_relcossin']\n",
    "del data['terror_v']\n",
    "del data['ft_std']\n",
    "del data['fdis_rel']\n",
    "del data['ftanthmc_v']\n",
    "del data['fenergymc2_v']\n",
    "del data['fcoscos']\n",
    "del data['fcosthmc_v']\n",
    "del data['fdis_mean']\n",
    "del data['ft_mean']\n",
    "del data['nhit']\n",
    "del data['fdis_std']\n",
    "del data['t_mean']\n",
    "del data['energymc']\n",
    "del data['terror']\n",
    "del data['ft_stdmean']\n",
    "del data['ft_min']\n",
    "del data['ft_max']\n",
    "del data['fcosphi']\n",
    "del data['thetamc']\n",
    "del data['fsinthmc']\n",
    "del data['fcosthmc']\n",
    "del data['fsincos']\n",
    "del data['fsinsin']\n",
    "del data['fsinphi']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9473201\n",
      "(13559712, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainshape[0])\n",
    "print(data.shape)\n",
    "testpd = data[data.flag.isna()].reset_index()\n",
    "# data.loc[data.flag.isna() & (data.t < -900), 'flag'] = 0\n",
    "# data.loc[data.flag.isna() & ((data.t > 1850) | (data.q < 0)), 'flag'] = 1\n",
    "trainpd = data[data.flag.notna()].reset_index()\n",
    "trainpd['flag'] = trainpd['flag'].astype('int')\n",
    "# trainpd = data[:trainshape[0]].reset_index()\n",
    "# testpd = data[trainshape[0]:].reset_index()\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'q', 'flag', 'event_id', 'hit_id', 'fsinthmc_v', 'fttrue_v',\n",
      "       'fttrue2', 'fttrue2_v', 'q2', 'ft_rel', 'ft2_rel_v', 'ft_7diff',\n",
      "       'ft_8diff', 'ft_11diff', 'ft_17diff', 'ft_47diff', 'fdis_t_rel',\n",
      "       'ft_rel_errcoscos', 'fdis_t_relcossin', 'fdis-t_relcossin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trainpd.columns)\n",
    "# feature = [x for x in trainpd.columns if x not in ['flag', 'index', 'hit_id', 'event_id']]\n",
    "feature = [x for x in trainpd.columns if x not in ['flag', 'index', 'event_id']]\n",
    "labels = trainpd[['flag']]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "trainpd[feature] = scaler.fit_transform(trainpd[feature])\n",
    "\n",
    "del trainpd['flag']\n",
    "del testpd['flag']\n",
    "\n",
    "X = np.concatenate((trainpd,labels),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "outliers_fraction = 0.05\n",
    "# Define seven outlier detection tools to be compared\n",
    "classifiers = {\n",
    "        'Angle-based Outlier Detector (ABOD)': ABOD(contamination=outliers_fraction),\n",
    "        'Cluster-based Local Outlier Factor (CBLOF)':CBLOF(contamination=outliers_fraction,check_estimator=False, random_state=random_state),\n",
    "        'Feature Bagging':FeatureBagging(LOF(n_neighbors=35),contamination=outliers_fraction,check_estimator=False,random_state=random_state),\n",
    "        'Histogram-base Outlier Detection (HBOS)': HBOS(contamination=outliers_fraction),\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Average KNN': KNN(method='mean',contamination=outliers_fraction)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle-based Outlier Detector (ABOD)\n"
     ]
    }
   ],
   "source": [
    "dfx = pd.DataFrame()\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    start_time = time.time()\n",
    "    print(clf_name)\n",
    "    clf.fit(X)\n",
    "    # predict raw anomaly score\n",
    "    scores_pred = clf.decision_function(X) * -1\n",
    "        \n",
    "    # prediction of a datapoint category outlier or inlier\n",
    "    y_pred = clf.predict(X)\n",
    "    used_time = (time.time() - start_time) / 3600\n",
    "    print(f'used_time: {used_time:.2f} hours')\n",
    "#     n_inliers = len(y_pred) - np.count_nonzero(y_pred)\n",
    "#     n_outliers = np.count_nonzero(y_pred == 1)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # copy of dataframe\n",
    "    dfx[clf_name] = y_pred\n",
    "    \n",
    "    # IX1 - inlier feature 1,  IX2 - inlier feature 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#阈值大概在0.2-0.4之间 本题对召回率较敏感，可适当降低一下阈值\n",
    "thre = 0.25\n",
    "\n",
    "#生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['hit_id'] = testpd['hit_id']\n",
    "sub['flag_pred'] = fy_submission\n",
    "sub['event_id'] = testpd['event_id']\n",
    "sub['flag_pred'] = sub['flag_pred'].apply(lambda x: 1 if x >= thre else 0)\n",
    "sub.to_csv(os.path.join(pathf, \"subsample.csv\").format(sub['flag_pred'].mean()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.plot(x='fcosphi_v', y='flag', kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
