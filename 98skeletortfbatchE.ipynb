{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from scipy.stats import entropy, kurtosis\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x      y  z        t   terror        q  flag  event_id  hit_id\n",
      "0 -142.5 -147.5  0  767.879  2.02966  1.05052     0         7       1\n",
      "(9473201, 9)\n",
      "   event_id  nhit  nhitreal  energymc  thetamc    phimc   xcmc    ycmc\n",
      "0         7   426        70   48348.9  63.1686  11.0982 -40.83  114.03\n",
      "(13315, 8)\n",
      "       x      y  z        t  terror        q  event_id  hit_id\n",
      "0 -142.5 -127.5  0  848.061  1.9984  1.15067         9       1\n",
      "(4086511, 8)\n"
     ]
    }
   ],
   "source": [
    "pathf = os.path.join(\"..\", \"data\", \"particles\")\n",
    "model_path = os.path.join(pathf, \"model\")\n",
    "log_path = os.path.join(pathf, \"model\")\n",
    "trainpd = pd.read_csv(os.path.join(pathf, \"train.csv\"))\n",
    "print(trainpd.head(1))\n",
    "trainshape = trainpd.shape\n",
    "print(trainshape)\n",
    "eventpd = pd.read_csv(os.path.join(pathf, \"event.csv\"))\n",
    "print(eventpd.head(1))\n",
    "print(eventpd.shape)\n",
    "testpd = pd.read_csv(os.path.join(pathf, \"test.csv\"))\n",
    "testshape = testpd.shape\n",
    "print(testpd.head(1))\n",
    "print(testpd.shape)\n",
    "\n",
    "data = pd.concat([trainpd, testpd], ignore_index=True)\n",
    "data = pd.merge(data, eventpd, on='event_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#组合特征 \n",
    "data['fx'] = data['x'] - data['xcmc']\n",
    "data['fy'] = data['y'] - data['ycmc']\n",
    "data['fdis'] = np.sqrt(data['fx'] ** 2 + data['fy'] ** 2)\n",
    "# data['fscala'] = np.sin(data['thetamc']) * data['t']\n",
    "data['fsinth'] = np.sin(data['thetamc'] * np.pi / 180.)\n",
    "data['fcosth'] = np.cos(data['thetamc'] * np.pi / 180.)\n",
    "data['fphi'] = np.arctan2(data['fy'], data['fx'])\n",
    "data['fsinphi'] = np.sin(data['fphi'] * np.pi / 180.)\n",
    "data['fcosphi'] = np.cos(data['fphi'] * np.pi / 180.)\n",
    "data['fttrue'] = data['t'] / data['terror']\n",
    "data['nhitratio'] = data['nhit'] / data['nhitreal']\n",
    "\n",
    "# del data['fx']\n",
    "# del data['fy']\n",
    "del data['x']\n",
    "del data['y']\n",
    "del data['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_new = pd.DataFrame()\n",
    "info_new[\"event_id\"] = data.groupby([\"event_id\"])[\"event_id\"].mean()\n",
    "info_new[\"fdis_stdmean\"] = data.groupby([\"event_id\"])[\"fdis\"].std() / data.groupby([\"event_id\"])[\"fdis\"].mean()\n",
    "info_new.reset_index(drop=True, inplace=True)\n",
    "data = pd.merge(data, info_new, on='event_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpd = data[:trainshape[0]].reset_index()\n",
    "testpd = data[trainshape[0]:].reset_index()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'event_id', 'flag', 'hit_id', 'q', 't', 'terror', 'nhit',\n",
      "       'nhitreal', 'energymc', 'thetamc', 'phimc', 'xcmc', 'ycmc', 'fx', 'fy',\n",
      "       'fdis', 'fsinth', 'fcosth', 'fphi', 'fsinphi', 'fcosphi', 'fttrue',\n",
      "       'nhitratio', 'fdis_stdmean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trainpd.columns)\n",
    "feature = [x for x in trainpd.columns if x not in ['flag', 'index', 'hit_id', 'event_id']]\n",
    "labels = trainpd['flag']\n",
    "del trainpd['flag']\n",
    "del testpd['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModeltensor(object):\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config\n",
    "\n",
    "    # You need to override this method.\n",
    "    def buildModel(self):\n",
    "        raise NotImplementedError(\"You need to implement your own model.\")\n",
    "\n",
    "\n",
    "class NeurousNet(AbstractModeltensor):\n",
    "    def __init__(self, xlenth, config=None):\n",
    "        super(NeurousNet, self).__init__(config)\n",
    "        self.graph = tf.Graph()  # 为每个类(实例)单独创建一个graph\n",
    "        self.modeldic = {\n",
    "            \"cnn_dense_less\": self._cnn_dense_less_model,\n",
    "            \"nomul_model\": self._nomul_model,\n",
    "        }\n",
    "        self.ydim = 1\n",
    "        self.keep_prob_ph = config[\"dropout\"]\n",
    "        self.input_dim = xlenth\n",
    "        self.out_dim = 1\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('Inputs'):\n",
    "                self.input_p = tf.placeholder(tf.float32, [None, self.input_dim])\n",
    "                self.learn_rate_p = tf.placeholder(dtype=tf.float32, shape=[], name=\"lr\")\n",
    "                self.lr_decay = tf.placeholder(dtype=tf.float32, shape=[])\n",
    "            with tf.name_scope('Outputs'):\n",
    "                self.target_y = tf.placeholder(dtype=tf.float32, shape=[None, self.out_dim])\n",
    "\n",
    "    def buildModel(self):\n",
    "        tf.reset_default_graph()\n",
    "        with self.graph.as_default():\n",
    "            # 不同选择加载\n",
    "            self.modeldic[self.config[\"modelname\"]]()\n",
    "            # 打印打包\n",
    "            self.merged = tf.summary.merge_all()\n",
    "            # 损失目标\n",
    "            tvars = tf.trainable_variables()  # 返回需要训练的variable\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.train_list, tvars), 2)\n",
    "            grads_and_vars = tuple(zip(grads, tvars))\n",
    "            self.train_op = tf.train.AdamOptimizer(self.learn_rate_p).apply_gradients(grads_and_vars)\n",
    "            #             self.train_op = []\n",
    "            #             for i2 in self.train_list:\n",
    "            #                 self.train_op.append(tf.train.AdamOptimizer(self.learn_rate_p).minimize(i2))\n",
    "            # 同一保存加载\n",
    "            self.saver = tf.train.Saver(tf.global_variables())\n",
    "            # [print(n.name) for n in tf.get_default_graph().as_graph_def().node]\n",
    "            # return self.saver\n",
    "\n",
    "    def _cnn_dense_less_model(self):\n",
    "        with self.graph.as_default():\n",
    "            # 部分1，预测值\n",
    "            dense1 = tf.layers.dense(inputs=self.input_p, units=self.input_dim, activation=tf.nn.softmax,\n",
    "                                     name=\"layer_dense1\")\n",
    "            tf.summary.histogram('dense1', dense1)  # 记录标量的变化\n",
    "            mult_layer1 = tf.nn.softmax(dense1 * self.input_p, name='mult_layer1')\n",
    "            mult_layer2 = tf.nn.softmax(mult_layer1 * self.input_p, name='mult_layer2')\n",
    "            concat1 = tf.concat([self.input_p, dense1, mult_layer1, mult_layer2], 1, name='concat1')\n",
    "            tf.summary.histogram('concat1', concat1)  # 记录标量的变化\n",
    "            denseo1 = tf.nn.dropout(concat1, keep_prob=self.keep_prob_ph)\n",
    "            denseo2 = tf.layers.dense(inputs=denseo1, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense2\")\n",
    "            denseo3 = tf.layers.dense(inputs=denseo2, units=self.input_dim // 4, activation=tf.nn.elu,\n",
    "                                      name=\"layer_dense3\")\n",
    "            y_res_t = tf.layers.dense(inputs=denseo3, units=self.out_dim, activation=None)\n",
    "            y_res_v = tf.nn.sigmoid(y_res_t, name=\"y_res_v\")\n",
    "            tf.summary.histogram('y_res_v', y_res_v)  # 记录标量的变化\n",
    "            # 损失返回值\n",
    "            y_los = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_res_t, labels=self.target_y, name=\"y_los\")\n",
    "            y_loss_t = tf.reduce_mean(y_los, name=\"y_loss_t\")\n",
    "            y_loss_v = tf.add(y_loss_t, 0, name=\"y_loss_v\")\n",
    "\n",
    "            one = tf.ones_like(y_res_t)\n",
    "            zero = tf.zeros_like(y_res_t)\n",
    "            label_bool = tf.where(y_res_t < 0.5, x=zero, y=one)\n",
    "            self.auc_value, self.auc_op = tf.metrics.auc(self.target_y, label_bool, num_thresholds=4000)\n",
    "            # 猜错的获取 实际盈利值的负数\n",
    "            self.train_list = [y_loss_t]\n",
    "            self.valid_list = [y_loss_v]\n",
    "            self.pred_list = [y_res_v]\n",
    "            # 打印信息\n",
    "            tf.summary.scalar('y_loss_t', y_loss_t)  # 记录标量的变化\n",
    "            tf.summary.scalar('y_loss_v', y_loss_v)  # 记录标量的变化\n",
    "            tf.summary.histogram('mult_layer1', mult_layer1)  # 记录标量的变化\n",
    "            tf.summary.histogram('mult_layer2', mult_layer2)  # 记录标量的变化\n",
    "\n",
    "            tf.summary.scalar('lr', self.learn_rate_p)  # 记录标量的变化\n",
    "            return None\n",
    "\n",
    "    def _nomul_model(self):\n",
    "        with self.graph.as_default():\n",
    "            # 部分1，预测值\n",
    "            dense1 = tf.layers.dense(inputs=self.input_p, units=self.input_dim, activation=tf.nn.softmax,\n",
    "                                     name=\"layer_dense1\")\n",
    "            tf.summary.histogram('dense1', dense1)  # 记录标量的变化\n",
    "            dense2 = tf.layers.dense(inputs=dense1, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense2\")\n",
    "            dense3 = tf.layers.dense(inputs=dense2, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense3\")\n",
    "            dense4 = tf.layers.dense(inputs=dense3, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense4\")\n",
    "            dense5 = tf.layers.dense(inputs=dense4, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense5\")\n",
    "            dense6 = tf.layers.dense(inputs=dense5, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense6\")\n",
    "            dense7 = tf.layers.dense(inputs=dense6, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense7\")\n",
    "            dense8 = tf.layers.dense(inputs=dense7, units=self.input_dim, activation=tf.nn.elu, name=\"layer_dense8\")\n",
    "            concat1 = tf.concat([self.input_p, dense1, dense2, dense3, dense4, dense5, dense6, dense7, dense8], 1,\n",
    "                                name='concat1')\n",
    "            tf.summary.histogram('concat1', concat1)  # 记录标量的变化\n",
    "            denseo1 = tf.nn.dropout(concat1, keep_prob=self.keep_prob_ph)\n",
    "            denseo2 = tf.layers.dense(inputs=denseo1, units=self.input_dim * 4, activation=tf.nn.elu,\n",
    "                                      name=\"layer_denseo2\")\n",
    "            denseo3 = tf.layers.dense(inputs=denseo2, units=self.input_dim, activation=tf.nn.elu,\n",
    "                                      name=\"layer_denseo3\")\n",
    "            denseo4 = tf.layers.dense(inputs=denseo3, units=self.input_dim // 4, activation=tf.nn.elu,\n",
    "                                      name=\"layer_denseo4\")\n",
    "            y_res_t = tf.layers.dense(inputs=denseo4, units=self.out_dim, activation=None)\n",
    "            y_res_v = tf.nn.sigmoid(y_res_t, name=\"y_res_v\")\n",
    "            tf.summary.histogram('y_res_v', y_res_v)  # 记录标量的变化\n",
    "            # 损失返回值\n",
    "            y_los = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_res_t, labels=self.target_y, name=\"y_los\")\n",
    "            y_loss_t = tf.reduce_mean(y_los, name=\"y_loss_t\")\n",
    "            y_loss_v = tf.add(y_loss_t, 0, name=\"y_loss_v\")\n",
    "\n",
    "            one = tf.ones_like(y_res_t)\n",
    "            zero = tf.zeros_like(y_res_t)\n",
    "            label_bool = tf.where(y_res_t < 0.5, x=zero, y=one)\n",
    "            self.auc_value, self.auc_op = tf.metrics.auc(self.target_y, label_bool, num_thresholds=4000)\n",
    "            # 猜错的获取 实际盈利值的负数\n",
    "            self.train_list = [y_loss_t]\n",
    "            self.valid_list = [y_loss_v]\n",
    "            self.pred_list = [y_res_v]\n",
    "            # 打印信息\n",
    "            tf.summary.scalar('y_loss_t', y_loss_t)  # 记录标量的变化\n",
    "            tf.summary.scalar('y_loss_v', y_loss_v)  # 记录标量的变化\n",
    "\n",
    "            tf.summary.scalar('lr', self.learn_rate_p)  # 记录标量的变化\n",
    "            return None\n",
    "\n",
    "    def batch_train(self, trainpd, labels, batch_size=8, num_epochs=1, retrain=True):\n",
    "        # 设置\n",
    "        sess = tf.Session(graph=self.graph)\n",
    "        with sess.as_default():\n",
    "            with self.graph.as_default():\n",
    "                if self.config[\"retrain\"] == 1:\n",
    "                    model_dir = os.path.join(model_path, \"modelevery_%s\" % self.config[\"tailname\"])\n",
    "                    latest_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "                    if os.path.isfile(\"{}.index\".format(latest_ckpt)):\n",
    "                        self.saver.restore(sess, latest_ckpt)\n",
    "                        sess.run(tf.local_variables_initializer())\n",
    "                        print(\"retraining {}\".format(latest_ckpt))\n",
    "                    else:\n",
    "                        sess.run(tf.global_variables_initializer())\n",
    "                        sess.run(tf.local_variables_initializer())\n",
    "                        print(\"no old model, training new----\")\n",
    "                writer = tf.summary.FileWriter(os.path.join(log_path, \"logsevery_%s\" % self.config[\"tailname\"]),\n",
    "                                               sess.graph)\n",
    "                global_n = 0\n",
    "                stop_n = 0\n",
    "                startt = time.time()\n",
    "                pre_t_base_loss = pre_t_much_loss = pre_v_much_loss = pre_v_base_loss = 100000\n",
    "\n",
    "                n_splits = 5\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=4389)\n",
    "                for epoch in range(num_epochs):\n",
    "                    self.config[\"learn_rate\"] *= 0.3\n",
    "                    trainevenidlist = list(set(trainpd['event_id']))\n",
    "                    for train_index, valid_index in kf.split(trainevenidlist):\n",
    "                        starte = time.time()\n",
    "                        print(\"iter_trainnum\", len(train_index))\n",
    "                        np.random.shuffle(train_index)\n",
    "                        np.random.shuffle(valid_index)\n",
    "                        for batch_num, eventindex in enumerate(train_index):\n",
    "                            # 获取数据\n",
    "                            thisindex = trainpd[trainpd['event_id'] == trainevenidlist[eventindex]].index\n",
    "                            r_inputs_t = np.array(trainpd.iloc[thisindex][feature])\n",
    "                            r_output_t = np.expand_dims(np.array(labels[thisindex]), -1)\n",
    "                            feed_dict_t = {\n",
    "                                self.input_p: r_inputs_t,\n",
    "                                self.target_y: r_output_t,\n",
    "                                self.learn_rate_p: self.config[\"learn_rate\"],\n",
    "                                self.lr_decay: 1,\n",
    "                            }\n",
    "                            # 更新学习率\n",
    "                            sess.run(self.train_op, feed_dict_t)\n",
    "                            global_n += 1\n",
    "                            losslist_t = sess.run(self.train_list, feed_dict_t)\n",
    "                            sess.run(self.auc_op, feed_dict=feed_dict_t)\n",
    "                            accu = sess.run(self.auc_value)\n",
    "                            result = sess.run(self.merged, feed_dict_t)\n",
    "                            if batch_num % 200 == 0:\n",
    "                                writer.add_summary(result, global_n)\n",
    "                                self.saver.save(sess,\n",
    "                                                os.path.join(model_path, 'modelevery_%s' % self.config[\"tailname\"],\n",
    "                                                             self.config[\"modelfile\"]), global_step=global_n)\n",
    "                                print(\"epocht {}, batch_num {}, step {}, time: {} s, accu: {}, loss_yt: {}\".format(\n",
    "                                    epoch, batch_num, global_n, time.time() - starte, accu, *losslist_t))\n",
    "                        # valid part\n",
    "                        print(\"iter_validnum\", len(valid_index))\n",
    "                        losslist_va = 0\n",
    "                        accu_va = 0\n",
    "                        for batch_num, eventindex in enumerate(valid_index):\n",
    "                            # 获取数据\n",
    "                            thisindex = trainpd[trainpd['event_id'] == trainevenidlist[eventindex]].index\n",
    "                            r_inputs_v = np.array(trainpd.iloc[thisindex][feature])\n",
    "                            r_output_v = np.expand_dims(np.array(labels[thisindex]), -1)\n",
    "                            feed_dict_v = {\n",
    "                                self.input_p: r_inputs_v,\n",
    "                                self.target_y: r_output_v,\n",
    "                                self.learn_rate_p: self.config[\"learn_rate\"],\n",
    "                                self.lr_decay: 1,\n",
    "                            }\n",
    "                            losslist_v = sess.run(self.valid_list, feed_dict_v)\n",
    "                            sess.run(self.auc_op, feed_dict=feed_dict_v)\n",
    "                            accu = sess.run(self.auc_value)\n",
    "                            losslist_va += losslist_v[0]\n",
    "                            accu_va += accu\n",
    "                        losslist_va /= len(valid_index)\n",
    "                        accu_va /= len(valid_index)\n",
    "                        result = sess.run(self.merged, feed_dict_v)\n",
    "                        writer.add_summary(result, global_n)\n",
    "                        if losslist_t[0] < pre_t_base_loss and losslist_va < pre_v_base_loss:\n",
    "                            stop_n += 1\n",
    "                            if stop_n > self.config[\"early_stop\"]:\n",
    "                                break\n",
    "                            else:\n",
    "                                self.saver.save(sess,\n",
    "                                                os.path.join(model_path, 'modelevery_%s' % self.config[\"tailname\"],\n",
    "                                                             self.config[\"modelfile\"]), global_step=global_n)\n",
    "                        else:\n",
    "                            stop_n = 0\n",
    "                            self.saver.save(sess, os.path.join(model_path, 'modelevery_%s' % self.config[\"tailname\"],\n",
    "                                                               self.config[\"modelfile\"]), global_step=global_n)\n",
    "                        print(\"epochv {}, step {}, stop_n {}, time: {} s, accu_va: {}, loss_yv: {}\".format(\n",
    "                            epoch, global_n, stop_n, time.time() - starte, accu_va, losslist_va))\n",
    "                        pre_t_base_loss = losslist_t[0]\n",
    "                        pre_v_base_loss = losslist_va\n",
    "                writer.close()\n",
    "                print(\"total time: %s s\" % (time.time() - startt))\n",
    "        # 结束\n",
    "        print(\"train finished!\")\n",
    "        return None\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        model_dir = os.path.join(model_path, \"modelevery_%s\" % self.config[\"tailname\"])\n",
    "        print(\"loading model...\")\n",
    "        latest_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "\n",
    "        sess = tf.Session(graph=self.graph)\n",
    "        with sess.as_default():\n",
    "            with self.graph.as_default():\n",
    "                if os.path.isfile(\"{}.index\".format(latest_ckpt)):\n",
    "                    self.saver.restore(sess, latest_ckpt)\n",
    "                else:\n",
    "                    raise Exception(\"没有找到模型:{}\".format(latest_ckpt))\n",
    "                nplist = []\n",
    "                oneiter = 2000\n",
    "                redi = inputs.shape[0] % oneiter\n",
    "                lenth = inputs.shape[0] // oneiter\n",
    "                if 0 != redi:\n",
    "                    lenth += 1\n",
    "                counter = 0\n",
    "                for num in range(lenth):\n",
    "                    # 获取数据\n",
    "                    startindex = num * oneiter\n",
    "                    if num == lenth - 1 and redi != 0:\n",
    "                        endindex = num * oneiter + redi\n",
    "                    else:\n",
    "                        endindex = (num + 1) * oneiter\n",
    "                    tmppd = inputs.iloc[startindex:endindex][feature]\n",
    "                    r_inputs_v = np.array(tmppd)\n",
    "                    feed_dict = {\n",
    "                        self.input_p: r_inputs_v,\n",
    "                    }\n",
    "                    teslis = sess.run(self.pred_list, feed_dict)\n",
    "                    nplist.append(teslis)\n",
    "                feed_dict = {\n",
    "                    self.input_p: inputs,\n",
    "                }\n",
    "                teslist = np.concatenate(nplist, axis=1)\n",
    "                return teslist\n",
    "\n",
    "\n",
    "trainconfig = {\n",
    "    \"dropout\": 0.5,\n",
    "    \"early_stop\": 100,\n",
    "#     \"tailname\": \"nomul_modeltail\",\n",
    "#     \"modelname\": \"nomul_model\",\n",
    "    \"tailname\": \"mul_test\",\n",
    "    \"modelname\": \"cnn_dense_less\",\n",
    "    \"modelfile\": \"v2\",\n",
    "    \"learn_rate\": 0.01,\n",
    "    \"retrain\": 1\n",
    "}\n",
    "modelcrnn = NeurousNet(len(feature), config=trainconfig)\n",
    "modelcrnn.buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  event_id  hit_id          q         t   terror  nhit  nhitreal  \\\n",
      "0      0         7       1   1.050520  767.8790  2.02966   426        70   \n",
      "1      1         7       2   0.999853  -70.5552  2.02966   426        70   \n",
      "2      2         7       3   2.052540 -837.8410  1.85146   426        70   \n",
      "3      3         7       4  19.513100 -973.1950  1.39994   426        70   \n",
      "4      4         7       5   0.800334 -159.1400  2.02966   426        70   \n",
      "\n",
      "   energymc  thetamc    phimc   xcmc    ycmc      fx      fy        fdis  \\\n",
      "0   48348.9  63.1686  11.0982 -40.83  114.03 -101.67 -261.53  280.597095   \n",
      "1   48348.9  63.1686  11.0982 -40.83  114.03  -96.67 -266.53  283.519540   \n",
      "2   48348.9  63.1686  11.0982 -40.83  114.03  -96.67 -246.53  264.805834   \n",
      "3   48348.9  63.1686  11.0982 -40.83  114.03 -101.67 -231.53  252.869393   \n",
      "4   48348.9  63.1686  11.0982 -40.83  114.03  -96.67 -231.53  250.900837   \n",
      "\n",
      "     fsinth    fcosth      fphi   fsinphi   fcosphi      fttrue  nhitratio  \\\n",
      "0  0.892339  0.451367 -1.941568 -0.033880  0.999426  378.328883   6.085714   \n",
      "1  0.892339  0.451367 -1.918739 -0.033482  0.999439  -34.762078   6.085714   \n",
      "2  0.892339  0.451367 -1.944494 -0.033931  0.999424 -452.529895   6.085714   \n",
      "3  0.892339  0.451367 -1.984568 -0.034630  0.999400 -695.169079   6.085714   \n",
      "4  0.892339  0.451367 -1.966320 -0.034312  0.999411  -78.407221   6.085714   \n",
      "\n",
      "   fdis_stdmean  \n",
      "0      0.542283  \n",
      "1      0.542283  \n",
      "2      0.542283  \n",
      "3      0.542283  \n",
      "4      0.542283  \n",
      "INFO:tensorflow:Restoring parameters from ..\\data\\particles\\model\\modelevery_mul_test\\v2-14241\n",
      "retraining ..\\data\\particles\\model\\modelevery_mul_test\\v2-14241\n",
      "iter_trainnum 7440\n",
      "epocht 0, batch_num 0, step 1, time: 0.746004581451416 s, accu: 0.7152913212776184, loss_yt: 0.3464307188987732\n",
      "epocht 0, batch_num 200, step 201, time: 8.985971927642822 s, accu: 0.8447082042694092, loss_yt: 0.20259451866149902\n",
      "epocht 0, batch_num 400, step 401, time: 17.27780032157898 s, accu: 0.8434895277023315, loss_yt: 0.5053129196166992\n",
      "epocht 0, batch_num 600, step 601, time: 25.69329524040222 s, accu: 0.8428889513015747, loss_yt: 0.3087349236011505\n",
      "epocht 0, batch_num 800, step 801, time: 33.68093752861023 s, accu: 0.845280110836029, loss_yt: 0.293260395526886\n",
      "epocht 0, batch_num 1000, step 1001, time: 41.96079707145691 s, accu: 0.8455407619476318, loss_yt: 0.22796587646007538\n",
      "epocht 0, batch_num 1200, step 1201, time: 49.97954535484314 s, accu: 0.846108615398407, loss_yt: 0.2020273208618164\n",
      "epocht 0, batch_num 1400, step 1401, time: 58.185603618621826 s, accu: 0.8456516861915588, loss_yt: 0.34340885281562805\n",
      "epocht 0, batch_num 1600, step 1601, time: 65.78129267692566 s, accu: 0.8466166853904724, loss_yt: 0.11641150712966919\n",
      "epocht 0, batch_num 1800, step 1801, time: 73.26228833198547 s, accu: 0.846992552280426, loss_yt: 0.2078886181116104\n",
      "epocht 0, batch_num 2000, step 2001, time: 80.79713845252991 s, accu: 0.8477271199226379, loss_yt: 0.22280310094356537\n",
      "epocht 0, batch_num 2200, step 2201, time: 88.46563267707825 s, accu: 0.8475748300552368, loss_yt: 0.32286736369132996\n",
      "epocht 0, batch_num 2400, step 2401, time: 96.26879334449768 s, accu: 0.8473957777023315, loss_yt: 0.3503965139389038\n",
      "epocht 0, batch_num 2600, step 2601, time: 103.78167700767517 s, accu: 0.8475431203842163, loss_yt: 0.3567138612270355\n",
      "epocht 0, batch_num 2800, step 2801, time: 111.69451808929443 s, accu: 0.848102867603302, loss_yt: 0.31972506642341614\n",
      "epocht 0, batch_num 3000, step 3001, time: 119.46576404571533 s, accu: 0.848212480545044, loss_yt: 0.3588065803050995\n",
      "epocht 0, batch_num 3200, step 3201, time: 127.23496222496033 s, accu: 0.8484859466552734, loss_yt: 0.4285280108451843\n",
      "epocht 0, batch_num 3400, step 3401, time: 135.22959780693054 s, accu: 0.8485745191574097, loss_yt: 0.2485494464635849\n",
      "epocht 0, batch_num 3600, step 3601, time: 143.49748134613037 s, accu: 0.8487629294395447, loss_yt: 0.352134644985199\n",
      "epocht 0, batch_num 3800, step 3801, time: 151.39536309242249 s, accu: 0.8489422798156738, loss_yt: 0.38688337802886963\n",
      "epocht 0, batch_num 4000, step 4001, time: 159.50966572761536 s, accu: 0.8489725589752197, loss_yt: 0.6531311869621277\n",
      "epocht 0, batch_num 4200, step 4201, time: 167.47137546539307 s, accu: 0.8495891690254211, loss_yt: 0.28500398993492126\n",
      "epocht 0, batch_num 4400, step 4401, time: 175.64751148223877 s, accu: 0.8495835661888123, loss_yt: 0.29779893159866333\n",
      "epocht 0, batch_num 4600, step 4601, time: 183.77780413627625 s, accu: 0.8499003052711487, loss_yt: 0.5058620572090149\n",
      "epocht 0, batch_num 4800, step 4801, time: 192.11251139640808 s, accu: 0.8501086235046387, loss_yt: 0.25007233023643494\n",
      "epocht 0, batch_num 5000, step 5001, time: 200.3753890991211 s, accu: 0.8502232432365417, loss_yt: 0.4291900396347046\n",
      "epocht 0, batch_num 5200, step 5201, time: 208.50664520263672 s, accu: 0.8501318693161011, loss_yt: 0.20726332068443298\n",
      "epocht 0, batch_num 5400, step 5401, time: 217.04385018348694 s, accu: 0.850590705871582, loss_yt: 0.26677724719047546\n",
      "epocht 0, batch_num 5600, step 5601, time: 224.69638061523438 s, accu: 0.8503600358963013, loss_yt: 0.30543577671051025\n",
      "epocht 0, batch_num 5800, step 5801, time: 232.38679456710815 s, accu: 0.8503086566925049, loss_yt: 0.5088860392570496\n",
      "epocht 0, batch_num 6000, step 6001, time: 239.88274931907654 s, accu: 0.8504593372344971, loss_yt: 0.3433103859424591\n",
      "epocht 0, batch_num 6200, step 6201, time: 247.65798711776733 s, accu: 0.8505139350891113, loss_yt: 0.3864954113960266\n",
      "epocht 0, batch_num 6400, step 6401, time: 255.55288887023926 s, accu: 0.8503039479255676, loss_yt: 0.27486857771873474\n",
      "epocht 0, batch_num 6600, step 6601, time: 262.9530909061432 s, accu: 0.8504709005355835, loss_yt: 0.35922402143478394\n",
      "epocht 0, batch_num 6800, step 6801, time: 270.8579170703888 s, accu: 0.8504602909088135, loss_yt: 0.26961711049079895\n",
      "epocht 0, batch_num 7000, step 7001, time: 278.3888740539551 s, accu: 0.850428581237793, loss_yt: 0.32892173528671265\n",
      "epocht 0, batch_num 7200, step 7201, time: 286.0464286804199 s, accu: 0.8505831956863403, loss_yt: 0.42321664094924927\n",
      "epocht 0, batch_num 7400, step 7401, time: 293.9223680496216 s, accu: 0.8506821393966675, loss_yt: 0.19715994596481323\n",
      "iter_validnum 1860\n",
      "epochv 0, step 7440, stop_n 1, time: 348.0396263599396 s, accu_va: 0.85044662567877, loss_yv: 0.3247487561717149\n",
      "iter_trainnum 7440\n",
      "epocht 0, batch_num 0, step 7441, time: 0.603384256362915 s, accu: 0.8501770496368408, loss_yt: 0.28032609820365906\n",
      "epocht 0, batch_num 200, step 7641, time: 8.163169622421265 s, accu: 0.8502480387687683, loss_yt: 0.5785950422286987\n",
      "epocht 0, batch_num 400, step 7841, time: 15.665109634399414 s, accu: 0.8503447771072388, loss_yt: 0.28385454416275024\n",
      "epocht 0, batch_num 600, step 8041, time: 23.660728216171265 s, accu: 0.850329577922821, loss_yt: 0.3867335915565491\n",
      "epocht 0, batch_num 800, step 8241, time: 31.119784355163574 s, accu: 0.850314736366272, loss_yt: 0.4305550754070282\n",
      "epocht 0, batch_num 1000, step 8441, time: 38.68555402755737 s, accu: 0.8501269817352295, loss_yt: 0.33986571431159973\n",
      "epocht 0, batch_num 1200, step 8641, time: 46.525614738464355 s, accu: 0.8499615788459778, loss_yt: 0.3177715539932251\n",
      "epocht 0, batch_num 1400, step 8841, time: 54.32376551628113 s, accu: 0.8500136733055115, loss_yt: 0.2177591323852539\n",
      "epocht 0, batch_num 1600, step 9041, time: 61.97830033302307 s, accu: 0.8500283360481262, loss_yt: 0.16035689413547516\n",
      "epocht 0, batch_num 1800, step 9241, time: 69.47425508499146 s, accu: 0.8501285314559937, loss_yt: 0.3551286458969116\n",
      "epocht 0, batch_num 2000, step 9441, time: 76.8824143409729 s, accu: 0.85007244348526, loss_yt: 0.24351048469543457\n",
      "epocht 0, batch_num 2200, step 9641, time: 84.39731907844543 s, accu: 0.8501100540161133, loss_yt: 0.3763042390346527\n",
      "epocht 0, batch_num 2400, step 9841, time: 91.850421667099 s, accu: 0.8501582741737366, loss_yt: 0.37608802318573\n",
      "epocht 0, batch_num 2600, step 10041, time: 99.43813467025757 s, accu: 0.8501665592193604, loss_yt: 0.2894103527069092\n",
      "epocht 0, batch_num 2800, step 10241, time: 107.0936667919159 s, accu: 0.8502703309059143, loss_yt: 0.30921661853790283\n",
      "epocht 0, batch_num 3000, step 10441, time: 115.07328939437866 s, accu: 0.8503515720367432, loss_yt: 0.2854149639606476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 0, batch_num 3200, step 10641, time: 122.49647855758667 s, accu: 0.8505020141601562, loss_yt: 0.24350520968437195\n",
      "epocht 0, batch_num 3400, step 10841, time: 129.9495439529419 s, accu: 0.8505746126174927, loss_yt: 0.22349847853183746\n",
      "epocht 0, batch_num 3600, step 11041, time: 137.39664816856384 s, accu: 0.8506602048873901, loss_yt: 0.33733245730400085\n",
      "epocht 0, batch_num 3800, step 11241, time: 145.0830433368683 s, accu: 0.8505998253822327, loss_yt: 0.3111403286457062\n",
      "epocht 0, batch_num 4000, step 11441, time: 152.54907989501953 s, accu: 0.8506993055343628, loss_yt: 0.49238941073417664\n",
      "epocht 0, batch_num 4200, step 11641, time: 160.16672039031982 s, accu: 0.8507202863693237, loss_yt: 0.3479946553707123\n",
      "epocht 0, batch_num 4400, step 11841, time: 167.88108444213867 s, accu: 0.8508158922195435, loss_yt: 0.277670294046402\n",
      "epocht 0, batch_num 4600, step 12041, time: 175.54861402511597 s, accu: 0.8508191704750061, loss_yt: 0.3162747919559479\n",
      "epocht 0, batch_num 4800, step 12241, time: 182.9488217830658 s, accu: 0.8509146571159363, loss_yt: 0.311550110578537\n",
      "epocht 0, batch_num 5000, step 12441, time: 190.74195671081543 s, accu: 0.8508613705635071, loss_yt: 0.11814163625240326\n",
      "epocht 0, batch_num 5200, step 12641, time: 198.08631134033203 s, accu: 0.8508651256561279, loss_yt: 0.24966377019882202\n",
      "epocht 0, batch_num 5400, step 12841, time: 205.65108442306519 s, accu: 0.850946307182312, loss_yt: 0.2627258002758026\n",
      "epocht 0, batch_num 5600, step 13041, time: 213.25874161720276 s, accu: 0.8510134220123291, loss_yt: 0.31281551718711853\n",
      "epocht 0, batch_num 5800, step 13241, time: 221.15861463546753 s, accu: 0.8509947657585144, loss_yt: 0.28692179918289185\n",
      "epocht 0, batch_num 6000, step 13441, time: 228.69246912002563 s, accu: 0.8510175943374634, loss_yt: 0.3181123733520508\n",
      "epocht 0, batch_num 6200, step 13641, time: 236.47166752815247 s, accu: 0.851012110710144, loss_yt: 0.19585049152374268\n",
      "epocht 0, batch_num 6400, step 13841, time: 244.00153255462646 s, accu: 0.8510057330131531, loss_yt: 0.14061380922794342\n",
      "epocht 0, batch_num 6600, step 14041, time: 251.42671585083008 s, accu: 0.8510357737541199, loss_yt: 0.3568130135536194\n",
      "epocht 0, batch_num 6800, step 14241, time: 259.2168462276459 s, accu: 0.8510302901268005, loss_yt: 0.2915780544281006\n",
      "epocht 0, batch_num 7000, step 14441, time: 266.81455874443054 s, accu: 0.8510730862617493, loss_yt: 0.27319392561912537\n",
      "epocht 0, batch_num 7200, step 14641, time: 274.3902807235718 s, accu: 0.8509368300437927, loss_yt: 0.28699129819869995\n",
      "epocht 0, batch_num 7400, step 14841, time: 282.0817050933838 s, accu: 0.8510269522666931, loss_yt: 0.4858511686325073\n",
      "iter_validnum 1860\n",
      "epochv 0, step 14880, stop_n 0, time: 335.77815341949463 s, accu_va: 0.8506393730640411, loss_yv: 0.3232689491443096\n",
      "iter_trainnum 7440\n",
      "epocht 0, batch_num 0, step 14881, time: 0.32213759422302246 s, accu: 0.8503677248954773, loss_yt: 0.29711875319480896\n",
      "epocht 0, batch_num 200, step 15081, time: 8.076369762420654 s, accu: 0.850383996963501, loss_yt: 0.3290749490261078\n",
      "epocht 0, batch_num 400, step 15281, time: 15.738882303237915 s, accu: 0.8503352403640747, loss_yt: 0.47002533078193665\n",
      "epocht 0, batch_num 600, step 15481, time: 23.154052257537842 s, accu: 0.8502988815307617, loss_yt: 0.3267807364463806\n",
      "epocht 0, batch_num 800, step 15681, time: 30.715867519378662 s, accu: 0.8502954840660095, loss_yt: 0.3438264727592468\n",
      "epocht 0, batch_num 1000, step 15881, time: 38.4032769203186 s, accu: 0.8503156900405884, loss_yt: 0.25454625487327576\n",
      "epocht 0, batch_num 1200, step 16081, time: 45.854376792907715 s, accu: 0.8504180908203125, loss_yt: 0.24358713626861572\n",
      "epocht 0, batch_num 1400, step 16281, time: 53.35030674934387 s, accu: 0.8504706621170044, loss_yt: 0.3616930842399597\n",
      "epocht 0, batch_num 1600, step 16481, time: 61.00583529472351 s, accu: 0.8505457043647766, loss_yt: 0.28927141427993774\n",
      "epocht 0, batch_num 1800, step 16681, time: 68.75012874603271 s, accu: 0.8505219221115112, loss_yt: 0.4057254195213318\n",
      "epocht 0, batch_num 2000, step 16881, time: 76.30193400382996 s, accu: 0.8505405783653259, loss_yt: 0.23508326709270477\n",
      "epocht 0, batch_num 2200, step 17081, time: 83.78993821144104 s, accu: 0.8505561947822571, loss_yt: 0.25151538848876953\n",
      "epocht 0, batch_num 2400, step 17281, time: 91.1672158241272 s, accu: 0.8506136536598206, loss_yt: 0.3956926167011261\n",
      "epocht 0, batch_num 2600, step 17481, time: 98.52953433990479 s, accu: 0.8506608605384827, loss_yt: 0.17684778571128845\n",
      "epocht 0, batch_num 2800, step 17681, time: 106.1152446269989 s, accu: 0.8507553935050964, loss_yt: 0.5110231041908264\n",
      "epocht 0, batch_num 3000, step 17881, time: 113.57825684547424 s, accu: 0.8506844639778137, loss_yt: 0.3137277662754059\n",
      "epocht 0, batch_num 3200, step 18081, time: 121.21786069869995 s, accu: 0.8507058024406433, loss_yt: 0.3490031063556671\n",
      "epocht 0, batch_num 3400, step 18281, time: 128.81850409507751 s, accu: 0.8507406711578369, loss_yt: 0.24452561140060425\n",
      "epocht 0, batch_num 3600, step 18481, time: 136.22170662879944 s, accu: 0.850780725479126, loss_yt: 0.13507214188575745\n",
      "epocht 0, batch_num 3800, step 18681, time: 143.6558609008789 s, accu: 0.850828230381012, loss_yt: 0.45496228337287903\n",
      "epocht 0, batch_num 4000, step 18881, time: 151.1977083683014 s, accu: 0.8508656024932861, loss_yt: 0.3714451193809509\n",
      "epocht 0, batch_num 4200, step 19081, time: 158.81130409240723 s, accu: 0.8508578538894653, loss_yt: 0.29205837845802307\n",
      "epocht 0, batch_num 4400, step 19281, time: 166.24745798110962 s, accu: 0.8508848547935486, loss_yt: 0.5276066660881042\n",
      "epocht 0, batch_num 4600, step 19481, time: 173.85308003425598 s, accu: 0.8509218692779541, loss_yt: 0.36859995126724243\n",
      "epocht 0, batch_num 4800, step 19681, time: 181.2823429107666 s, accu: 0.8508978486061096, loss_yt: 0.4073101878166199\n",
      "epocht 0, batch_num 5000, step 19881, time: 188.83810758590698 s, accu: 0.8509004712104797, loss_yt: 0.1982167512178421\n",
      "epocht 0, batch_num 5200, step 20081, time: 196.26524543762207 s, accu: 0.8509229421615601, loss_yt: 0.323214590549469\n",
      "epocht 0, batch_num 5400, step 20281, time: 203.85101056098938 s, accu: 0.8510164618492126, loss_yt: 0.4209950566291809\n",
      "epocht 0, batch_num 5600, step 20481, time: 211.29309344291687 s, accu: 0.8510169982910156, loss_yt: 0.3578396737575531\n",
      "epocht 0, batch_num 5800, step 20681, time: 218.84290027618408 s, accu: 0.8510139584541321, loss_yt: 0.35397130250930786\n",
      "epocht 0, batch_num 6000, step 20881, time: 226.15733885765076 s, accu: 0.8511215448379517, loss_yt: 0.3064860999584198\n",
      "epocht 0, batch_num 6200, step 21081, time: 233.7540307044983 s, accu: 0.8510977029800415, loss_yt: 0.3003118932247162\n",
      "epocht 0, batch_num 6400, step 21281, time: 241.490336894989 s, accu: 0.8510854244232178, loss_yt: 0.38008761405944824\n",
      "epocht 0, batch_num 6600, step 21481, time: 248.90648365020752 s, accu: 0.8510913848876953, loss_yt: 0.27611953020095825\n",
      "epocht 0, batch_num 6800, step 21681, time: 256.49818181991577 s, accu: 0.8511278629302979, loss_yt: 0.3301582336425781\n",
      "epocht 0, batch_num 7000, step 21881, time: 263.9412784576416 s, accu: 0.8511500954627991, loss_yt: 0.3517199754714966\n",
      "epocht 0, batch_num 7200, step 22081, time: 271.6736309528351 s, accu: 0.8511090278625488, loss_yt: 0.2209457904100418\n",
      "epocht 0, batch_num 7400, step 22281, time: 279.21743059158325 s, accu: 0.8511704206466675, loss_yt: 0.2029733508825302\n",
      "iter_validnum 1860\n",
      "epochv 0, step 22320, stop_n 1, time: 332.8251140117645 s, accu_va: 0.8513029737177715, loss_yv: 0.31048908300537575\n",
      "iter_trainnum 7440\n",
      "epocht 0, batch_num 0, step 22321, time: 0.3899247646331787 s, accu: 0.8514471054077148, loss_yt: 0.2552258372306824\n",
      "epocht 0, batch_num 200, step 22521, time: 8.025538921356201 s, accu: 0.8514875173568726, loss_yt: 0.2832300066947937\n",
      "epocht 0, batch_num 400, step 22721, time: 15.509492874145508 s, accu: 0.8514875173568726, loss_yt: 0.7053562998771667\n",
      "epocht 0, batch_num 600, step 22921, time: 22.9785213470459 s, accu: 0.8515117764472961, loss_yt: 0.2542833685874939\n",
      "epocht 0, batch_num 800, step 23121, time: 30.585214376449585 s, accu: 0.8515444993972778, loss_yt: 0.3957967758178711\n",
      "epocht 0, batch_num 1000, step 23321, time: 38.198853731155396 s, accu: 0.8515245318412781, loss_yt: 0.26399677991867065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 0, batch_num 1200, step 23521, time: 46.11166477203369 s, accu: 0.8514974117279053, loss_yt: 0.5381332635879517\n",
      "epocht 0, batch_num 1400, step 23721, time: 53.77417206764221 s, accu: 0.8515070676803589, loss_yt: 0.17125381529331207\n",
      "epocht 0, batch_num 1600, step 23921, time: 61.404768228530884 s, accu: 0.851513683795929, loss_yt: 0.23237530887126923\n",
      "epocht 0, batch_num 1800, step 24121, time: 68.93862318992615 s, accu: 0.8514977693557739, loss_yt: 0.40964871644973755\n",
      "epocht 0, batch_num 2000, step 24321, time: 76.51536178588867 s, accu: 0.8515134453773499, loss_yt: 0.27907583117485046\n",
      "epocht 0, batch_num 2200, step 24521, time: 84.237713098526 s, accu: 0.8515274524688721, loss_yt: 0.12859109044075012\n",
      "epocht 0, batch_num 2400, step 24721, time: 91.77359390258789 s, accu: 0.8515454530715942, loss_yt: 0.2602071166038513\n",
      "epocht 0, batch_num 2600, step 24921, time: 99.4580283164978 s, accu: 0.8515669107437134, loss_yt: 0.25924697518348694\n",
      "epocht 0, batch_num 2800, step 25121, time: 107.51649212837219 s, accu: 0.8515456914901733, loss_yt: 0.35166704654693604\n",
      "epocht 0, batch_num 3000, step 25321, time: 114.75411176681519 s, accu: 0.8516075611114502, loss_yt: 0.2775941789150238\n",
      "epocht 0, batch_num 3200, step 25521, time: 122.40166211128235 s, accu: 0.851586639881134, loss_yt: 0.3246021568775177\n",
      "epocht 0, batch_num 3400, step 25721, time: 129.95446610450745 s, accu: 0.8515827655792236, loss_yt: 0.30557334423065186\n",
      "epocht 0, batch_num 3600, step 25921, time: 137.57713794708252 s, accu: 0.8516066074371338, loss_yt: 0.23878207802772522\n",
      "epocht 0, batch_num 3800, step 26121, time: 144.95343923568726 s, accu: 0.8516032695770264, loss_yt: 0.33546552062034607\n",
      "epocht 0, batch_num 4000, step 26321, time: 152.46732306480408 s, accu: 0.851611316204071, loss_yt: 0.18954500555992126\n",
      "epocht 0, batch_num 4200, step 26521, time: 160.26048636436462 s, accu: 0.8516662120819092, loss_yt: 0.2633976936340332\n",
      "epocht 0, batch_num 4400, step 26721, time: 167.67466115951538 s, accu: 0.8517120480537415, loss_yt: 0.4224398732185364\n",
      "epocht 0, batch_num 4600, step 26921, time: 175.074871301651 s, accu: 0.8516900539398193, loss_yt: 0.3257429003715515\n",
      "epocht 0, batch_num 4800, step 27121, time: 182.74937772750854 s, accu: 0.8516318798065186, loss_yt: 0.2914584279060364\n",
      "epocht 0, batch_num 5000, step 27321, time: 190.20341515541077 s, accu: 0.8516839146614075, loss_yt: 0.3237307369709015\n",
      "epocht 0, batch_num 5200, step 27521, time: 197.57869219779968 s, accu: 0.8517035245895386, loss_yt: 0.2994256019592285\n",
      "epocht 0, batch_num 5400, step 27721, time: 205.15347242355347 s, accu: 0.851715624332428, loss_yt: 0.19674204289913177\n",
      "epocht 0, batch_num 5600, step 27921, time: 212.70923352241516 s, accu: 0.851719319820404, loss_yt: 0.30193057656288147\n",
      "epocht 0, batch_num 5800, step 28121, time: 220.30990934371948 s, accu: 0.8517165780067444, loss_yt: 0.16530834138393402\n",
      "epocht 0, batch_num 6000, step 28321, time: 227.9205663204193 s, accu: 0.8516642451286316, loss_yt: 0.3012218475341797\n",
      "epocht 0, batch_num 6200, step 28521, time: 235.58905458450317 s, accu: 0.8516470789909363, loss_yt: 0.373260498046875\n",
      "epocht 0, batch_num 6400, step 28721, time: 242.92244243621826 s, accu: 0.8516537547111511, loss_yt: 0.18620087206363678\n",
      "epocht 0, batch_num 6600, step 28921, time: 250.5989158153534 s, accu: 0.8516530394554138, loss_yt: 0.5872274041175842\n",
      "epocht 0, batch_num 6800, step 29121, time: 258.309298992157 s, accu: 0.8516600131988525, loss_yt: 0.32586756348609924\n",
      "epocht 0, batch_num 7000, step 29321, time: 265.64668321609497 s, accu: 0.8516742587089539, loss_yt: 0.23544031381607056\n",
      "epocht 0, batch_num 7200, step 29521, time: 273.24339151382446 s, accu: 0.8517047166824341, loss_yt: 0.3768724203109741\n",
      "epocht 0, batch_num 7400, step 29721, time: 280.70341634750366 s, accu: 0.8516983985900879, loss_yt: 0.4305545389652252\n",
      "iter_validnum 1860\n",
      "epochv 0, step 29760, stop_n 0, time: 334.30807638168335 s, accu_va: 0.8518188517260296, loss_yv: 0.31192665211055226\n",
      "iter_trainnum 7440\n",
      "epocht 0, batch_num 0, step 29761, time: 0.24434494972229004 s, accu: 0.8519747257232666, loss_yt: 0.24863721430301666\n",
      "epocht 0, batch_num 200, step 29961, time: 7.9138360023498535 s, accu: 0.8519815802574158, loss_yt: 0.3465554416179657\n",
      "epocht 0, batch_num 400, step 30161, time: 15.619263648986816 s, accu: 0.8519736528396606, loss_yt: 0.327412486076355\n",
      "epocht 0, batch_num 600, step 30361, time: 23.125195741653442 s, accu: 0.8519615530967712, loss_yt: 0.13426339626312256\n",
      "epocht 0, batch_num 800, step 30561, time: 30.615132570266724 s, accu: 0.8519777655601501, loss_yt: 0.2825223207473755\n",
      "epocht 0, batch_num 1000, step 30761, time: 38.306599140167236 s, accu: 0.8520092964172363, loss_yt: 0.25802820920944214\n",
      "epocht 0, batch_num 1200, step 30961, time: 45.8733594417572 s, accu: 0.8520350456237793, loss_yt: 0.3206220865249634\n",
      "epocht 0, batch_num 1400, step 31161, time: 53.21769309043884 s, accu: 0.8520591259002686, loss_yt: 0.2885964810848236\n",
      "epocht 0, batch_num 1600, step 31361, time: 60.71668362617493 s, accu: 0.8520832657814026, loss_yt: 0.33194729685783386\n",
      "epocht 0, batch_num 1800, step 31561, time: 68.03410530090332 s, accu: 0.8521138429641724, loss_yt: 0.6776576042175293\n",
      "epocht 0, batch_num 2000, step 31761, time: 75.59289073944092 s, accu: 0.8521115779876709, loss_yt: 0.28954753279685974\n",
      "epocht 0, batch_num 2200, step 31961, time: 83.25738430023193 s, accu: 0.8521572351455688, loss_yt: 0.3606681823730469\n",
      "epocht 0, batch_num 2400, step 32161, time: 91.00867199897766 s, accu: 0.8521400690078735, loss_yt: 0.29934704303741455\n",
      "epocht 0, batch_num 2600, step 32361, time: 98.66120862960815 s, accu: 0.8521027565002441, loss_yt: 0.4116934537887573\n",
      "epocht 0, batch_num 2800, step 32561, time: 106.30277442932129 s, accu: 0.8521130681037903, loss_yt: 0.2878844439983368\n",
      "epocht 0, batch_num 3000, step 32761, time: 113.71994113922119 s, accu: 0.8521219491958618, loss_yt: 0.14618612825870514\n",
      "epocht 0, batch_num 3200, step 32961, time: 121.12610363960266 s, accu: 0.8521242141723633, loss_yt: 0.17804472148418427\n",
      "epocht 0, batch_num 3400, step 33161, time: 128.55424046516418 s, accu: 0.8521355390548706, loss_yt: 0.25362229347229004\n",
      "epocht 0, batch_num 3600, step 33361, time: 135.85870933532715 s, accu: 0.8521842956542969, loss_yt: 0.16744619607925415\n",
      "epocht 0, batch_num 3800, step 33561, time: 143.45445132255554 s, accu: 0.8521866798400879, loss_yt: 0.3826914429664612\n",
      "epocht 0, batch_num 4000, step 33761, time: 151.2984230518341 s, accu: 0.8521701693534851, loss_yt: 0.17937536537647247\n",
      "epocht 0, batch_num 4200, step 33961, time: 159.1195409297943 s, accu: 0.8521562218666077, loss_yt: 0.18226797878742218\n",
      "epocht 0, batch_num 4400, step 34161, time: 166.4878330230713 s, accu: 0.8522067070007324, loss_yt: 0.14751584827899933\n",
      "epocht 0, batch_num 4600, step 34361, time: 173.95387315750122 s, accu: 0.8522439002990723, loss_yt: 0.1360357105731964\n",
      "epocht 0, batch_num 4800, step 34561, time: 181.51265692710876 s, accu: 0.8522418141365051, loss_yt: 0.26915431022644043\n",
      "epocht 0, batch_num 5000, step 34761, time: 188.9427933692932 s, accu: 0.852228045463562, loss_yt: 0.30536991357803345\n",
      "epocht 0, batch_num 5200, step 34961, time: 196.42176222801208 s, accu: 0.8522420525550842, loss_yt: 0.26624128222465515\n",
      "epocht 0, batch_num 5400, step 35161, time: 204.07330083847046 s, accu: 0.8522526621818542, loss_yt: 0.4123147130012512\n",
      "epocht 0, batch_num 5600, step 35361, time: 212.04199409484863 s, accu: 0.852274477481842, loss_yt: 0.2725083827972412\n",
      "epocht 0, batch_num 5800, step 35561, time: 219.58983492851257 s, accu: 0.8522721529006958, loss_yt: 0.32503458857536316\n",
      "epocht 0, batch_num 6000, step 35761, time: 227.00102472305298 s, accu: 0.852295994758606, loss_yt: 0.39104074239730835\n",
      "epocht 0, batch_num 6200, step 35961, time: 234.61266899108887 s, accu: 0.8522982001304626, loss_yt: 0.28161782026290894\n",
      "epocht 0, batch_num 6400, step 36161, time: 242.1454954147339 s, accu: 0.8523238897323608, loss_yt: 0.2494301199913025\n",
      "epocht 0, batch_num 6600, step 36361, time: 249.71129703521729 s, accu: 0.8523603081703186, loss_yt: 0.10836352407932281\n",
      "epocht 0, batch_num 6800, step 36561, time: 257.34189796447754 s, accu: 0.8523866534233093, loss_yt: 0.13915389776229858\n",
      "epocht 0, batch_num 7000, step 36761, time: 265.03230142593384 s, accu: 0.8524000644683838, loss_yt: 0.4129093587398529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 0, batch_num 7200, step 36961, time: 272.55318427085876 s, accu: 0.852409839630127, loss_yt: 0.35412105917930603\n",
      "epocht 0, batch_num 7400, step 37161, time: 280.1588795185089 s, accu: 0.852426290512085, loss_yt: 0.2678402364253998\n",
      "iter_validnum 1860\n",
      "epochv 0, step 37200, stop_n 0, time: 333.6348509788513 s, accu_va: 0.8522295066105422, loss_yv: 0.3281840598531148\n",
      "iter_trainnum 7440\n",
      "epocht 1, batch_num 0, step 37201, time: 0.31616711616516113 s, accu: 0.8519389629364014, loss_yt: 0.20100855827331543\n",
      "epocht 1, batch_num 200, step 37401, time: 7.79217529296875 s, accu: 0.8519799709320068, loss_yt: 0.15820613503456116\n",
      "epocht 1, batch_num 400, step 37601, time: 15.519510746002197 s, accu: 0.8519885540008545, loss_yt: 0.20871752500534058\n",
      "epocht 1, batch_num 600, step 37801, time: 23.076273202896118 s, accu: 0.8519834280014038, loss_yt: 0.3163989186286926\n",
      "epocht 1, batch_num 800, step 38001, time: 30.60115623474121 s, accu: 0.8520246148109436, loss_yt: 0.399379700422287\n",
      "epocht 1, batch_num 1000, step 38201, time: 38.03327703475952 s, accu: 0.8520451784133911, loss_yt: 0.28679996728897095\n",
      "epocht 1, batch_num 1200, step 38401, time: 45.581095457077026 s, accu: 0.8520815372467041, loss_yt: 0.23524361848831177\n",
      "epocht 1, batch_num 1400, step 38601, time: 53.24559950828552 s, accu: 0.8521305322647095, loss_yt: 0.13504350185394287\n",
      "epocht 1, batch_num 1600, step 38801, time: 60.631848096847534 s, accu: 0.8521842956542969, loss_yt: 0.2632441520690918\n",
      "epocht 1, batch_num 1800, step 39001, time: 68.27443981170654 s, accu: 0.8522043824195862, loss_yt: 0.3272225856781006\n",
      "epocht 1, batch_num 2000, step 39201, time: 75.66066122055054 s, accu: 0.8522305488586426, loss_yt: 0.2567142844200134\n",
      "epocht 1, batch_num 2200, step 39401, time: 83.30523180961609 s, accu: 0.8522694706916809, loss_yt: 0.41102510690689087\n",
      "epocht 1, batch_num 2400, step 39601, time: 90.86301016807556 s, accu: 0.8522962927818298, loss_yt: 0.29861390590667725\n",
      "epocht 1, batch_num 2600, step 39801, time: 98.35198664665222 s, accu: 0.8523414134979248, loss_yt: 0.3584722876548767\n",
      "epocht 1, batch_num 2800, step 40001, time: 105.94171571731567 s, accu: 0.8523755073547363, loss_yt: 0.21348929405212402\n",
      "epocht 1, batch_num 3000, step 40201, time: 113.19230151176453 s, accu: 0.8524051308631897, loss_yt: 0.3665570020675659\n",
      "epocht 1, batch_num 3200, step 40401, time: 121.0463011264801 s, accu: 0.852446973323822, loss_yt: 0.28902962803840637\n",
      "epocht 1, batch_num 3400, step 40601, time: 128.4784631729126 s, accu: 0.8524747490882874, loss_yt: 0.6140442490577698\n",
      "epocht 1, batch_num 3600, step 40801, time: 136.15592074394226 s, accu: 0.8524938225746155, loss_yt: 0.319429874420166\n",
      "epocht 1, batch_num 3800, step 41001, time: 143.72468996047974 s, accu: 0.8525165319442749, loss_yt: 0.3111357092857361\n",
      "epocht 1, batch_num 4000, step 41201, time: 151.1847083568573 s, accu: 0.8525489568710327, loss_yt: 0.16275356709957123\n",
      "epocht 1, batch_num 4200, step 41401, time: 158.8143389225006 s, accu: 0.8525647521018982, loss_yt: 0.330322802066803\n",
      "epocht 1, batch_num 4400, step 41601, time: 166.31827354431152 s, accu: 0.8525910973548889, loss_yt: 0.5502347350120544\n",
      "epocht 1, batch_num 4600, step 41801, time: 173.84813928604126 s, accu: 0.8526592254638672, loss_yt: 0.2455151081085205\n",
      "epocht 1, batch_num 4800, step 42001, time: 181.35005950927734 s, accu: 0.8526790142059326, loss_yt: 0.3651646673679352\n",
      "epocht 1, batch_num 5000, step 42201, time: 188.91185021400452 s, accu: 0.8527185320854187, loss_yt: 0.2609999179840088\n",
      "epocht 1, batch_num 5200, step 42401, time: 196.28112030029297 s, accu: 0.8527650833129883, loss_yt: 0.3496257960796356\n",
      "epocht 1, batch_num 5400, step 42601, time: 203.659414768219 s, accu: 0.8527975678443909, loss_yt: 0.29120224714279175\n",
      "epocht 1, batch_num 5600, step 42801, time: 211.0456383228302 s, accu: 0.852821946144104, loss_yt: 0.4514085054397583\n",
      "epocht 1, batch_num 5800, step 43001, time: 218.53461456298828 s, accu: 0.852858304977417, loss_yt: 0.18427960574626923\n",
      "epocht 1, batch_num 6000, step 43201, time: 226.18818426132202 s, accu: 0.8528679609298706, loss_yt: 0.24785947799682617\n",
      "epocht 1, batch_num 6200, step 43401, time: 233.74095034599304 s, accu: 0.8529026508331299, loss_yt: 0.3191605806350708\n",
      "epocht 1, batch_num 6400, step 43601, time: 241.35658717155457 s, accu: 0.8529341220855713, loss_yt: 0.12857379019260406\n",
      "epocht 1, batch_num 6600, step 43801, time: 248.97322034835815 s, accu: 0.8529660105705261, loss_yt: 0.31452637910842896\n",
      "epocht 1, batch_num 6800, step 44001, time: 256.49410915374756 s, accu: 0.8529801368713379, loss_yt: 0.1192273199558258\n",
      "epocht 1, batch_num 7000, step 44201, time: 263.955157995224 s, accu: 0.8530281782150269, loss_yt: 0.35875195264816284\n",
      "epocht 1, batch_num 7200, step 44401, time: 271.39825558662415 s, accu: 0.8530511856079102, loss_yt: 0.2801627218723297\n",
      "epocht 1, batch_num 7400, step 44601, time: 278.8473355770111 s, accu: 0.8531049489974976, loss_yt: 0.1102602630853653\n",
      "iter_validnum 1860\n",
      "epochv 1, step 44640, stop_n 0, time: 332.8070466518402 s, accu_va: 0.8532548456422744, loss_yv: 0.30419681888193856\n",
      "iter_trainnum 7440\n",
      "epocht 1, batch_num 0, step 44641, time: 0.22140789031982422 s, accu: 0.8533643484115601, loss_yt: 0.4435727596282959\n",
      "epocht 1, batch_num 200, step 44841, time: 7.7343504428863525 s, accu: 0.8533798456192017, loss_yt: 0.2625879943370819\n",
      "epocht 1, batch_num 400, step 45041, time: 15.431735038757324 s, accu: 0.8534062504768372, loss_yt: 0.3249916732311249\n",
      "epocht 1, batch_num 600, step 45241, time: 22.843915224075317 s, accu: 0.8534423112869263, loss_yt: 0.2575046122074127\n",
      "epocht 1, batch_num 800, step 45441, time: 30.42863178253174 s, accu: 0.8534600734710693, loss_yt: 0.3264255225658417\n",
      "epocht 1, batch_num 1000, step 45641, time: 37.87075757980347 s, accu: 0.8534886240959167, loss_yt: 0.30806633830070496\n",
      "epocht 1, batch_num 1200, step 45841, time: 45.42453455924988 s, accu: 0.8535258769989014, loss_yt: 0.74442058801651\n",
      "epocht 1, batch_num 1400, step 46041, time: 53.06712365150452 s, accu: 0.8535647988319397, loss_yt: 0.4617297649383545\n",
      "epocht 1, batch_num 1600, step 46241, time: 60.7854585647583 s, accu: 0.8536073565483093, loss_yt: 0.24933265149593353\n",
      "epocht 1, batch_num 1800, step 46441, time: 68.19866800308228 s, accu: 0.8536321520805359, loss_yt: 0.48069754242897034\n",
      "epocht 1, batch_num 2000, step 46641, time: 75.91699552536011 s, accu: 0.853649377822876, loss_yt: 0.3580392301082611\n",
      "epocht 1, batch_num 2200, step 46841, time: 83.59449791908264 s, accu: 0.8536733984947205, loss_yt: 0.25644880533218384\n",
      "epocht 1, batch_num 2400, step 47041, time: 91.12533402442932 s, accu: 0.8537123799324036, loss_yt: 0.4506736993789673\n",
      "epocht 1, batch_num 2600, step 47241, time: 98.63627648353577 s, accu: 0.8537466526031494, loss_yt: 0.16234703361988068\n",
      "epocht 1, batch_num 2800, step 47441, time: 106.0145149230957 s, accu: 0.8537768125534058, loss_yt: 0.21998251974582672\n",
      "epocht 1, batch_num 3000, step 47641, time: 113.55638027191162 s, accu: 0.8537720441818237, loss_yt: 0.20288315415382385\n",
      "epocht 1, batch_num 3200, step 47841, time: 121.07427644729614 s, accu: 0.8537828922271729, loss_yt: 0.08346983790397644\n",
      "epocht 1, batch_num 3400, step 48041, time: 128.78864812850952 s, accu: 0.853801965713501, loss_yt: 0.38884398341178894\n",
      "epocht 1, batch_num 3600, step 48241, time: 136.37233805656433 s, accu: 0.8538281917572021, loss_yt: 0.2321828007698059\n",
      "epocht 1, batch_num 3800, step 48441, time: 144.00097060203552 s, accu: 0.8538657426834106, loss_yt: 0.2993195354938507\n",
      "epocht 1, batch_num 4000, step 48641, time: 151.7313196659088 s, accu: 0.8538973331451416, loss_yt: 0.22863683104515076\n",
      "epocht 1, batch_num 4200, step 48841, time: 159.09557485580444 s, accu: 0.8539383411407471, loss_yt: 0.47754091024398804\n",
      "epocht 1, batch_num 4400, step 49041, time: 166.45093941688538 s, accu: 0.8539730310440063, loss_yt: 0.2654944360256195\n",
      "epocht 1, batch_num 4600, step 49241, time: 174.04363560676575 s, accu: 0.8540066480636597, loss_yt: 0.46798402070999146\n",
      "epocht 1, batch_num 4800, step 49441, time: 181.58543705940247 s, accu: 0.8540278077125549, loss_yt: 0.32313036918640137\n",
      "epocht 1, batch_num 5000, step 49641, time: 189.01955819129944 s, accu: 0.8540340662002563, loss_yt: 0.5222949981689453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 1, batch_num 5200, step 49841, time: 196.50557160377502 s, accu: 0.854060709476471, loss_yt: 0.6710466742515564\n",
      "epocht 1, batch_num 5400, step 50041, time: 204.2508363723755 s, accu: 0.8540775179862976, loss_yt: 0.46258479356765747\n",
      "epocht 1, batch_num 5600, step 50241, time: 211.71387362480164 s, accu: 0.8541157245635986, loss_yt: 0.2503279149532318\n",
      "epocht 1, batch_num 5800, step 50441, time: 219.12605214118958 s, accu: 0.8541485071182251, loss_yt: 0.3085162937641144\n",
      "epocht 1, batch_num 6000, step 50641, time: 226.6499330997467 s, accu: 0.8541585206985474, loss_yt: 0.38837283849716187\n",
      "epocht 1, batch_num 6200, step 50841, time: 234.10503029823303 s, accu: 0.8542103171348572, loss_yt: 0.2951407730579376\n",
      "epocht 1, batch_num 6400, step 51041, time: 241.82734870910645 s, accu: 0.8542119860649109, loss_yt: 0.3401823341846466\n",
      "epocht 1, batch_num 6600, step 51241, time: 249.26446056365967 s, accu: 0.8542420864105225, loss_yt: 0.23706597089767456\n",
      "epocht 1, batch_num 6800, step 51441, time: 257.1164655685425 s, accu: 0.8542706370353699, loss_yt: 0.4284306764602661\n",
      "epocht 1, batch_num 7000, step 51641, time: 264.60743284225464 s, accu: 0.854316771030426, loss_yt: 0.2778085470199585\n",
      "epocht 1, batch_num 7200, step 51841, time: 272.26299500465393 s, accu: 0.8543468713760376, loss_yt: 0.25775688886642456\n",
      "epocht 1, batch_num 7400, step 52041, time: 279.8795952796936 s, accu: 0.8543524146080017, loss_yt: 0.43790099024772644\n",
      "iter_validnum 1860\n",
      "epochv 1, step 52080, stop_n 0, time: 333.5331242084503 s, accu_va: 0.8544631529238916, loss_yv: 0.30833736493863084\n",
      "iter_trainnum 7440\n",
      "epocht 1, batch_num 0, step 52081, time: 0.22240567207336426 s, accu: 0.8545630574226379, loss_yt: 0.3054109811782837\n",
      "epocht 1, batch_num 200, step 52281, time: 8.18212103843689 s, accu: 0.8545657992362976, loss_yt: 0.5244648456573486\n",
      "epocht 1, batch_num 400, step 52481, time: 15.718968629837036 s, accu: 0.8545942902565002, loss_yt: 0.4288731813430786\n",
      "epocht 1, batch_num 600, step 52681, time: 23.19597339630127 s, accu: 0.8546134233474731, loss_yt: 0.2775678336620331\n",
      "epocht 1, batch_num 800, step 52881, time: 30.582223653793335 s, accu: 0.8546270132064819, loss_yt: 0.2535872161388397\n",
      "epocht 1, batch_num 1000, step 53081, time: 38.363415002822876 s, accu: 0.8546683192253113, loss_yt: 0.2956373989582062\n",
      "epocht 1, batch_num 1200, step 53281, time: 45.778754234313965 s, accu: 0.8546886444091797, loss_yt: 0.19988462328910828\n",
      "epocht 1, batch_num 1400, step 53481, time: 53.284685134887695 s, accu: 0.8547217845916748, loss_yt: 0.22522860765457153\n",
      "epocht 1, batch_num 1600, step 53681, time: 60.69290828704834 s, accu: 0.8547390103340149, loss_yt: 0.363025039434433\n",
      "epocht 1, batch_num 1800, step 53881, time: 68.21176934242249 s, accu: 0.8547796010971069, loss_yt: 0.3983931541442871\n",
      "epocht 1, batch_num 2000, step 54081, time: 75.96304154396057 s, accu: 0.8547797799110413, loss_yt: 0.22393783926963806\n",
      "epocht 1, batch_num 2200, step 54281, time: 83.50487446784973 s, accu: 0.8547996282577515, loss_yt: 0.2807918190956116\n",
      "epocht 1, batch_num 2400, step 54481, time: 91.33095026016235 s, accu: 0.85481858253479, loss_yt: 0.30568498373031616\n",
      "epocht 1, batch_num 2600, step 54681, time: 98.84884452819824 s, accu: 0.8548377156257629, loss_yt: 0.24734704196453094\n",
      "epocht 1, batch_num 2800, step 54881, time: 106.36574482917786 s, accu: 0.8548570871353149, loss_yt: 0.3375304043292999\n",
      "epocht 1, batch_num 3000, step 55081, time: 114.1310043334961 s, accu: 0.8548704385757446, loss_yt: 0.1367267519235611\n",
      "epocht 1, batch_num 3200, step 55281, time: 121.63890194892883 s, accu: 0.8548954725265503, loss_yt: 0.22134466469287872\n",
      "epocht 1, batch_num 3400, step 55481, time: 129.07801127433777 s, accu: 0.8549283742904663, loss_yt: 0.2713669538497925\n",
      "epocht 1, batch_num 3600, step 55681, time: 136.41243052482605 s, accu: 0.8549511432647705, loss_yt: 0.2504189610481262\n",
      "epocht 1, batch_num 3800, step 55881, time: 143.8575258255005 s, accu: 0.854971170425415, loss_yt: 0.15267802774906158\n",
      "epocht 1, batch_num 4000, step 56081, time: 151.57186245918274 s, accu: 0.8549644351005554, loss_yt: 0.27975884079933167\n",
      "epocht 1, batch_num 4200, step 56281, time: 159.21243238449097 s, accu: 0.8549790978431702, loss_yt: 0.2599254250526428\n",
      "epocht 1, batch_num 4400, step 56481, time: 166.6914632320404 s, accu: 0.8549916744232178, loss_yt: 0.30245348811149597\n",
      "epocht 1, batch_num 4600, step 56681, time: 174.30307698249817 s, accu: 0.8550102114677429, loss_yt: 0.2535068988800049\n",
      "epocht 1, batch_num 4800, step 56881, time: 181.90477800369263 s, accu: 0.8550077676773071, loss_yt: 0.276895672082901\n",
      "epocht 1, batch_num 5000, step 57081, time: 189.54531955718994 s, accu: 0.855021059513092, loss_yt: 0.19613023102283478\n",
      "epocht 1, batch_num 5200, step 57281, time: 197.09114241600037 s, accu: 0.8550308346748352, loss_yt: 0.5260411500930786\n",
      "epocht 1, batch_num 5400, step 57481, time: 204.64696717262268 s, accu: 0.8550358414649963, loss_yt: 0.13986974954605103\n",
      "epocht 1, batch_num 5600, step 57681, time: 212.26162242889404 s, accu: 0.8550447225570679, loss_yt: 0.42358845472335815\n",
      "epocht 1, batch_num 5800, step 57881, time: 219.59299659729004 s, accu: 0.8550624251365662, loss_yt: 0.3029167354106903\n",
      "epocht 1, batch_num 6000, step 58081, time: 227.2744300365448 s, accu: 0.8550708293914795, loss_yt: 0.27802959084510803\n",
      "epocht 1, batch_num 6200, step 58281, time: 234.60383343696594 s, accu: 0.8550809621810913, loss_yt: 0.38968807458877563\n",
      "epocht 1, batch_num 6400, step 58481, time: 242.23343110084534 s, accu: 0.8550880551338196, loss_yt: 0.294462651014328\n",
      "epocht 1, batch_num 6600, step 58681, time: 249.87898659706116 s, accu: 0.8551169037818909, loss_yt: 0.24239131808280945\n",
      "epocht 1, batch_num 6800, step 58881, time: 257.4258096218109 s, accu: 0.8551351428031921, loss_yt: 0.4019215703010559\n",
      "epocht 1, batch_num 7000, step 59081, time: 264.87289214134216 s, accu: 0.8551337718963623, loss_yt: 0.26574164628982544\n",
      "epocht 1, batch_num 7200, step 59281, time: 272.42968559265137 s, accu: 0.8551498651504517, loss_yt: 0.2415405809879303\n",
      "epocht 1, batch_num 7400, step 59481, time: 280.0373694896698 s, accu: 0.8551726341247559, loss_yt: 0.366346538066864\n",
      "iter_validnum 1860\n",
      "epochv 1, step 59520, stop_n 1, time: 334.0309624671936 s, accu_va: 0.8552703731803484, loss_yv: 0.3025260976085099\n",
      "iter_trainnum 7440\n",
      "epocht 1, batch_num 0, step 59521, time: 0.3430824279785156 s, accu: 0.855378270149231, loss_yt: 0.2969982624053955\n",
      "epocht 1, batch_num 200, step 59721, time: 8.23996615409851 s, accu: 0.8553846478462219, loss_yt: 0.6438317894935608\n",
      "epocht 1, batch_num 400, step 59921, time: 15.655171871185303 s, accu: 0.8554057478904724, loss_yt: 0.33286088705062866\n",
      "epocht 1, batch_num 600, step 60121, time: 23.18300771713257 s, accu: 0.8554242253303528, loss_yt: 0.2887585461139679\n",
      "epocht 1, batch_num 800, step 60321, time: 30.804659128189087 s, accu: 0.8554494380950928, loss_yt: 0.22336383163928986\n",
      "epocht 1, batch_num 1000, step 60521, time: 38.24674916267395 s, accu: 0.8554693460464478, loss_yt: 0.5879632234573364\n",
      "epocht 1, batch_num 1200, step 60721, time: 45.74268627166748 s, accu: 0.8554881811141968, loss_yt: 0.48274508118629456\n",
      "epocht 1, batch_num 1400, step 60921, time: 53.16686010360718 s, accu: 0.8555100560188293, loss_yt: 0.324323832988739\n",
      "epocht 1, batch_num 1600, step 61121, time: 60.544137716293335 s, accu: 0.8555304408073425, loss_yt: 0.253525048494339\n",
      "epocht 1, batch_num 1800, step 61321, time: 68.33028149604797 s, accu: 0.8555570840835571, loss_yt: 0.530331015586853\n",
      "epocht 1, batch_num 2000, step 61521, time: 75.90305185317993 s, accu: 0.8555663824081421, loss_yt: 0.17931661009788513\n",
      "epocht 1, batch_num 2200, step 61721, time: 83.48777532577515 s, accu: 0.8555774092674255, loss_yt: 0.5671539902687073\n",
      "epocht 1, batch_num 2400, step 61921, time: 91.1014187335968 s, accu: 0.855583906173706, loss_yt: 0.32875120639801025\n",
      "epocht 1, batch_num 2600, step 62121, time: 98.61134195327759 s, accu: 0.8556081056594849, loss_yt: 0.21554258465766907\n",
      "epocht 1, batch_num 2800, step 62321, time: 106.59595847129822 s, accu: 0.8556166887283325, loss_yt: 0.2284637838602066\n",
      "epocht 1, batch_num 3000, step 62521, time: 114.24751162528992 s, accu: 0.8556332588195801, loss_yt: 0.27651792764663696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 1, batch_num 3200, step 62721, time: 121.92995500564575 s, accu: 0.8556221127510071, loss_yt: 0.4338122010231018\n",
      "epocht 1, batch_num 3400, step 62921, time: 129.41596937179565 s, accu: 0.8556268215179443, loss_yt: 0.24422354996204376\n",
      "epocht 1, batch_num 3600, step 63121, time: 137.14626789093018 s, accu: 0.8556545972824097, loss_yt: 0.3312474489212036\n",
      "epocht 1, batch_num 3800, step 63321, time: 144.66914916038513 s, accu: 0.8556568026542664, loss_yt: 0.18909481167793274\n",
      "epocht 1, batch_num 4000, step 63521, time: 152.02248811721802 s, accu: 0.8556792736053467, loss_yt: 0.30557990074157715\n",
      "epocht 1, batch_num 4200, step 63721, time: 159.50850248336792 s, accu: 0.8556860089302063, loss_yt: 0.2574862241744995\n",
      "epocht 1, batch_num 4400, step 63921, time: 166.98048996925354 s, accu: 0.8557108640670776, loss_yt: 0.3485049903392792\n",
      "epocht 1, batch_num 4600, step 64121, time: 174.3896770477295 s, accu: 0.8557484149932861, loss_yt: 0.23350709676742554\n",
      "epocht 1, batch_num 4800, step 64321, time: 181.96841144561768 s, accu: 0.8557618260383606, loss_yt: 0.45070770382881165\n",
      "epocht 1, batch_num 5000, step 64521, time: 189.54219150543213 s, accu: 0.8557792901992798, loss_yt: 0.3627789318561554\n",
      "epocht 1, batch_num 5200, step 64721, time: 197.16781091690063 s, accu: 0.8557902574539185, loss_yt: 0.28659552335739136\n",
      "epocht 1, batch_num 5400, step 64921, time: 204.65175652503967 s, accu: 0.8557945489883423, loss_yt: 0.37944096326828003\n",
      "epocht 1, batch_num 5600, step 65121, time: 212.19162511825562 s, accu: 0.8558233976364136, loss_yt: 0.23546242713928223\n",
      "epocht 1, batch_num 5800, step 65321, time: 219.56188917160034 s, accu: 0.8558284640312195, loss_yt: 0.33805203437805176\n",
      "epocht 1, batch_num 6000, step 65521, time: 227.00498175621033 s, accu: 0.8558432459831238, loss_yt: 0.30974283814430237\n",
      "epocht 1, batch_num 6200, step 65721, time: 234.61363792419434 s, accu: 0.8558411598205566, loss_yt: 0.3567274510860443\n",
      "epocht 1, batch_num 6400, step 65921, time: 242.443701505661 s, accu: 0.8558464050292969, loss_yt: 0.3206084966659546\n",
      "epocht 1, batch_num 6600, step 66121, time: 250.04238152503967 s, accu: 0.8558602333068848, loss_yt: 0.41158217191696167\n",
      "epocht 1, batch_num 6800, step 66321, time: 257.5722727775574 s, accu: 0.8558648228645325, loss_yt: 0.1785316914319992\n",
      "epocht 1, batch_num 7000, step 66521, time: 264.9774444103241 s, accu: 0.8558844327926636, loss_yt: 0.22563549876213074\n",
      "epocht 1, batch_num 7200, step 66721, time: 272.6549143791199 s, accu: 0.8559116125106812, loss_yt: 0.12406645715236664\n",
      "epocht 1, batch_num 7400, step 66921, time: 280.1878080368042 s, accu: 0.8559378981590271, loss_yt: 0.27596479654312134\n",
      "iter_validnum 1860\n",
      "epochv 1, step 66960, stop_n 0, time: 334.1983458995819 s, accu_va: 0.856000595195319, loss_yv: 0.3038846810939171\n",
      "iter_trainnum 7440\n",
      "epocht 1, batch_num 0, step 66961, time: 0.22140812873840332 s, accu: 0.8560759425163269, loss_yt: 0.2899130582809448\n",
      "epocht 1, batch_num 200, step 67161, time: 8.269885301589966 s, accu: 0.8560943603515625, loss_yt: 0.4811609387397766\n",
      "epocht 1, batch_num 400, step 67361, time: 15.906463384628296 s, accu: 0.8561099171638489, loss_yt: 0.3071364164352417\n",
      "epocht 1, batch_num 600, step 67561, time: 23.344576835632324 s, accu: 0.8561400175094604, loss_yt: 0.31581008434295654\n",
      "epocht 1, batch_num 800, step 67761, time: 30.945253133773804 s, accu: 0.8561546206474304, loss_yt: 0.3827425241470337\n",
      "epocht 1, batch_num 1000, step 67961, time: 38.52302050590515 s, accu: 0.8561601042747498, loss_yt: 0.439178466796875\n",
      "epocht 1, batch_num 1200, step 68161, time: 46.540550231933594 s, accu: 0.8561646938323975, loss_yt: 0.14689688384532928\n",
      "epocht 1, batch_num 1400, step 68361, time: 54.07939100265503 s, accu: 0.8561758995056152, loss_yt: 0.13690949976444244\n",
      "epocht 1, batch_num 1600, step 68561, time: 61.68807625770569 s, accu: 0.8561819195747375, loss_yt: 0.21924172341823578\n",
      "epocht 1, batch_num 1800, step 68761, time: 69.11222863197327 s, accu: 0.8561944365501404, loss_yt: 0.3688190281391144\n",
      "epocht 1, batch_num 2000, step 68961, time: 76.61815667152405 s, accu: 0.8561953902244568, loss_yt: 0.3060314953327179\n",
      "epocht 1, batch_num 2200, step 69161, time: 84.15300488471985 s, accu: 0.8562100529670715, loss_yt: 0.20794925093650818\n",
      "epocht 1, batch_num 2400, step 69361, time: 91.58310341835022 s, accu: 0.8562217354774475, loss_yt: 0.39325860142707825\n",
      "epocht 1, batch_num 2600, step 69561, time: 99.7163565158844 s, accu: 0.8562153577804565, loss_yt: 0.3606193959712982\n",
      "epocht 1, batch_num 2800, step 69761, time: 107.380859375 s, accu: 0.8562121987342834, loss_yt: 0.26270952820777893\n",
      "epocht 1, batch_num 3000, step 69961, time: 115.2837553024292 s, accu: 0.8562173843383789, loss_yt: 0.15140892565250397\n",
      "epocht 1, batch_num 3200, step 70161, time: 122.82058000564575 s, accu: 0.8562271595001221, loss_yt: 0.38674837350845337\n",
      "epocht 1, batch_num 3400, step 70361, time: 130.44120979309082 s, accu: 0.8562366366386414, loss_yt: 0.32755836844444275\n",
      "epocht 1, batch_num 3600, step 70561, time: 137.86634230613708 s, accu: 0.8562560081481934, loss_yt: 0.3800792396068573\n",
      "epocht 1, batch_num 3800, step 70761, time: 145.32040929794312 s, accu: 0.8562670946121216, loss_yt: 0.4897291660308838\n",
      "epocht 1, batch_num 4000, step 70961, time: 152.83930468559265 s, accu: 0.8562836647033691, loss_yt: 0.29016298055648804\n",
      "epocht 1, batch_num 4200, step 71161, time: 160.35919618606567 s, accu: 0.8562955260276794, loss_yt: 0.251620888710022\n",
      "epocht 1, batch_num 4400, step 71361, time: 168.0636248588562 s, accu: 0.8563065528869629, loss_yt: 0.4457264840602875\n",
      "epocht 1, batch_num 4600, step 71561, time: 175.58951592445374 s, accu: 0.8563181757926941, loss_yt: 0.2158409059047699\n",
      "epocht 1, batch_num 4800, step 71761, time: 183.1512496471405 s, accu: 0.8563429713249207, loss_yt: 0.386599063873291\n",
      "epocht 1, batch_num 5000, step 71961, time: 190.76987671852112 s, accu: 0.8563607931137085, loss_yt: 0.2932385206222534\n",
      "epocht 1, batch_num 5200, step 72161, time: 198.37454223632812 s, accu: 0.856369137763977, loss_yt: 0.2614324390888214\n",
      "epocht 1, batch_num 5400, step 72361, time: 205.8774778842926 s, accu: 0.8563816547393799, loss_yt: 0.272805392742157\n",
      "epocht 1, batch_num 5600, step 72561, time: 213.3215720653534 s, accu: 0.8563929200172424, loss_yt: 0.23331138491630554\n",
      "epocht 1, batch_num 5800, step 72761, time: 220.7566921710968 s, accu: 0.8564090728759766, loss_yt: 0.26928454637527466\n",
      "epocht 1, batch_num 6000, step 72961, time: 228.5019805431366 s, accu: 0.8564183712005615, loss_yt: 0.26897579431533813\n",
      "epocht 1, batch_num 6200, step 73161, time: 236.00292205810547 s, accu: 0.8564287424087524, loss_yt: 0.15203502774238586\n",
      "epocht 1, batch_num 6400, step 73361, time: 243.59864044189453 s, accu: 0.8564529418945312, loss_yt: 0.3514486849308014\n",
      "epocht 1, batch_num 6600, step 73561, time: 251.13548946380615 s, accu: 0.8564587235450745, loss_yt: 0.13396188616752625\n",
      "epocht 1, batch_num 6800, step 73761, time: 258.9455726146698 s, accu: 0.8564648628234863, loss_yt: 0.291658490896225\n",
      "epocht 1, batch_num 7000, step 73961, time: 266.57420206069946 s, accu: 0.8564776182174683, loss_yt: 0.3352953791618347\n",
      "epocht 1, batch_num 7200, step 74161, time: 273.8836534023285 s, accu: 0.8564974069595337, loss_yt: 0.23712758719921112\n",
      "epocht 1, batch_num 7400, step 74361, time: 281.6388921737671 s, accu: 0.8565106391906738, loss_yt: 0.35298147797584534\n",
      "iter_validnum 1860\n",
      "epochv 1, step 74400, stop_n 1, time: 335.2236042022705 s, accu_va: 0.8565674188316509, loss_yv: 0.30270340495332276\n",
      "iter_trainnum 7440\n",
      "epocht 2, batch_num 0, step 74401, time: 0.5076732635498047 s, accu: 0.8566277027130127, loss_yt: 0.5847662687301636\n",
      "epocht 2, batch_num 200, step 74601, time: 8.146214485168457 s, accu: 0.8566356897354126, loss_yt: 0.24459010362625122\n",
      "epocht 2, batch_num 400, step 74801, time: 15.710021495819092 s, accu: 0.8566598892211914, loss_yt: 0.26010942459106445\n",
      "epocht 2, batch_num 600, step 75001, time: 23.095242261886597 s, accu: 0.8566800951957703, loss_yt: 0.44991379976272583\n",
      "epocht 2, batch_num 800, step 75201, time: 30.80763292312622 s, accu: 0.8567045331001282, loss_yt: 0.384389191865921\n",
      "epocht 2, batch_num 1000, step 75401, time: 38.229771852493286 s, accu: 0.8567403554916382, loss_yt: 0.18228864669799805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 2, batch_num 1200, step 75601, time: 45.950127363204956 s, accu: 0.8567526340484619, loss_yt: 0.5438618659973145\n",
      "epocht 2, batch_num 1400, step 75801, time: 53.48600769042969 s, accu: 0.856782078742981, loss_yt: 0.3040422797203064\n",
      "epocht 2, batch_num 1600, step 76001, time: 61.03881216049194 s, accu: 0.8567885160446167, loss_yt: 0.288636714220047\n",
      "epocht 2, batch_num 1800, step 76201, time: 68.50783181190491 s, accu: 0.8568176031112671, loss_yt: 0.35128259658813477\n",
      "epocht 2, batch_num 2000, step 76401, time: 76.20622301101685 s, accu: 0.856822669506073, loss_yt: 0.2642330229282379\n",
      "epocht 2, batch_num 2200, step 76601, time: 83.70121145248413 s, accu: 0.8568430542945862, loss_yt: 0.48040345311164856\n",
      "epocht 2, batch_num 2400, step 76801, time: 91.22207570075989 s, accu: 0.8568667769432068, loss_yt: 0.435722678899765\n",
      "epocht 2, batch_num 2600, step 77001, time: 98.78088808059692 s, accu: 0.8568827509880066, loss_yt: 0.3284633159637451\n",
      "epocht 2, batch_num 2800, step 77201, time: 106.30975604057312 s, accu: 0.8568954467773438, loss_yt: 0.40991461277008057\n",
      "epocht 2, batch_num 3000, step 77401, time: 114.10089039802551 s, accu: 0.856903612613678, loss_yt: 0.17609372735023499\n",
      "epocht 2, batch_num 3200, step 77601, time: 121.89208841323853 s, accu: 0.8569039106369019, loss_yt: 0.23787571489810944\n",
      "epocht 2, batch_num 3400, step 77801, time: 129.50370240211487 s, accu: 0.8569310903549194, loss_yt: 0.33688095211982727\n",
      "epocht 2, batch_num 3600, step 78001, time: 136.98772311210632 s, accu: 0.8569503426551819, loss_yt: 0.17315100133419037\n",
      "epocht 2, batch_num 3800, step 78201, time: 144.61828589439392 s, accu: 0.8569523096084595, loss_yt: 0.34841495752334595\n",
      "epocht 2, batch_num 4000, step 78401, time: 152.06237959861755 s, accu: 0.8569633364677429, loss_yt: 0.28731125593185425\n",
      "epocht 2, batch_num 4200, step 78601, time: 159.60022950172424 s, accu: 0.8569751977920532, loss_yt: 0.3303506076335907\n",
      "epocht 2, batch_num 4400, step 78801, time: 167.1111719608307 s, accu: 0.8569856882095337, loss_yt: 0.3196081817150116\n",
      "epocht 2, batch_num 4600, step 79001, time: 174.5193305015564 s, accu: 0.8569988012313843, loss_yt: 0.3960828185081482\n",
      "epocht 2, batch_num 4800, step 79201, time: 182.01830983161926 s, accu: 0.8570058941841125, loss_yt: 0.3825613260269165\n",
      "epocht 2, batch_num 5000, step 79401, time: 189.73467540740967 s, accu: 0.8570054173469543, loss_yt: 0.25029274821281433\n",
      "epocht 2, batch_num 5200, step 79601, time: 197.34329915046692 s, accu: 0.8570275902748108, loss_yt: 0.4824075400829315\n",
      "epocht 2, batch_num 5400, step 79801, time: 205.0656499862671 s, accu: 0.8570343852043152, loss_yt: 0.3238632380962372\n",
      "epocht 2, batch_num 5600, step 80001, time: 212.59551429748535 s, accu: 0.8570486307144165, loss_yt: 0.34675148129463196\n",
      "epocht 2, batch_num 5800, step 80201, time: 220.17025899887085 s, accu: 0.8570560216903687, loss_yt: 0.2161586433649063\n",
      "epocht 2, batch_num 6000, step 80401, time: 227.77791500091553 s, accu: 0.8570592403411865, loss_yt: 0.1845754086971283\n",
      "epocht 2, batch_num 6200, step 80601, time: 235.18912935256958 s, accu: 0.8570803999900818, loss_yt: 0.23999236524105072\n",
      "epocht 2, batch_num 6400, step 80801, time: 242.4746162891388 s, accu: 0.8570964932441711, loss_yt: 0.1605713665485382\n",
      "epocht 2, batch_num 6600, step 81001, time: 250.13413310050964 s, accu: 0.8571162223815918, loss_yt: 0.11284459382295609\n",
      "epocht 2, batch_num 6800, step 81201, time: 257.6649980545044 s, accu: 0.857133686542511, loss_yt: 0.16015784442424774\n",
      "epocht 2, batch_num 7000, step 81401, time: 265.1868839263916 s, accu: 0.8571405410766602, loss_yt: 0.3200457692146301\n",
      "epocht 2, batch_num 7200, step 81601, time: 272.93619894981384 s, accu: 0.8571496605873108, loss_yt: 0.3593035340309143\n",
      "epocht 2, batch_num 7400, step 81801, time: 280.41416454315186 s, accu: 0.857154369354248, loss_yt: 0.30769214034080505\n",
      "iter_validnum 1860\n",
      "epochv 2, step 81840, stop_n 0, time: 334.16346287727356 s, accu_va: 0.8572141770714072, loss_yv: 0.3023915245888695\n",
      "iter_trainnum 7440\n",
      "epocht 2, batch_num 0, step 81841, time: 0.38993120193481445 s, accu: 0.8572653532028198, loss_yt: 0.2474713772535324\n",
      "epocht 2, batch_num 200, step 82041, time: 8.16713547706604 s, accu: 0.8572713136672974, loss_yt: 0.3275633156299591\n",
      "epocht 2, batch_num 400, step 82241, time: 15.718942165374756 s, accu: 0.8572867512702942, loss_yt: 0.333775132894516\n",
      "epocht 2, batch_num 600, step 82441, time: 23.353528261184692 s, accu: 0.857300877571106, loss_yt: 0.16228368878364563\n",
      "epocht 2, batch_num 800, step 82641, time: 30.97115683555603 s, accu: 0.8573065996170044, loss_yt: 0.27406439185142517\n",
      "epocht 2, batch_num 1000, step 82841, time: 38.50204682350159 s, accu: 0.8573198914527893, loss_yt: 0.37446287274360657\n",
      "epocht 2, batch_num 1200, step 83041, time: 46.15854597091675 s, accu: 0.8573369979858398, loss_yt: 0.240428164601326\n",
      "epocht 2, batch_num 1400, step 83241, time: 53.854966163635254 s, accu: 0.8573476672172546, loss_yt: 0.30776798725128174\n",
      "epocht 2, batch_num 1600, step 83441, time: 61.490548610687256 s, accu: 0.8573706746101379, loss_yt: 0.2838455140590668\n",
      "epocht 2, batch_num 1800, step 83641, time: 69.21094083786011 s, accu: 0.8573823571205139, loss_yt: 0.4433475136756897\n",
      "epocht 2, batch_num 2000, step 83841, time: 76.7637083530426 s, accu: 0.8573845624923706, loss_yt: 0.23369672894477844\n",
      "epocht 2, batch_num 2200, step 84041, time: 84.12103509902954 s, accu: 0.8574027419090271, loss_yt: 0.3062140643596649\n",
      "epocht 2, batch_num 2400, step 84241, time: 91.7217161655426 s, accu: 0.8574212193489075, loss_yt: 0.23293812572956085\n",
      "epocht 2, batch_num 2600, step 84441, time: 99.2495789527893 s, accu: 0.857428252696991, loss_yt: 0.20832909643650055\n",
      "epocht 2, batch_num 2800, step 84641, time: 106.870201587677 s, accu: 0.8574443459510803, loss_yt: 0.49297791719436646\n",
      "epocht 2, batch_num 3000, step 84841, time: 114.48683452606201 s, accu: 0.8574564456939697, loss_yt: 0.18283279240131378\n",
      "epocht 2, batch_num 3200, step 85041, time: 122.03671026229858 s, accu: 0.8574568033218384, loss_yt: 0.30313798785209656\n",
      "epocht 2, batch_num 3400, step 85241, time: 129.51172184944153 s, accu: 0.8574727177619934, loss_yt: 0.35423022508621216\n",
      "epocht 2, batch_num 3600, step 85441, time: 136.94687342643738 s, accu: 0.8574858903884888, loss_yt: 0.3833518624305725\n",
      "epocht 2, batch_num 3800, step 85641, time: 144.4039011001587 s, accu: 0.8575054407119751, loss_yt: 0.3883211612701416\n",
      "epocht 2, batch_num 4000, step 85841, time: 151.80613374710083 s, accu: 0.8575194478034973, loss_yt: 0.2562482953071594\n",
      "epocht 2, batch_num 4200, step 86041, time: 159.36692643165588 s, accu: 0.8575389981269836, loss_yt: 0.11487993597984314\n",
      "epocht 2, batch_num 4400, step 86241, time: 167.01546955108643 s, accu: 0.8575447797775269, loss_yt: 0.3202422857284546\n",
      "epocht 2, batch_num 4600, step 86441, time: 174.72282695770264 s, accu: 0.857563316822052, loss_yt: 0.2969704270362854\n",
      "epocht 2, batch_num 4800, step 86641, time: 182.29262685775757 s, accu: 0.8575830459594727, loss_yt: 0.3910338878631592\n",
      "epocht 2, batch_num 5000, step 86841, time: 189.94615268707275 s, accu: 0.8576091527938843, loss_yt: 0.3132414221763611\n",
      "epocht 2, batch_num 5200, step 87041, time: 197.52884316444397 s, accu: 0.8576194643974304, loss_yt: 0.3180995285511017\n",
      "epocht 2, batch_num 5400, step 87241, time: 204.93603658676147 s, accu: 0.8576396703720093, loss_yt: 0.5943936705589294\n",
      "epocht 2, batch_num 5600, step 87441, time: 212.51081800460815 s, accu: 0.8576524257659912, loss_yt: 0.42493578791618347\n",
      "epocht 2, batch_num 5800, step 87641, time: 220.00976586341858 s, accu: 0.8576644659042358, loss_yt: 0.26047414541244507\n",
      "epocht 2, batch_num 6000, step 87841, time: 227.554621219635 s, accu: 0.8576580286026001, loss_yt: 0.26204875111579895\n",
      "epocht 2, batch_num 6200, step 88041, time: 234.91490864753723 s, accu: 0.8576661944389343, loss_yt: 0.1459466964006424\n",
      "epocht 2, batch_num 6400, step 88241, time: 242.56547737121582 s, accu: 0.8576695322990417, loss_yt: 0.4804408550262451\n",
      "epocht 2, batch_num 6600, step 88441, time: 250.194078207016 s, accu: 0.8576721549034119, loss_yt: 0.3267205059528351\n",
      "epocht 2, batch_num 6800, step 88641, time: 257.757915019989 s, accu: 0.8576856851577759, loss_yt: 0.33450451493263245\n",
      "epocht 2, batch_num 7000, step 88841, time: 265.2269411087036 s, accu: 0.8576873540878296, loss_yt: 0.33385685086250305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 2, batch_num 7200, step 89041, time: 272.98017740249634 s, accu: 0.8576940894126892, loss_yt: 0.3291131556034088\n",
      "epocht 2, batch_num 7400, step 89241, time: 280.5958499908447 s, accu: 0.8577112555503845, loss_yt: 0.34465891122817993\n",
      "iter_validnum 1860\n",
      "epochv 2, step 89280, stop_n 0, time: 334.2583165168762 s, accu_va: 0.8577490187780832, loss_yv: 0.30395588309614247\n",
      "iter_trainnum 7440\n",
      "epocht 2, batch_num 0, step 89281, time: 0.3560171127319336 s, accu: 0.8577906489372253, loss_yt: 0.22221635282039642\n",
      "epocht 2, batch_num 200, step 89481, time: 8.58800482749939 s, accu: 0.8577973246574402, loss_yt: 0.39018091559410095\n",
      "epocht 2, batch_num 400, step 89681, time: 16.067004680633545 s, accu: 0.8578024506568909, loss_yt: 0.26573270559310913\n",
      "epocht 2, batch_num 600, step 89881, time: 23.35551428794861 s, accu: 0.8578295707702637, loss_yt: 0.29948532581329346\n",
      "epocht 2, batch_num 800, step 90081, time: 31.222479104995728 s, accu: 0.8578380942344666, loss_yt: 0.18104708194732666\n",
      "epocht 2, batch_num 1000, step 90281, time: 38.80919146537781 s, accu: 0.8578402996063232, loss_yt: 0.510282576084137\n",
      "epocht 2, batch_num 1200, step 90481, time: 46.47369718551636 s, accu: 0.8578641414642334, loss_yt: 0.21968738734722137\n",
      "epocht 2, batch_num 1400, step 90681, time: 53.99861001968384 s, accu: 0.8578705787658691, loss_yt: 0.1733120083808899\n",
      "epocht 2, batch_num 1600, step 90881, time: 61.65314340591431 s, accu: 0.8578765392303467, loss_yt: 0.5621554851531982\n",
      "epocht 2, batch_num 1800, step 91081, time: 69.12911486625671 s, accu: 0.8578805327415466, loss_yt: 0.3869480490684509\n",
      "epocht 2, batch_num 2000, step 91281, time: 76.58022284507751 s, accu: 0.8578915596008301, loss_yt: 0.21996553242206573\n",
      "epocht 2, batch_num 2200, step 91481, time: 84.22478127479553 s, accu: 0.8579009175300598, loss_yt: 0.3501951992511749\n",
      "epocht 2, batch_num 2400, step 91681, time: 91.61897540092468 s, accu: 0.8579224348068237, loss_yt: 0.26459813117980957\n",
      "epocht 2, batch_num 2600, step 91881, time: 99.23361492156982 s, accu: 0.8579245805740356, loss_yt: 0.20429940521717072\n",
      "epocht 2, batch_num 2800, step 92081, time: 106.9131076335907 s, accu: 0.8579298853874207, loss_yt: 0.254377156496048\n",
      "epocht 2, batch_num 3000, step 92281, time: 114.45395016670227 s, accu: 0.8579558730125427, loss_yt: 0.33837559819221497\n",
      "epocht 2, batch_num 3200, step 92481, time: 121.91599297523499 s, accu: 0.8579606413841248, loss_yt: 0.4292694926261902\n",
      "epocht 2, batch_num 3400, step 92681, time: 129.52264523506165 s, accu: 0.8579689264297485, loss_yt: 0.5166971683502197\n",
      "epocht 2, batch_num 3600, step 92881, time: 136.98666763305664 s, accu: 0.8579757213592529, loss_yt: 0.3215320110321045\n",
      "epocht 2, batch_num 3800, step 93081, time: 144.80379128456116 s, accu: 0.8579843044281006, loss_yt: 0.20019468665122986\n",
      "epocht 2, batch_num 4000, step 93281, time: 152.39346432685852 s, accu: 0.8579874038696289, loss_yt: 0.28602248430252075\n",
      "epocht 2, batch_num 4200, step 93481, time: 159.9253225326538 s, accu: 0.8580023050308228, loss_yt: 0.31711816787719727\n",
      "epocht 2, batch_num 4400, step 93681, time: 167.3554549217224 s, accu: 0.858015775680542, loss_yt: 0.3077452778816223\n",
      "epocht 2, batch_num 4600, step 93881, time: 174.79757380485535 s, accu: 0.858026921749115, loss_yt: 0.3118104636669159\n",
      "epocht 2, batch_num 4800, step 94081, time: 182.0491645336151 s, accu: 0.8580459356307983, loss_yt: 0.3219004273414612\n",
      "epocht 2, batch_num 5000, step 94281, time: 189.60298871994019 s, accu: 0.8580427169799805, loss_yt: 0.3274969756603241\n",
      "epocht 2, batch_num 5200, step 94481, time: 197.05802989006042 s, accu: 0.8580628633499146, loss_yt: 0.40646398067474365\n",
      "epocht 2, batch_num 5400, step 94681, time: 204.92103362083435 s, accu: 0.8580818772315979, loss_yt: 0.306844562292099\n",
      "epocht 2, batch_num 5600, step 94881, time: 212.63939952850342 s, accu: 0.8580947518348694, loss_yt: 0.17361687123775482\n",
      "epocht 2, batch_num 5800, step 95081, time: 220.1622486114502 s, accu: 0.8581117987632751, loss_yt: 0.4471226930618286\n",
      "epocht 2, batch_num 6000, step 95281, time: 227.8946623802185 s, accu: 0.85811847448349, loss_yt: 0.3388955295085907\n",
      "epocht 2, batch_num 6200, step 95481, time: 235.2519612312317 s, accu: 0.85813307762146, loss_yt: 0.2983853220939636\n",
      "epocht 2, batch_num 6400, step 95681, time: 243.0511016845703 s, accu: 0.8581352233886719, loss_yt: 0.2793917953968048\n",
      "epocht 2, batch_num 6600, step 95881, time: 250.8013780117035 s, accu: 0.8581473231315613, loss_yt: 0.3025553524494171\n",
      "epocht 2, batch_num 6800, step 96081, time: 258.42003989219666 s, accu: 0.8581616282463074, loss_yt: 0.2100006639957428\n",
      "epocht 2, batch_num 7000, step 96281, time: 265.9588646888733 s, accu: 0.8581617474555969, loss_yt: 0.2819322943687439\n",
      "epocht 2, batch_num 7200, step 96481, time: 273.57949471473694 s, accu: 0.858165979385376, loss_yt: 0.25110235810279846\n",
      "epocht 2, batch_num 7400, step 96681, time: 281.09437322616577 s, accu: 0.8581636548042297, loss_yt: 0.4086611866950989\n",
      "iter_validnum 1860\n",
      "epochv 2, step 96720, stop_n 0, time: 334.7289888858795 s, accu_va: 0.8582120856931132, loss_yv: 0.2989378054175646\n",
      "iter_trainnum 7440\n",
      "epocht 2, batch_num 0, step 96721, time: 0.23237967491149902 s, accu: 0.8582590222358704, loss_yt: 0.35160762071609497\n",
      "epocht 2, batch_num 200, step 96921, time: 7.740290403366089 s, accu: 0.8582790493965149, loss_yt: 0.34040120244026184\n",
      "epocht 2, batch_num 400, step 97121, time: 15.24021053314209 s, accu: 0.8582862019538879, loss_yt: 0.3355470597743988\n",
      "epocht 2, batch_num 600, step 97321, time: 22.809970140457153 s, accu: 0.8582978248596191, loss_yt: 0.40537190437316895\n",
      "epocht 2, batch_num 800, step 97521, time: 30.49743914604187 s, accu: 0.8583265542984009, loss_yt: 0.2672397196292877\n",
      "epocht 2, batch_num 1000, step 97721, time: 38.226744651794434 s, accu: 0.8583195209503174, loss_yt: 0.20591460168361664\n",
      "epocht 2, batch_num 1200, step 97921, time: 45.701756715774536 s, accu: 0.85833740234375, loss_yt: 0.12735730409622192\n",
      "epocht 2, batch_num 1400, step 98121, time: 53.29943871498108 s, accu: 0.8583380579948425, loss_yt: 0.3115555942058563\n",
      "epocht 2, batch_num 1600, step 98321, time: 60.80337476730347 s, accu: 0.8583443760871887, loss_yt: 0.2939123809337616\n",
      "epocht 2, batch_num 1800, step 98521, time: 68.22256970405579 s, accu: 0.8583568930625916, loss_yt: 0.11278408765792847\n",
      "epocht 2, batch_num 2000, step 98721, time: 75.82420825958252 s, accu: 0.8583687543869019, loss_yt: 0.2670624554157257\n",
      "epocht 2, batch_num 2200, step 98921, time: 83.53461647033691 s, accu: 0.8583671450614929, loss_yt: 0.2951694428920746\n",
      "epocht 2, batch_num 2400, step 99121, time: 91.2230634689331 s, accu: 0.8583667874336243, loss_yt: 0.4890829622745514\n",
      "epocht 2, batch_num 2600, step 99321, time: 99.13989329338074 s, accu: 0.858380138874054, loss_yt: 0.2565740942955017\n",
      "epocht 2, batch_num 2800, step 99521, time: 106.52212190628052 s, accu: 0.8583886623382568, loss_yt: 0.40457603335380554\n",
      "epocht 2, batch_num 3000, step 99721, time: 114.02209877967834 s, accu: 0.8584001064300537, loss_yt: 0.44140133261680603\n",
      "epocht 2, batch_num 3200, step 99921, time: 121.54495167732239 s, accu: 0.8584078550338745, loss_yt: 0.283242791891098\n",
      "epocht 2, batch_num 3400, step 100121, time: 129.0429003238678 s, accu: 0.8584176898002625, loss_yt: 0.43007275462150574\n",
      "epocht 2, batch_num 3600, step 100321, time: 136.611661195755 s, accu: 0.8584204316139221, loss_yt: 0.32745593786239624\n",
      "epocht 2, batch_num 3800, step 100521, time: 144.1305558681488 s, accu: 0.8584237694740295, loss_yt: 0.16970087587833405\n",
      "epocht 2, batch_num 4000, step 100721, time: 152.25685286521912 s, accu: 0.8584298491477966, loss_yt: 0.4021734893321991\n",
      "epocht 2, batch_num 4200, step 100921, time: 159.73881816864014 s, accu: 0.8584510684013367, loss_yt: 0.3665717840194702\n",
      "epocht 2, batch_num 4400, step 101121, time: 167.19191551208496 s, accu: 0.8584571480751038, loss_yt: 0.18423186242580414\n",
      "epocht 2, batch_num 4600, step 101321, time: 174.73970484733582 s, accu: 0.8584589958190918, loss_yt: 0.31630879640579224\n",
      "epocht 2, batch_num 4800, step 101521, time: 182.33839082717896 s, accu: 0.858467161655426, loss_yt: 0.28687238693237305\n",
      "epocht 2, batch_num 5000, step 101721, time: 189.99594235420227 s, accu: 0.8584754467010498, loss_yt: 0.2523542642593384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 2, batch_num 5200, step 101921, time: 197.63847422599792 s, accu: 0.8584816455841064, loss_yt: 0.3219032287597656\n",
      "epocht 2, batch_num 5400, step 102121, time: 205.2381513118744 s, accu: 0.8584830164909363, loss_yt: 0.3441009819507599\n",
      "epocht 2, batch_num 5600, step 102321, time: 212.55758023262024 s, accu: 0.8584899306297302, loss_yt: 0.4751397371292114\n",
      "epocht 2, batch_num 5800, step 102521, time: 220.14232993125916 s, accu: 0.8584979772567749, loss_yt: 0.38502368330955505\n",
      "epocht 2, batch_num 6000, step 102721, time: 227.7040786743164 s, accu: 0.8585124611854553, loss_yt: 0.29961106181144714\n",
      "epocht 2, batch_num 6200, step 102921, time: 235.34165477752686 s, accu: 0.8585236668586731, loss_yt: 0.3493403494358063\n",
      "epocht 2, batch_num 6400, step 103121, time: 242.77082133293152 s, accu: 0.8585276007652283, loss_yt: 0.10326583683490753\n",
      "epocht 2, batch_num 6600, step 103321, time: 250.3016550540924 s, accu: 0.8585366606712341, loss_yt: 0.31096670031547546\n",
      "epocht 2, batch_num 6800, step 103521, time: 257.8953776359558 s, accu: 0.8585422039031982, loss_yt: 0.2783614993095398\n",
      "epocht 2, batch_num 7000, step 103721, time: 265.4132742881775 s, accu: 0.8585553765296936, loss_yt: 0.2501967251300812\n",
      "epocht 2, batch_num 7200, step 103921, time: 272.8035078048706 s, accu: 0.8585631847381592, loss_yt: 0.31171661615371704\n",
      "epocht 2, batch_num 7400, step 104121, time: 280.3852415084839 s, accu: 0.8585730791091919, loss_yt: 0.2840752899646759\n",
      "iter_validnum 1860\n",
      "epochv 2, step 104160, stop_n 0, time: 334.2102782726288 s, accu_va: 0.8586138569539593, loss_yv: 0.30354835089616555\n",
      "iter_trainnum 7440\n",
      "epocht 2, batch_num 0, step 104161, time: 0.5585300922393799 s, accu: 0.8586617708206177, loss_yt: 0.19395002722740173\n",
      "epocht 2, batch_num 200, step 104361, time: 8.52619981765747 s, accu: 0.85866379737854, loss_yt: 0.3034712076187134\n",
      "epocht 2, batch_num 400, step 104561, time: 16.13986563682556 s, accu: 0.858672559261322, loss_yt: 0.3186568319797516\n",
      "epocht 2, batch_num 600, step 104761, time: 23.674702882766724 s, accu: 0.8586833477020264, loss_yt: 0.2609247863292694\n",
      "epocht 2, batch_num 800, step 104961, time: 31.316260814666748 s, accu: 0.858686089515686, loss_yt: 0.2629550099372864\n",
      "epocht 2, batch_num 1000, step 105161, time: 38.839178800582886 s, accu: 0.8587039113044739, loss_yt: 0.29067185521125793\n",
      "epocht 2, batch_num 1200, step 105361, time: 46.24439334869385 s, accu: 0.8587208390235901, loss_yt: 0.27354177832603455\n",
      "epocht 2, batch_num 1400, step 105561, time: 53.74728012084961 s, accu: 0.8587402701377869, loss_yt: 0.26884809136390686\n",
      "epocht 2, batch_num 1600, step 105761, time: 61.41780090332031 s, accu: 0.8587451577186584, loss_yt: 0.38029924035072327\n",
      "epocht 2, batch_num 1800, step 105961, time: 69.01646995544434 s, accu: 0.8587480187416077, loss_yt: 0.48922163248062134\n",
      "epocht 2, batch_num 2000, step 106161, time: 76.62214183807373 s, accu: 0.8587483167648315, loss_yt: 0.34258028864860535\n",
      "epocht 2, batch_num 2200, step 106361, time: 84.1260621547699 s, accu: 0.8587555289268494, loss_yt: 0.44754207134246826\n",
      "epocht 2, batch_num 2400, step 106561, time: 91.71176028251648 s, accu: 0.8587690591812134, loss_yt: 0.3521488308906555\n",
      "epocht 2, batch_num 2600, step 106761, time: 99.45505571365356 s, accu: 0.8587769865989685, loss_yt: 0.30331164598464966\n",
      "epocht 2, batch_num 2800, step 106961, time: 106.98102879524231 s, accu: 0.8587879538536072, loss_yt: 0.39870142936706543\n",
      "epocht 2, batch_num 3000, step 107161, time: 114.63755011558533 s, accu: 0.8587989807128906, loss_yt: 0.25202497839927673\n",
      "epocht 2, batch_num 3200, step 107361, time: 122.19234871864319 s, accu: 0.8588037490844727, loss_yt: 0.21606095135211945\n",
      "epocht 2, batch_num 3400, step 107561, time: 129.95556211471558 s, accu: 0.8588144183158875, loss_yt: 0.37093353271484375\n",
      "epocht 2, batch_num 3600, step 107761, time: 137.44456815719604 s, accu: 0.8588312864303589, loss_yt: 0.15676158666610718\n",
      "epocht 2, batch_num 3800, step 107961, time: 144.99534583091736 s, accu: 0.8588366508483887, loss_yt: 0.3067460060119629\n",
      "epocht 2, batch_num 4000, step 108161, time: 152.5880422592163 s, accu: 0.858838677406311, loss_yt: 0.41593536734580994\n",
      "epocht 2, batch_num 4200, step 108361, time: 160.14187741279602 s, accu: 0.8588433265686035, loss_yt: 0.2853141725063324\n",
      "epocht 2, batch_num 4400, step 108561, time: 168.09956669807434 s, accu: 0.8588486909866333, loss_yt: 0.30599159002304077\n",
      "epocht 2, batch_num 4600, step 108761, time: 175.50579595565796 s, accu: 0.8588560819625854, loss_yt: 0.3043171167373657\n",
      "epocht 2, batch_num 4800, step 108961, time: 183.22212600708008 s, accu: 0.8588650226593018, loss_yt: 0.20381852984428406\n",
      "epocht 2, batch_num 5000, step 109161, time: 190.7639582157135 s, accu: 0.8588715195655823, loss_yt: 0.3046380281448364\n",
      "epocht 2, batch_num 5200, step 109361, time: 198.2519407272339 s, accu: 0.8588842153549194, loss_yt: 0.14858150482177734\n",
      "epocht 2, batch_num 5400, step 109561, time: 205.8386812210083 s, accu: 0.8588880300521851, loss_yt: 0.28560981154441833\n",
      "epocht 2, batch_num 5600, step 109761, time: 213.31866717338562 s, accu: 0.8589012622833252, loss_yt: 0.12000899761915207\n",
      "epocht 2, batch_num 5800, step 109961, time: 221.32326984405518 s, accu: 0.8588948249816895, loss_yt: 0.3400130569934845\n",
      "epocht 2, batch_num 6000, step 110161, time: 228.8989839553833 s, accu: 0.8589059114456177, loss_yt: 0.2387380599975586\n",
      "epocht 2, batch_num 6200, step 110361, time: 236.3271210193634 s, accu: 0.8589237928390503, loss_yt: 0.18217065930366516\n",
      "epocht 2, batch_num 6400, step 110561, time: 243.81709384918213 s, accu: 0.8589344620704651, loss_yt: 0.26521164178848267\n",
      "epocht 2, batch_num 6600, step 110761, time: 251.2950963973999 s, accu: 0.8589402437210083, loss_yt: 0.3301280736923218\n",
      "epocht 2, batch_num 6800, step 110961, time: 258.6943471431732 s, accu: 0.8589507341384888, loss_yt: 0.188075989484787\n",
      "epocht 2, batch_num 7000, step 111161, time: 266.35183453559875 s, accu: 0.8589560389518738, loss_yt: 0.2928568422794342\n",
      "epocht 2, batch_num 7200, step 111361, time: 273.8039083480835 s, accu: 0.8589598536491394, loss_yt: 0.2535838782787323\n",
      "epocht 2, batch_num 7400, step 111561, time: 281.33079051971436 s, accu: 0.8589605689048767, loss_yt: 0.38545286655426025\n",
      "iter_validnum 1860\n",
      "epochv 2, step 111600, stop_n 1, time: 334.9514067173004 s, accu_va: 0.8589898037974553, loss_yv: 0.29823902029023375\n",
      "iter_trainnum 7440\n",
      "epocht 3, batch_num 0, step 111601, time: 0.867682933807373 s, accu: 0.8590402007102966, loss_yt: 0.27123427391052246\n",
      "epocht 3, batch_num 200, step 111801, time: 8.362637996673584 s, accu: 0.8590419888496399, loss_yt: 0.3781472444534302\n",
      "epocht 3, batch_num 400, step 112001, time: 15.805734872817993 s, accu: 0.8590490818023682, loss_yt: 0.42835453152656555\n",
      "epocht 3, batch_num 600, step 112201, time: 23.41641354560852 s, accu: 0.8590508103370667, loss_yt: 0.2863459885120392\n",
      "epocht 3, batch_num 800, step 112401, time: 31.066925287246704 s, accu: 0.8590569496154785, loss_yt: 0.3219248354434967\n",
      "epocht 3, batch_num 1000, step 112601, time: 38.59180474281311 s, accu: 0.8590683937072754, loss_yt: 0.48783910274505615\n",
      "epocht 3, batch_num 1200, step 112801, time: 46.0469024181366 s, accu: 0.8590736389160156, loss_yt: 0.24445196986198425\n",
      "epocht 3, batch_num 1400, step 113001, time: 53.60964918136597 s, accu: 0.8590877652168274, loss_yt: 0.23896721005439758\n",
      "epocht 3, batch_num 1600, step 113201, time: 61.164445877075195 s, accu: 0.8590943813323975, loss_yt: 0.582339882850647\n",
      "epocht 3, batch_num 1800, step 113401, time: 68.70827913284302 s, accu: 0.8591020107269287, loss_yt: 0.12490101903676987\n",
      "epocht 3, batch_num 2000, step 113601, time: 76.1822898387909 s, accu: 0.859112560749054, loss_yt: 0.5113973617553711\n",
      "epocht 3, batch_num 2200, step 113801, time: 83.77600622177124 s, accu: 0.8591226935386658, loss_yt: 0.15302978456020355\n",
      "epocht 3, batch_num 2400, step 114001, time: 91.25401735305786 s, accu: 0.8591242432594299, loss_yt: 0.42873138189315796\n",
      "epocht 3, batch_num 2600, step 114201, time: 98.7709231376648 s, accu: 0.8591309189796448, loss_yt: 0.2966744601726532\n",
      "epocht 3, batch_num 2800, step 114401, time: 106.32767844200134 s, accu: 0.8591377139091492, loss_yt: 0.2164582759141922\n",
      "epocht 3, batch_num 3000, step 114601, time: 113.88846373558044 s, accu: 0.8591468930244446, loss_yt: 0.31030556559562683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 3, batch_num 3200, step 114801, time: 121.41735982894897 s, accu: 0.859155535697937, loss_yt: 0.1683483123779297\n",
      "epocht 3, batch_num 3400, step 115001, time: 128.96517133712769 s, accu: 0.8591632843017578, loss_yt: 0.2818728983402252\n",
      "epocht 3, batch_num 3600, step 115201, time: 136.5030221939087 s, accu: 0.8591776490211487, loss_yt: 0.30465221405029297\n",
      "epocht 3, batch_num 3800, step 115401, time: 144.00795221328735 s, accu: 0.8591881394386292, loss_yt: 0.3611743450164795\n",
      "epocht 3, batch_num 4000, step 115601, time: 151.4061357975006 s, accu: 0.8591983914375305, loss_yt: 0.20002451539039612\n",
      "epocht 3, batch_num 4200, step 115801, time: 159.1434464454651 s, accu: 0.8592013120651245, loss_yt: 0.3534613847732544\n",
      "epocht 3, batch_num 4400, step 116001, time: 166.51476764678955 s, accu: 0.8592174649238586, loss_yt: 0.3395078480243683\n",
      "epocht 3, batch_num 4600, step 116201, time: 174.1762957572937 s, accu: 0.8592227697372437, loss_yt: 0.1985892951488495\n",
      "epocht 3, batch_num 4800, step 116401, time: 181.68018674850464 s, accu: 0.8592272996902466, loss_yt: 0.46409088373184204\n",
      "epocht 3, batch_num 5000, step 116601, time: 189.3447151184082 s, accu: 0.8592374920845032, loss_yt: 0.2506166696548462\n",
      "epocht 3, batch_num 5200, step 116801, time: 196.90949153900146 s, accu: 0.8592297434806824, loss_yt: 0.26051250100135803\n",
      "epocht 3, batch_num 5400, step 117001, time: 204.41841220855713 s, accu: 0.8592404723167419, loss_yt: 0.2842799723148346\n",
      "epocht 3, batch_num 5600, step 117201, time: 212.03902411460876 s, accu: 0.8592470288276672, loss_yt: 0.2939358353614807\n",
      "epocht 3, batch_num 5800, step 117401, time: 219.34846019744873 s, accu: 0.859256386756897, loss_yt: 0.3117074966430664\n",
      "epocht 3, batch_num 6000, step 117601, time: 227.0568447113037 s, accu: 0.8592586517333984, loss_yt: 0.2451350837945938\n",
      "epocht 3, batch_num 6200, step 117801, time: 234.75728750228882 s, accu: 0.8592652082443237, loss_yt: 0.2388220578432083\n",
      "epocht 3, batch_num 6400, step 118001, time: 242.30011415481567 s, accu: 0.8592678308486938, loss_yt: 0.31310370564460754\n",
      "epocht 3, batch_num 6600, step 118201, time: 249.71126508712769 s, accu: 0.8592751026153564, loss_yt: 0.12741200625896454\n",
      "epocht 3, batch_num 6800, step 118401, time: 257.1533658504486 s, accu: 0.859290361404419, loss_yt: 0.1731145977973938\n",
      "epocht 3, batch_num 7000, step 118601, time: 264.7770049571991 s, accu: 0.8593006134033203, loss_yt: 0.2555282413959503\n",
      "epocht 3, batch_num 7200, step 118801, time: 272.2769250869751 s, accu: 0.8593109846115112, loss_yt: 0.3298946022987366\n",
      "epocht 3, batch_num 7400, step 119001, time: 279.8895688056946 s, accu: 0.8593213558197021, loss_yt: 0.4763512909412384\n",
      "iter_validnum 1860\n",
      "epochv 3, step 119040, stop_n 0, time: 333.74758434295654 s, accu_va: 0.8593524866206672, loss_yv: 0.3006219650788974\n",
      "iter_trainnum 7440\n",
      "epocht 3, batch_num 0, step 119041, time: 0.3669857978820801 s, accu: 0.8593681454658508, loss_yt: 0.4506992995738983\n",
      "epocht 3, batch_num 200, step 119241, time: 8.009586334228516 s, accu: 0.859374463558197, loss_yt: 0.25115424394607544\n",
      "epocht 3, batch_num 400, step 119441, time: 15.76082158088684 s, accu: 0.8593736886978149, loss_yt: 0.24838680028915405\n",
      "epocht 3, batch_num 600, step 119641, time: 23.376490354537964 s, accu: 0.859378457069397, loss_yt: 0.3829798698425293\n",
      "epocht 3, batch_num 800, step 119841, time: 30.863439083099365 s, accu: 0.8593828678131104, loss_yt: 0.1078081876039505\n",
      "epocht 3, batch_num 1000, step 120041, time: 38.516971588134766 s, accu: 0.8593930006027222, loss_yt: 0.23681360483169556\n",
      "epocht 3, batch_num 1200, step 120241, time: 46.11369061470032 s, accu: 0.8594057559967041, loss_yt: 0.1633746325969696\n",
      "epocht 3, batch_num 1400, step 120441, time: 53.69937491416931 s, accu: 0.8594180941581726, loss_yt: 0.30027708411216736\n",
      "epocht 3, batch_num 1600, step 120641, time: 61.32002902030945 s, accu: 0.8594282865524292, loss_yt: 0.3071659505367279\n",
      "epocht 3, batch_num 1800, step 120841, time: 68.94464063644409 s, accu: 0.8594371676445007, loss_yt: 0.42568644881248474\n",
      "epocht 3, batch_num 2000, step 121041, time: 76.57722568511963 s, accu: 0.8594388961791992, loss_yt: 0.2879152297973633\n",
      "epocht 3, batch_num 2200, step 121241, time: 84.1779248714447 s, accu: 0.8594396710395813, loss_yt: 0.34595370292663574\n",
      "epocht 3, batch_num 2400, step 121441, time: 91.92615389823914 s, accu: 0.8594369888305664, loss_yt: 0.47193145751953125\n",
      "epocht 3, batch_num 2600, step 121641, time: 99.40319347381592 s, accu: 0.8594427108764648, loss_yt: 0.2558360993862152\n",
      "epocht 3, batch_num 2800, step 121841, time: 106.96697115898132 s, accu: 0.8594484329223633, loss_yt: 0.2433348000049591\n",
      "epocht 3, batch_num 3000, step 122041, time: 114.36016511917114 s, accu: 0.8594568371772766, loss_yt: 0.10878388583660126\n",
      "epocht 3, batch_num 3200, step 122241, time: 122.02968978881836 s, accu: 0.8594703078269958, loss_yt: 0.3219784200191498\n",
      "epocht 3, batch_num 3400, step 122441, time: 129.51364398002625 s, accu: 0.859480619430542, loss_yt: 0.291108638048172\n",
      "epocht 3, batch_num 3600, step 122641, time: 137.21205878257751 s, accu: 0.8594760894775391, loss_yt: 0.1939539611339569\n",
      "epocht 3, batch_num 3800, step 122841, time: 144.80478882789612 s, accu: 0.8594807386398315, loss_yt: 0.31736883521080017\n",
      "epocht 3, batch_num 4000, step 123041, time: 152.56303691864014 s, accu: 0.8594866991043091, loss_yt: 0.2891252636909485\n",
      "epocht 3, batch_num 4200, step 123241, time: 160.1477279663086 s, accu: 0.8595041036605835, loss_yt: 0.12148904800415039\n",
      "epocht 3, batch_num 4400, step 123441, time: 167.59381794929504 s, accu: 0.8595139980316162, loss_yt: 0.4736303687095642\n",
      "epocht 3, batch_num 4600, step 123641, time: 174.96909594535828 s, accu: 0.8595169186592102, loss_yt: 0.1962990015745163\n",
      "epocht 3, batch_num 4800, step 123841, time: 182.7832009792328 s, accu: 0.8595196604728699, loss_yt: 0.5417462587356567\n",
      "epocht 3, batch_num 5000, step 124041, time: 190.19740772247314 s, accu: 0.8595278859138489, loss_yt: 0.2413330227136612\n",
      "epocht 3, batch_num 5200, step 124241, time: 197.6285367012024 s, accu: 0.8595402240753174, loss_yt: 0.3547821342945099\n",
      "epocht 3, batch_num 5400, step 124441, time: 205.58127117156982 s, accu: 0.8595368266105652, loss_yt: 0.2891561985015869\n",
      "epocht 3, batch_num 5600, step 124641, time: 213.38636922836304 s, accu: 0.8595390915870667, loss_yt: 0.24778737127780914\n",
      "epocht 3, batch_num 5800, step 124841, time: 220.88732814788818 s, accu: 0.8595460057258606, loss_yt: 0.4487510323524475\n",
      "epocht 3, batch_num 6000, step 125041, time: 228.3154788017273 s, accu: 0.8595560789108276, loss_yt: 0.20121584832668304\n",
      "epocht 3, batch_num 6200, step 125241, time: 235.91412687301636 s, accu: 0.8595630526542664, loss_yt: 0.10938845574855804\n",
      "epocht 3, batch_num 6400, step 125441, time: 243.34425950050354 s, accu: 0.8595770597457886, loss_yt: 0.2153097540140152\n",
      "epocht 3, batch_num 6600, step 125641, time: 250.9140281677246 s, accu: 0.8595843315124512, loss_yt: 0.3229321837425232\n",
      "epocht 3, batch_num 6800, step 125841, time: 258.39701199531555 s, accu: 0.8595936298370361, loss_yt: 0.40979433059692383\n",
      "epocht 3, batch_num 7000, step 126041, time: 265.99569058418274 s, accu: 0.8595985174179077, loss_yt: 0.23000003397464752\n",
      "epocht 3, batch_num 7200, step 126241, time: 273.77488803863525 s, accu: 0.8596012592315674, loss_yt: 0.39041876792907715\n",
      "epocht 3, batch_num 7400, step 126441, time: 281.24291729927063 s, accu: 0.859609842300415, loss_yt: 0.23060402274131775\n",
      "iter_validnum 1860\n",
      "epochv 3, step 126480, stop_n 0, time: 335.12683153152466 s, accu_va: 0.8596332220300551, loss_yv: 0.30301733197624325\n",
      "iter_trainnum 7440\n",
      "epocht 3, batch_num 0, step 126481, time: 0.33809518814086914 s, accu: 0.8596587777137756, loss_yt: 0.28641220927238464\n",
      "epocht 3, batch_num 200, step 126681, time: 8.146216869354248 s, accu: 0.8596605658531189, loss_yt: 0.3228870630264282\n",
      "epocht 3, batch_num 400, step 126881, time: 15.823686361312866 s, accu: 0.8596646785736084, loss_yt: 0.06311843544244766\n",
      "epocht 3, batch_num 600, step 127081, time: 23.34660243988037 s, accu: 0.8596715331077576, loss_yt: 0.27403220534324646\n",
      "epocht 3, batch_num 800, step 127281, time: 30.96719217300415 s, accu: 0.8596720695495605, loss_yt: 0.3103552460670471\n",
      "epocht 3, batch_num 1000, step 127481, time: 38.58980941772461 s, accu: 0.8596708178520203, loss_yt: 0.24107378721237183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 3, batch_num 1200, step 127681, time: 46.4158821105957 s, accu: 0.8596766591072083, loss_yt: 0.47531265020370483\n",
      "epocht 3, batch_num 1400, step 127881, time: 53.815144777297974 s, accu: 0.8596880435943604, loss_yt: 0.36656609177589417\n",
      "epocht 3, batch_num 1600, step 128081, time: 61.71899604797363 s, accu: 0.859696626663208, loss_yt: 0.2837979197502136\n",
      "epocht 3, batch_num 1800, step 128281, time: 69.44433569908142 s, accu: 0.8596948981285095, loss_yt: 0.4466440975666046\n",
      "epocht 3, batch_num 2000, step 128481, time: 77.09487843513489 s, accu: 0.8597046732902527, loss_yt: 0.26318681240081787\n",
      "epocht 3, batch_num 2200, step 128681, time: 84.50503206253052 s, accu: 0.8597044348716736, loss_yt: 0.2590676546096802\n",
      "epocht 3, batch_num 2400, step 128881, time: 92.18549299240112 s, accu: 0.8597149848937988, loss_yt: 0.14488504827022552\n",
      "epocht 3, batch_num 2600, step 129081, time: 99.72732734680176 s, accu: 0.8597195148468018, loss_yt: 0.2517778277397156\n",
      "epocht 3, batch_num 2800, step 129281, time: 107.03279066085815 s, accu: 0.859725296497345, loss_yt: 0.43358978629112244\n",
      "epocht 3, batch_num 3000, step 129481, time: 114.58758974075317 s, accu: 0.8597337603569031, loss_yt: 0.28235334157943726\n",
      "epocht 3, batch_num 3200, step 129681, time: 122.13344287872314 s, accu: 0.8597407937049866, loss_yt: 0.3028910160064697\n",
      "epocht 3, batch_num 3400, step 129881, time: 129.71117520332336 s, accu: 0.8597456812858582, loss_yt: 0.55013507604599\n",
      "epocht 3, batch_num 3600, step 130081, time: 137.00267672538757 s, accu: 0.8597511053085327, loss_yt: 0.34054380655288696\n",
      "epocht 3, batch_num 3800, step 130281, time: 144.5425145626068 s, accu: 0.8597561717033386, loss_yt: 0.31852245330810547\n",
      "epocht 3, batch_num 4000, step 130481, time: 152.15114378929138 s, accu: 0.8597628474235535, loss_yt: 0.21425820887088776\n",
      "epocht 3, batch_num 4200, step 130681, time: 159.82661962509155 s, accu: 0.859767496585846, loss_yt: 0.229537695646286\n",
      "epocht 3, batch_num 4400, step 130881, time: 167.4781584739685 s, accu: 0.8597726225852966, loss_yt: 0.1890442669391632\n",
      "epocht 3, batch_num 4600, step 131081, time: 174.98710012435913 s, accu: 0.8597855567932129, loss_yt: 0.24999965727329254\n",
      "epocht 3, batch_num 4800, step 131281, time: 182.88997983932495 s, accu: 0.8597937822341919, loss_yt: 0.3082231879234314\n",
      "epocht 3, batch_num 5000, step 131481, time: 190.41582322120667 s, accu: 0.8597927689552307, loss_yt: 0.12692919373512268\n",
      "epocht 3, batch_num 5200, step 131681, time: 197.96865940093994 s, accu: 0.8597955107688904, loss_yt: 0.31601682305336\n",
      "epocht 3, batch_num 5400, step 131881, time: 205.62216138839722 s, accu: 0.8598011136054993, loss_yt: 0.3176247179508209\n",
      "epocht 3, batch_num 5600, step 132081, time: 213.36050152778625 s, accu: 0.8598035573959351, loss_yt: 0.12685145437717438\n",
      "epocht 3, batch_num 5800, step 132281, time: 220.8045620918274 s, accu: 0.8598036766052246, loss_yt: 0.3796459436416626\n",
      "epocht 3, batch_num 6000, step 132481, time: 228.28855061531067 s, accu: 0.8598178625106812, loss_yt: 0.46542829275131226\n",
      "epocht 3, batch_num 6200, step 132681, time: 236.0138931274414 s, accu: 0.8598150014877319, loss_yt: 0.6079758405685425\n",
      "epocht 3, batch_num 6400, step 132881, time: 243.4799554347992 s, accu: 0.8598225712776184, loss_yt: 0.2135823518037796\n",
      "epocht 3, batch_num 6600, step 133081, time: 251.05371284484863 s, accu: 0.859828531742096, loss_yt: 0.23361754417419434\n",
      "epocht 3, batch_num 6800, step 133281, time: 258.81893706321716 s, accu: 0.8598339557647705, loss_yt: 0.3817533850669861\n",
      "epocht 3, batch_num 7000, step 133481, time: 266.2999064922333 s, accu: 0.859838604927063, loss_yt: 0.6169995665550232\n",
      "epocht 3, batch_num 7200, step 133681, time: 273.9045739173889 s, accu: 0.8598488569259644, loss_yt: 0.4989200532436371\n",
      "epocht 3, batch_num 7400, step 133881, time: 281.48832654953003 s, accu: 0.8598531484603882, loss_yt: 0.21730446815490723\n",
      "iter_validnum 1860\n",
      "epochv 3, step 133920, stop_n 1, time: 335.24155592918396 s, accu_va: 0.8598921887977149, loss_yv: 0.29807613459966514\n",
      "iter_trainnum 7440\n",
      "epocht 3, batch_num 0, step 133921, time: 0.3440728187561035 s, accu: 0.8599152565002441, loss_yt: 0.2518405020236969\n",
      "epocht 3, batch_num 200, step 134121, time: 8.268881559371948 s, accu: 0.8599094152450562, loss_yt: 0.4552082121372223\n",
      "epocht 3, batch_num 400, step 134321, time: 15.781792640686035 s, accu: 0.85991370677948, loss_yt: 0.3157990574836731\n",
      "epocht 3, batch_num 600, step 134521, time: 23.275753021240234 s, accu: 0.859923779964447, loss_yt: 0.30340614914894104\n",
      "epocht 3, batch_num 800, step 134721, time: 30.866506576538086 s, accu: 0.8599339723587036, loss_yt: 0.3627470135688782\n",
      "epocht 3, batch_num 1000, step 134921, time: 38.392330169677734 s, accu: 0.8599320650100708, loss_yt: 0.2922907769680023\n",
      "epocht 3, batch_num 1200, step 135121, time: 45.758660316467285 s, accu: 0.8599388003349304, loss_yt: 0.27707400918006897\n",
      "epocht 3, batch_num 1400, step 135321, time: 53.266557455062866 s, accu: 0.8599450588226318, loss_yt: 0.2746618688106537\n",
      "epocht 3, batch_num 1600, step 135521, time: 60.905133962631226 s, accu: 0.8599510192871094, loss_yt: 0.2662004828453064\n",
      "epocht 3, batch_num 1800, step 135721, time: 68.49186992645264 s, accu: 0.8599528074264526, loss_yt: 0.24374495446681976\n",
      "epocht 3, batch_num 2000, step 135921, time: 75.9559178352356 s, accu: 0.8599602580070496, loss_yt: 0.48811206221580505\n",
      "epocht 3, batch_num 2200, step 136121, time: 83.47580218315125 s, accu: 0.859967052936554, loss_yt: 0.4591776728630066\n",
      "epocht 3, batch_num 2400, step 136321, time: 90.9567723274231 s, accu: 0.8599700331687927, loss_yt: 0.3462691009044647\n",
      "epocht 3, batch_num 2600, step 136521, time: 98.41183710098267 s, accu: 0.859970211982727, loss_yt: 0.3288266658782959\n",
      "epocht 3, batch_num 2800, step 136721, time: 105.74622583389282 s, accu: 0.8599770069122314, loss_yt: 0.30019310116767883\n",
      "epocht 3, batch_num 3000, step 136921, time: 113.48453187942505 s, accu: 0.8599817752838135, loss_yt: 0.3442879915237427\n",
      "epocht 3, batch_num 3200, step 137121, time: 121.1510648727417 s, accu: 0.8599862456321716, loss_yt: 0.56806880235672\n",
      "epocht 3, batch_num 3400, step 137321, time: 128.67092299461365 s, accu: 0.8599857687950134, loss_yt: 0.2585964798927307\n",
      "epocht 3, batch_num 3600, step 137521, time: 136.37734699249268 s, accu: 0.8599885106086731, loss_yt: 0.31024083495140076\n",
      "epocht 3, batch_num 3800, step 137721, time: 143.7924931049347 s, accu: 0.8599883913993835, loss_yt: 0.1728925257921219\n",
      "epocht 3, batch_num 4000, step 137921, time: 151.5757086277008 s, accu: 0.8599972724914551, loss_yt: 0.3599952161312103\n",
      "epocht 3, batch_num 4200, step 138121, time: 159.09656524658203 s, accu: 0.8599984645843506, loss_yt: 0.5223143696784973\n",
      "epocht 3, batch_num 4400, step 138321, time: 166.7601180076599 s, accu: 0.8600084781646729, loss_yt: 0.1200534999370575\n",
      "epocht 3, batch_num 4600, step 138521, time: 174.39266347885132 s, accu: 0.8600127100944519, loss_yt: 0.1421593874692917\n",
      "epocht 3, batch_num 4800, step 138721, time: 181.99533247947693 s, accu: 0.8600229024887085, loss_yt: 0.39761850237846375\n",
      "epocht 3, batch_num 5000, step 138921, time: 189.69175338745117 s, accu: 0.8600303530693054, loss_yt: 0.27902278304100037\n",
      "epocht 3, batch_num 5200, step 139121, time: 197.28544688224792 s, accu: 0.8600281476974487, loss_yt: 0.5225516557693481\n",
      "epocht 3, batch_num 5400, step 139321, time: 204.84925413131714 s, accu: 0.8600308299064636, loss_yt: 0.35186290740966797\n",
      "epocht 3, batch_num 5600, step 139521, time: 212.5337085723877 s, accu: 0.8600363731384277, loss_yt: 0.3033493161201477\n",
      "epocht 3, batch_num 5800, step 139721, time: 220.44252610206604 s, accu: 0.8600356578826904, loss_yt: 0.29059627652168274\n",
      "epocht 3, batch_num 6000, step 139921, time: 228.07810831069946 s, accu: 0.8600418567657471, loss_yt: 0.42321255803108215\n",
      "epocht 3, batch_num 6200, step 140121, time: 235.87528944015503 s, accu: 0.8600466251373291, loss_yt: 0.29781559109687805\n",
      "epocht 3, batch_num 6400, step 140321, time: 243.6225733757019 s, accu: 0.8600441217422485, loss_yt: 0.34591951966285706\n",
      "epocht 3, batch_num 6600, step 140521, time: 250.9140429496765 s, accu: 0.8600550293922424, loss_yt: 0.2907211184501648\n",
      "epocht 3, batch_num 6800, step 140721, time: 258.2953085899353 s, accu: 0.8600594997406006, loss_yt: 0.3351845443248749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 3, batch_num 7000, step 140921, time: 265.85608744621277 s, accu: 0.8600679636001587, loss_yt: 0.3054959177970886\n",
      "epocht 3, batch_num 7200, step 141121, time: 273.7050998210907 s, accu: 0.8600637912750244, loss_yt: 0.24511785805225372\n",
      "epocht 3, batch_num 7400, step 141321, time: 281.1651830673218 s, accu: 0.8600724339485168, loss_yt: 0.15995649993419647\n",
      "iter_validnum 1860\n",
      "epochv 3, step 141360, stop_n 0, time: 334.7797932624817 s, accu_va: 0.8601041700570814, loss_yv: 0.2992365892776238\n",
      "iter_trainnum 7440\n",
      "epocht 3, batch_num 0, step 141361, time: 0.48772692680358887 s, accu: 0.8601274490356445, loss_yt: 0.1384524554014206\n",
      "epocht 3, batch_num 200, step 141561, time: 8.299803733825684 s, accu: 0.8601313829421997, loss_yt: 0.34123921394348145\n",
      "epocht 3, batch_num 400, step 141761, time: 15.893499612808228 s, accu: 0.8601314425468445, loss_yt: 0.3124552369117737\n",
      "epocht 3, batch_num 600, step 141961, time: 23.31967282295227 s, accu: 0.8601358532905579, loss_yt: 0.28836214542388916\n",
      "epocht 3, batch_num 800, step 142161, time: 30.811639070510864 s, accu: 0.8601470589637756, loss_yt: 0.3158167898654938\n",
      "epocht 3, batch_num 1000, step 142361, time: 38.277687072753906 s, accu: 0.8601561188697815, loss_yt: 0.258671373128891\n",
      "epocht 3, batch_num 1200, step 142561, time: 45.92818546295166 s, accu: 0.8601570725440979, loss_yt: 0.15580707788467407\n",
      "epocht 3, batch_num 1400, step 142761, time: 53.701430797576904 s, accu: 0.8601650595664978, loss_yt: 0.16807369887828827\n",
      "epocht 3, batch_num 1600, step 142961, time: 61.474613428115845 s, accu: 0.8601700067520142, loss_yt: 0.2410305142402649\n",
      "epocht 3, batch_num 1800, step 143161, time: 68.83293652534485 s, accu: 0.8601734638214111, loss_yt: 0.12285774946212769\n",
      "epocht 3, batch_num 2000, step 143361, time: 76.30395913124084 s, accu: 0.8601837754249573, loss_yt: 0.22839348018169403\n",
      "epocht 3, batch_num 2200, step 143561, time: 83.82986044883728 s, accu: 0.8601831793785095, loss_yt: 0.31506046652793884\n",
      "epocht 3, batch_num 2400, step 143761, time: 91.50331568717957 s, accu: 0.8601869940757751, loss_yt: 0.2853792607784271\n",
      "epocht 3, batch_num 2600, step 143961, time: 99.26755595207214 s, accu: 0.8601943254470825, loss_yt: 0.2635783851146698\n",
      "epocht 3, batch_num 2800, step 144161, time: 106.95998501777649 s, accu: 0.8602018356323242, loss_yt: 0.3971782624721527\n",
      "epocht 3, batch_num 3000, step 144361, time: 114.91172456741333 s, accu: 0.8602043986320496, loss_yt: 0.26176536083221436\n",
      "epocht 3, batch_num 3200, step 144561, time: 122.46352815628052 s, accu: 0.8602117300033569, loss_yt: 0.208416149020195\n",
      "epocht 3, batch_num 3400, step 144761, time: 130.12304615974426 s, accu: 0.8602128624916077, loss_yt: 0.30250105261802673\n",
      "epocht 3, batch_num 3600, step 144961, time: 137.7217309474945 s, accu: 0.8602133393287659, loss_yt: 0.27977535128593445\n",
      "epocht 3, batch_num 3800, step 145161, time: 145.19976115226746 s, accu: 0.8602162599563599, loss_yt: 0.34890997409820557\n",
      "epocht 3, batch_num 4000, step 145361, time: 153.20634150505066 s, accu: 0.8602166771888733, loss_yt: 0.44485777616500854\n",
      "epocht 3, batch_num 4200, step 145561, time: 160.79602527618408 s, accu: 0.8602119088172913, loss_yt: 0.3841995298862457\n",
      "epocht 3, batch_num 4400, step 145761, time: 168.50740575790405 s, accu: 0.860223650932312, loss_yt: 0.2651507258415222\n",
      "epocht 3, batch_num 4600, step 145961, time: 175.98046684265137 s, accu: 0.8602259159088135, loss_yt: 0.3100458085536957\n",
      "epocht 3, batch_num 4800, step 146161, time: 183.4045786857605 s, accu: 0.8602222204208374, loss_yt: 0.310222327709198\n",
      "epocht 3, batch_num 5000, step 146361, time: 190.95438313484192 s, accu: 0.8602334856987, loss_yt: 0.3385026156902313\n",
      "epocht 3, batch_num 5200, step 146561, time: 198.52816152572632 s, accu: 0.8602379560470581, loss_yt: 0.5161460041999817\n",
      "epocht 3, batch_num 5400, step 146761, time: 206.61154079437256 s, accu: 0.860244631767273, loss_yt: 0.3323441445827484\n",
      "epocht 3, batch_num 5600, step 146961, time: 214.15634179115295 s, accu: 0.8602496981620789, loss_yt: 0.388609915971756\n",
      "epocht 3, batch_num 5800, step 147161, time: 221.8358371257782 s, accu: 0.8602521419525146, loss_yt: 0.48232346773147583\n",
      "epocht 3, batch_num 6000, step 147361, time: 229.58707737922668 s, accu: 0.8602489233016968, loss_yt: 0.2714998722076416\n",
      "epocht 3, batch_num 6200, step 147561, time: 237.00726771354675 s, accu: 0.8602563142776489, loss_yt: 0.13320748507976532\n",
      "epocht 3, batch_num 6400, step 147761, time: 244.8781886100769 s, accu: 0.8602582216262817, loss_yt: 0.2892959415912628\n",
      "epocht 3, batch_num 6600, step 147961, time: 252.42304611206055 s, accu: 0.8602641820907593, loss_yt: 0.425243616104126\n",
      "epocht 3, batch_num 6800, step 148161, time: 259.97584891319275 s, accu: 0.860272228717804, loss_yt: 0.2228143960237503\n",
      "epocht 3, batch_num 7000, step 148361, time: 267.7660138607025 s, accu: 0.8602761626243591, loss_yt: 0.25265759229660034\n",
      "epocht 3, batch_num 7200, step 148561, time: 275.65788221359253 s, accu: 0.8602809309959412, loss_yt: 0.5032259821891785\n",
      "epocht 3, batch_num 7400, step 148761, time: 283.2994861602783 s, accu: 0.8602811098098755, loss_yt: 0.3268522024154663\n",
      "iter_validnum 1860\n",
      "epochv 3, step 148800, stop_n 0, time: 336.8273239135742 s, accu_va: 0.8603056243991339, loss_yv: 0.2993102541413679\n",
      "iter_trainnum 7440\n",
      "epocht 4, batch_num 0, step 148801, time: 0.4817030429840088 s, accu: 0.8603199124336243, loss_yt: 0.2518577575683594\n",
      "epocht 4, batch_num 200, step 149001, time: 8.105345249176025 s, accu: 0.8603287935256958, loss_yt: 0.3623669445514679\n",
      "epocht 4, batch_num 400, step 149201, time: 15.791796445846558 s, accu: 0.8603412508964539, loss_yt: 0.4351468086242676\n",
      "epocht 4, batch_num 600, step 149401, time: 24.058659315109253 s, accu: 0.8603485822677612, loss_yt: 0.499207079410553\n",
      "epocht 4, batch_num 800, step 149601, time: 31.999428510665894 s, accu: 0.8603440523147583, loss_yt: 0.14641202986240387\n",
      "epocht 4, batch_num 1000, step 149801, time: 39.44152498245239 s, accu: 0.8603501319885254, loss_yt: 0.29766845703125\n",
      "epocht 4, batch_num 1200, step 150001, time: 46.979389905929565 s, accu: 0.8603544235229492, loss_yt: 0.3549599349498749\n",
      "epocht 4, batch_num 1400, step 150201, time: 54.32672429084778 s, accu: 0.8603593111038208, loss_yt: 0.25801992416381836\n",
      "epocht 4, batch_num 1600, step 150401, time: 62.277485847473145 s, accu: 0.8603648543357849, loss_yt: 0.40866008400917053\n",
      "epocht 4, batch_num 1800, step 150601, time: 70.18332004547119 s, accu: 0.8603659272193909, loss_yt: 0.23400400578975677\n",
      "epocht 4, batch_num 2000, step 150801, time: 78.15907907485962 s, accu: 0.860373854637146, loss_yt: 0.37431004643440247\n",
      "epocht 4, batch_num 2200, step 151001, time: 85.69992089271545 s, accu: 0.8603899478912354, loss_yt: 0.18016397953033447\n",
      "epocht 4, batch_num 2400, step 151201, time: 93.21781015396118 s, accu: 0.8603955507278442, loss_yt: 0.21079176664352417\n",
      "epocht 4, batch_num 2600, step 151401, time: 100.88734984397888 s, accu: 0.8604029417037964, loss_yt: 0.32582756876945496\n",
      "epocht 4, batch_num 2800, step 151601, time: 108.28352570533752 s, accu: 0.860404908657074, loss_yt: 0.2775435745716095\n",
      "epocht 4, batch_num 3000, step 151801, time: 116.09666156768799 s, accu: 0.8604075908660889, loss_yt: 0.1704857498407364\n",
      "epocht 4, batch_num 3200, step 152001, time: 123.3961501121521 s, accu: 0.8604217767715454, loss_yt: 0.19996966421604156\n",
      "epocht 4, batch_num 3400, step 152201, time: 131.22418236732483 s, accu: 0.8604225516319275, loss_yt: 0.28617802262306213\n",
      "epocht 4, batch_num 3600, step 152401, time: 139.02532124519348 s, accu: 0.8604208827018738, loss_yt: 0.31011825799942017\n",
      "epocht 4, batch_num 3800, step 152601, time: 146.47440242767334 s, accu: 0.8604257106781006, loss_yt: 0.2743203043937683\n",
      "epocht 4, batch_num 4000, step 152801, time: 153.91251254081726 s, accu: 0.860430121421814, loss_yt: 0.2679865062236786\n",
      "epocht 4, batch_num 4200, step 153001, time: 161.44138622283936 s, accu: 0.8604320287704468, loss_yt: 0.2616824805736542\n",
      "epocht 4, batch_num 4400, step 153201, time: 169.18968892097473 s, accu: 0.8604270219802856, loss_yt: 0.26129043102264404\n",
      "epocht 4, batch_num 4600, step 153401, time: 176.55396795272827 s, accu: 0.8604344725608826, loss_yt: 0.13032834231853485\n",
      "epocht 4, batch_num 4800, step 153601, time: 184.2982587814331 s, accu: 0.8604293465614319, loss_yt: 0.16115900874137878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 4, batch_num 5000, step 153801, time: 191.91889023780823 s, accu: 0.8604366183280945, loss_yt: 0.14272797107696533\n",
      "epocht 4, batch_num 5200, step 154001, time: 199.51656460762024 s, accu: 0.8604348301887512, loss_yt: 0.36981484293937683\n",
      "epocht 4, batch_num 5400, step 154201, time: 207.00055313110352 s, accu: 0.8604321479797363, loss_yt: 0.452802836894989\n",
      "epocht 4, batch_num 5600, step 154401, time: 214.5364010334015 s, accu: 0.8604365587234497, loss_yt: 0.28212815523147583\n",
      "epocht 4, batch_num 5800, step 154601, time: 222.1290979385376 s, accu: 0.8604374527931213, loss_yt: 0.3161047101020813\n",
      "epocht 4, batch_num 6000, step 154801, time: 229.78168153762817 s, accu: 0.8604442477226257, loss_yt: 0.22929593920707703\n",
      "epocht 4, batch_num 6200, step 155001, time: 237.34241771697998 s, accu: 0.8604502081871033, loss_yt: 0.21589913964271545\n",
      "epocht 4, batch_num 6400, step 155201, time: 245.0857367515564 s, accu: 0.8604531288146973, loss_yt: 0.2848242223262787\n",
      "epocht 4, batch_num 6600, step 155401, time: 252.73727655410767 s, accu: 0.8604550361633301, loss_yt: 0.14700175821781158\n",
      "epocht 4, batch_num 6800, step 155601, time: 260.2192702293396 s, accu: 0.8604606986045837, loss_yt: 0.34904471039772034\n",
      "epocht 4, batch_num 7000, step 155801, time: 267.7341499328613 s, accu: 0.8604649305343628, loss_yt: 0.48573216795921326\n",
      "epocht 4, batch_num 7200, step 156001, time: 275.4026758670807 s, accu: 0.8604661822319031, loss_yt: 0.3418055474758148\n",
      "epocht 4, batch_num 7400, step 156201, time: 283.0142903327942 s, accu: 0.8604720830917358, loss_yt: 0.2595245838165283\n",
      "iter_validnum 1860\n",
      "epochv 4, step 156240, stop_n 0, time: 337.1096396446228 s, accu_va: 0.8604799113927349, loss_yv: 0.3012734545695205\n",
      "iter_trainnum 7440\n",
      "epocht 4, batch_num 0, step 156241, time: 0.33809590339660645 s, accu: 0.8604962229728699, loss_yt: 0.19948431849479675\n",
      "epocht 4, batch_num 200, step 156441, time: 8.52523684501648 s, accu: 0.8604902029037476, loss_yt: 0.25794747471809387\n",
      "epocht 4, batch_num 400, step 156641, time: 16.0660719871521 s, accu: 0.8604943752288818, loss_yt: 0.3235737979412079\n",
      "epocht 4, batch_num 600, step 156841, time: 23.409400701522827 s, accu: 0.8604915142059326, loss_yt: 0.33397695422172546\n",
      "epocht 4, batch_num 800, step 157041, time: 30.98514485359192 s, accu: 0.860494077205658, loss_yt: 0.32836174964904785\n",
      "epocht 4, batch_num 1000, step 157241, time: 38.49605870246887 s, accu: 0.8604955673217773, loss_yt: 0.2788597047328949\n",
      "epocht 4, batch_num 1200, step 157441, time: 46.3321328163147 s, accu: 0.860501229763031, loss_yt: 0.32088688015937805\n",
      "epocht 4, batch_num 1400, step 157641, time: 53.87892484664917 s, accu: 0.8605054020881653, loss_yt: 0.3446348309516907\n",
      "epocht 4, batch_num 1600, step 157841, time: 61.65214657783508 s, accu: 0.8605058789253235, loss_yt: 0.3011154532432556\n",
      "epocht 4, batch_num 1800, step 158041, time: 69.20494270324707 s, accu: 0.8605117797851562, loss_yt: 0.3056868314743042\n",
      "epocht 4, batch_num 2000, step 158241, time: 76.78370594978333 s, accu: 0.860511839389801, loss_yt: 0.37896013259887695\n",
      "epocht 4, batch_num 2200, step 158441, time: 84.41231060028076 s, accu: 0.8605149388313293, loss_yt: 0.3641566336154938\n",
      "epocht 4, batch_num 2400, step 158641, time: 91.87731671333313 s, accu: 0.8605221509933472, loss_yt: 0.29468366503715515\n",
      "epocht 4, batch_num 2600, step 158841, time: 99.6216127872467 s, accu: 0.8605270981788635, loss_yt: 0.39118316769599915\n",
      "epocht 4, batch_num 2800, step 159041, time: 107.0537371635437 s, accu: 0.8605337142944336, loss_yt: 0.18408836424350739\n",
      "epocht 4, batch_num 3000, step 159241, time: 114.9926073551178 s, accu: 0.8605397939682007, loss_yt: 0.34316495060920715\n",
      "epocht 4, batch_num 3200, step 159441, time: 122.55138921737671 s, accu: 0.8605456948280334, loss_yt: 0.5833107233047485\n",
      "epocht 4, batch_num 3400, step 159641, time: 130.20692992210388 s, accu: 0.8605480790138245, loss_yt: 0.26833876967430115\n",
      "epocht 4, batch_num 3600, step 159841, time: 138.16164898872375 s, accu: 0.860554575920105, loss_yt: 0.4349237382411957\n",
      "epocht 4, batch_num 3800, step 160041, time: 145.98573756217957 s, accu: 0.8605585098266602, loss_yt: 0.3183284103870392\n",
      "epocht 4, batch_num 4000, step 160241, time: 153.56445407867432 s, accu: 0.8605661392211914, loss_yt: 0.274021178483963\n",
      "epocht 4, batch_num 4200, step 160441, time: 161.02447986602783 s, accu: 0.8605741858482361, loss_yt: 0.32434189319610596\n",
      "epocht 4, batch_num 4400, step 160641, time: 168.83759093284607 s, accu: 0.8605760335922241, loss_yt: 0.23482133448123932\n",
      "epocht 4, batch_num 4600, step 160841, time: 176.3535225391388 s, accu: 0.8605822920799255, loss_yt: 0.3649290204048157\n",
      "epocht 4, batch_num 4800, step 161041, time: 184.19754767417908 s, accu: 0.860587477684021, loss_yt: 0.24655406177043915\n",
      "epocht 4, batch_num 5000, step 161241, time: 191.74337649345398 s, accu: 0.8605915904045105, loss_yt: 0.2763649821281433\n",
      "epocht 4, batch_num 5200, step 161441, time: 199.31209921836853 s, accu: 0.8605930805206299, loss_yt: 0.3043557107448578\n",
      "epocht 4, batch_num 5400, step 161641, time: 206.76319193840027 s, accu: 0.8606035709381104, loss_yt: 0.13634485006332397\n",
      "epocht 4, batch_num 5600, step 161841, time: 214.070631980896 s, accu: 0.8606154918670654, loss_yt: 0.2238917201757431\n",
      "epocht 4, batch_num 5800, step 162041, time: 222.07323479652405 s, accu: 0.8606154918670654, loss_yt: 0.24293071031570435\n",
      "epocht 4, batch_num 6000, step 162241, time: 229.5353126525879 s, accu: 0.8606233596801758, loss_yt: 0.24396635591983795\n",
      "epocht 4, batch_num 6200, step 162441, time: 237.13798427581787 s, accu: 0.8606288433074951, loss_yt: 0.2937430143356323\n",
      "epocht 4, batch_num 6400, step 162641, time: 244.83237433433533 s, accu: 0.8606278896331787, loss_yt: 0.556454598903656\n",
      "epocht 4, batch_num 6600, step 162841, time: 252.317378282547 s, accu: 0.8606351017951965, loss_yt: 0.3569211959838867\n",
      "epocht 4, batch_num 6800, step 163041, time: 259.8133153915405 s, accu: 0.860639214515686, loss_yt: 0.3124348521232605\n",
      "epocht 4, batch_num 7000, step 163241, time: 267.2903473377228 s, accu: 0.8606376647949219, loss_yt: 0.2252851277589798\n",
      "epocht 4, batch_num 7200, step 163441, time: 275.151300907135 s, accu: 0.8606421947479248, loss_yt: 0.35329583287239075\n",
      "epocht 4, batch_num 7400, step 163641, time: 282.7540192604065 s, accu: 0.8606421947479248, loss_yt: 0.28475892543792725\n",
      "iter_validnum 1860\n",
      "epochv 4, step 163680, stop_n 0, time: 336.41149044036865 s, accu_va: 0.8606571699021965, loss_yv: 0.3031637510264753\n",
      "iter_trainnum 7440\n",
      "epocht 4, batch_num 0, step 163681, time: 0.5255954265594482 s, accu: 0.8606660962104797, loss_yt: 0.2699490189552307\n",
      "epocht 4, batch_num 200, step 163881, time: 8.418493509292603 s, accu: 0.8606714606285095, loss_yt: 0.14087489247322083\n",
      "epocht 4, batch_num 400, step 164081, time: 16.35426902770996 s, accu: 0.8606712818145752, loss_yt: 0.35992899537086487\n",
      "epocht 4, batch_num 600, step 164281, time: 23.774428367614746 s, accu: 0.8606758117675781, loss_yt: 0.46937546133995056\n",
      "epocht 4, batch_num 800, step 164481, time: 31.470848083496094 s, accu: 0.860679566860199, loss_yt: 0.3476621210575104\n",
      "epocht 4, batch_num 1000, step 164681, time: 39.04658818244934 s, accu: 0.8606809377670288, loss_yt: 0.2380629926919937\n",
      "epocht 4, batch_num 1200, step 164881, time: 46.769936323165894 s, accu: 0.8606768250465393, loss_yt: 0.28305745124816895\n",
      "epocht 4, batch_num 1400, step 165081, time: 54.46137022972107 s, accu: 0.8606777191162109, loss_yt: 0.2673005163669586\n",
      "epocht 4, batch_num 1600, step 165281, time: 61.87457895278931 s, accu: 0.8606810569763184, loss_yt: 0.3442192077636719\n",
      "epocht 4, batch_num 1800, step 165481, time: 69.40840125083923 s, accu: 0.8606935143470764, loss_yt: 0.25262337923049927\n",
      "epocht 4, batch_num 2000, step 165681, time: 76.92928886413574 s, accu: 0.8607010841369629, loss_yt: 0.2830737829208374\n",
      "epocht 4, batch_num 2200, step 165881, time: 84.60476469993591 s, accu: 0.8607057929039001, loss_yt: 0.37119632959365845\n",
      "epocht 4, batch_num 2400, step 166081, time: 92.46275234222412 s, accu: 0.8607172966003418, loss_yt: 0.21548263728618622\n",
      "epocht 4, batch_num 2600, step 166281, time: 100.03453850746155 s, accu: 0.8607149720191956, loss_yt: 0.2759976089000702\n",
      "epocht 4, batch_num 2800, step 166481, time: 107.6301941871643 s, accu: 0.8607200980186462, loss_yt: 0.2619541883468628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 4, batch_num 3000, step 166681, time: 115.55504083633423 s, accu: 0.8607195615768433, loss_yt: 0.3195420205593109\n",
      "epocht 4, batch_num 3200, step 166881, time: 123.1865963935852 s, accu: 0.8607269525527954, loss_yt: 0.18198086321353912\n",
      "epocht 4, batch_num 3400, step 167081, time: 130.60575771331787 s, accu: 0.8607299327850342, loss_yt: 0.10915879160165787\n",
      "epocht 4, batch_num 3600, step 167281, time: 138.16355729103088 s, accu: 0.860734760761261, loss_yt: 0.2320423573255539\n",
      "epocht 4, batch_num 3800, step 167481, time: 145.82107138633728 s, accu: 0.8607316017150879, loss_yt: 0.30310824513435364\n",
      "epocht 4, batch_num 4000, step 167681, time: 153.4037947654724 s, accu: 0.8607349395751953, loss_yt: 0.3704824149608612\n",
      "epocht 4, batch_num 4200, step 167881, time: 161.28771352767944 s, accu: 0.86074298620224, loss_yt: 0.1509343534708023\n",
      "epocht 4, batch_num 4400, step 168081, time: 169.21850609779358 s, accu: 0.8607469201087952, loss_yt: 0.2773831784725189\n",
      "epocht 4, batch_num 4600, step 168281, time: 177.60108995437622 s, accu: 0.8607486486434937, loss_yt: 0.28666648268699646\n",
      "epocht 4, batch_num 4800, step 168481, time: 185.68746781349182 s, accu: 0.8607504367828369, loss_yt: 0.2509002685546875\n",
      "epocht 4, batch_num 5000, step 168681, time: 193.72401094436646 s, accu: 0.8607537150382996, loss_yt: 0.40663596987724304\n",
      "epocht 4, batch_num 5200, step 168881, time: 201.75153970718384 s, accu: 0.8607608079910278, loss_yt: 0.2845887243747711\n",
      "epocht 4, batch_num 5400, step 169081, time: 210.07229137420654 s, accu: 0.8607603311538696, loss_yt: 0.3470492660999298\n",
      "epocht 4, batch_num 5600, step 169281, time: 218.47978019714355 s, accu: 0.8607615232467651, loss_yt: 0.3665255010128021\n",
      "epocht 4, batch_num 5800, step 169481, time: 226.625 s, accu: 0.860764741897583, loss_yt: 0.3658100962638855\n",
      "epocht 4, batch_num 6000, step 169681, time: 234.80313444137573 s, accu: 0.8607655763626099, loss_yt: 0.35536932945251465\n",
      "epocht 4, batch_num 6200, step 169881, time: 243.21962666511536 s, accu: 0.8607660531997681, loss_yt: 0.39534029364585876\n",
      "epocht 4, batch_num 6400, step 170081, time: 251.47754549980164 s, accu: 0.8607656955718994, loss_yt: 0.29364877939224243\n",
      "epocht 4, batch_num 6600, step 170281, time: 259.40634298324585 s, accu: 0.8607715964317322, loss_yt: 0.26018068194389343\n",
      "epocht 4, batch_num 6800, step 170481, time: 267.72609424591064 s, accu: 0.8607746958732605, loss_yt: 0.2747823894023895\n",
      "epocht 4, batch_num 7000, step 170681, time: 275.9870054721832 s, accu: 0.8607769012451172, loss_yt: 0.2920873165130615\n",
      "epocht 4, batch_num 7200, step 170881, time: 284.2269718647003 s, accu: 0.8607808947563171, loss_yt: 0.3225215673446655\n",
      "epocht 4, batch_num 7400, step 171081, time: 292.149786233902 s, accu: 0.8607829809188843, loss_yt: 0.5396870374679565\n",
      "iter_validnum 1860\n",
      "epochv 4, step 171120, stop_n 1, time: 351.21587109565735 s, accu_va: 0.8608033743596846, loss_yv: 0.2978564549557945\n",
      "iter_trainnum 7440\n",
      "epocht 4, batch_num 0, step 171121, time: 0.3700089454650879 s, accu: 0.860822856426239, loss_yt: 0.3002808690071106\n",
      "epocht 4, batch_num 200, step 171321, time: 8.443419694900513 s, accu: 0.8608230948448181, loss_yt: 0.3084341585636139\n",
      "epocht 4, batch_num 400, step 171521, time: 16.815033197402954 s, accu: 0.8608261346817017, loss_yt: 0.30710867047309875\n",
      "epocht 4, batch_num 600, step 171721, time: 24.766770839691162 s, accu: 0.8608312606811523, loss_yt: 0.3044564425945282\n",
      "epocht 4, batch_num 800, step 171921, time: 32.98280167579651 s, accu: 0.8608375787734985, loss_yt: 0.32485413551330566\n",
      "epocht 4, batch_num 1000, step 172121, time: 41.14796686172485 s, accu: 0.860836386680603, loss_yt: 0.4749837815761566\n",
      "epocht 4, batch_num 1200, step 172321, time: 49.291220903396606 s, accu: 0.8608361482620239, loss_yt: 0.2335285246372223\n",
      "epocht 4, batch_num 1400, step 172521, time: 57.34864616394043 s, accu: 0.8608376979827881, loss_yt: 0.34740182757377625\n",
      "epocht 4, batch_num 1600, step 172721, time: 65.68837857246399 s, accu: 0.8608395457267761, loss_yt: 0.33071258664131165\n",
      "epocht 4, batch_num 1800, step 172921, time: 74.1487250328064 s, accu: 0.8608404994010925, loss_yt: 0.35065507888793945\n",
      "epocht 4, batch_num 2000, step 173121, time: 82.51039624214172 s, accu: 0.8608420491218567, loss_yt: 0.2965468764305115\n",
      "epocht 4, batch_num 2200, step 173321, time: 91.07948184013367 s, accu: 0.8608464598655701, loss_yt: 0.2650473117828369\n",
      "epocht 4, batch_num 2400, step 173521, time: 99.3992018699646 s, accu: 0.8608486652374268, loss_yt: 0.5018919706344604\n",
      "epocht 4, batch_num 2600, step 173721, time: 107.54345703125 s, accu: 0.8608523607254028, loss_yt: 0.1859324425458908\n",
      "epocht 4, batch_num 2800, step 173921, time: 115.76743626594543 s, accu: 0.8608564138412476, loss_yt: 0.2798483073711395\n",
      "epocht 4, batch_num 3000, step 174121, time: 124.0383186340332 s, accu: 0.8608578443527222, loss_yt: 0.14975152909755707\n",
      "epocht 4, batch_num 3200, step 174321, time: 132.2722978591919 s, accu: 0.8608613014221191, loss_yt: 0.1783551722764969\n",
      "epocht 4, batch_num 3400, step 174521, time: 140.61598920822144 s, accu: 0.860863983631134, loss_yt: 0.33779576420783997\n",
      "epocht 4, batch_num 3600, step 174721, time: 149.01253652572632 s, accu: 0.8608648777008057, loss_yt: 0.5273243188858032\n",
      "epocht 4, batch_num 3800, step 174921, time: 157.0600175857544 s, accu: 0.8608688116073608, loss_yt: 0.33358854055404663\n",
      "epocht 4, batch_num 4000, step 175121, time: 165.32393741607666 s, accu: 0.860871434211731, loss_yt: 0.21543870866298676\n",
      "epocht 4, batch_num 4200, step 175321, time: 173.83815217018127 s, accu: 0.8608677387237549, loss_yt: 0.15603365004062653\n",
      "epocht 4, batch_num 4400, step 175521, time: 182.38629412651062 s, accu: 0.8608675003051758, loss_yt: 0.29302406311035156\n",
      "epocht 4, batch_num 4600, step 175721, time: 190.37493348121643 s, accu: 0.8608733415603638, loss_yt: 0.24342957139015198\n",
      "epocht 4, batch_num 4800, step 175921, time: 198.70565605163574 s, accu: 0.8608757853507996, loss_yt: 0.49118781089782715\n",
      "epocht 4, batch_num 5000, step 176121, time: 206.9476249217987 s, accu: 0.8608755469322205, loss_yt: 0.4940696656703949\n",
      "epocht 4, batch_num 5200, step 176321, time: 214.94024324417114 s, accu: 0.8608776926994324, loss_yt: 0.4038424789905548\n",
      "epocht 4, batch_num 5400, step 176521, time: 223.41956901550293 s, accu: 0.8608834743499756, loss_yt: 0.2021024078130722\n",
      "epocht 4, batch_num 5600, step 176721, time: 231.52888441085815 s, accu: 0.8608869314193726, loss_yt: 0.30051323771476746\n",
      "epocht 4, batch_num 5800, step 176921, time: 239.5813536643982 s, accu: 0.8608977198600769, loss_yt: 0.16683295369148254\n",
      "epocht 4, batch_num 6000, step 177121, time: 247.72258162498474 s, accu: 0.8609071969985962, loss_yt: 0.29418250918388367\n",
      "epocht 4, batch_num 6200, step 177321, time: 255.97252321243286 s, accu: 0.8609129786491394, loss_yt: 0.27385056018829346\n",
      "epocht 4, batch_num 6400, step 177521, time: 264.1037781238556 s, accu: 0.8609163165092468, loss_yt: 0.23003827035427094\n",
      "epocht 4, batch_num 6600, step 177721, time: 272.04953169822693 s, accu: 0.8609201908111572, loss_yt: 0.25337526202201843\n",
      "epocht 4, batch_num 6800, step 177921, time: 280.3214123249054 s, accu: 0.8609175682067871, loss_yt: 0.316412091255188\n",
      "epocht 4, batch_num 7000, step 178121, time: 288.42175126075745 s, accu: 0.8609185814857483, loss_yt: 0.23990845680236816\n",
      "epocht 4, batch_num 7200, step 178321, time: 296.58592200279236 s, accu: 0.8609261512756348, loss_yt: 0.3303818702697754\n",
      "epocht 4, batch_num 7400, step 178521, time: 304.8697702884674 s, accu: 0.8609319925308228, loss_yt: 0.25324028730392456\n",
      "iter_validnum 1860\n",
      "epochv 4, step 178560, stop_n 0, time: 364.822482585907 s, accu_va: 0.8609529185038741, loss_yv: 0.2986948703686076\n",
      "iter_trainnum 7440\n",
      "epocht 4, batch_num 0, step 178561, time: 0.5435457229614258 s, accu: 0.8609695434570312, loss_yt: 0.3005705773830414\n",
      "epocht 4, batch_num 200, step 178761, time: 8.67284107208252 s, accu: 0.8609706163406372, loss_yt: 0.2206239402294159\n",
      "epocht 4, batch_num 400, step 178961, time: 16.66543698310852 s, accu: 0.8609721660614014, loss_yt: 0.383474200963974\n",
      "epocht 4, batch_num 600, step 179161, time: 24.916372537612915 s, accu: 0.8609732389450073, loss_yt: 0.22025226056575775\n",
      "epocht 4, batch_num 800, step 179361, time: 32.99975657463074 s, accu: 0.8609786629676819, loss_yt: 0.32240045070648193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 4, batch_num 1000, step 179561, time: 41.36239719390869 s, accu: 0.8609789609909058, loss_yt: 0.5107691884040833\n",
      "epocht 4, batch_num 1200, step 179761, time: 49.999327659606934 s, accu: 0.860979437828064, loss_yt: 0.3689420521259308\n",
      "epocht 4, batch_num 1400, step 179961, time: 58.17842960357666 s, accu: 0.8609905242919922, loss_yt: 0.24430865049362183\n",
      "epocht 4, batch_num 1600, step 180161, time: 66.4473192691803 s, accu: 0.8609927892684937, loss_yt: 0.27016112208366394\n",
      "epocht 4, batch_num 1800, step 180361, time: 74.75912523269653 s, accu: 0.8609935641288757, loss_yt: 0.22891438007354736\n",
      "epocht 4, batch_num 2000, step 180561, time: 83.12671756744385 s, accu: 0.8609983325004578, loss_yt: 0.45603808760643005\n",
      "epocht 4, batch_num 2200, step 180761, time: 91.30584597587585 s, accu: 0.8610074520111084, loss_yt: 0.32561537623405457\n",
      "epocht 4, batch_num 2400, step 180961, time: 99.84900307655334 s, accu: 0.8610071539878845, loss_yt: 0.45283347368240356\n",
      "epocht 4, batch_num 2600, step 181161, time: 107.95632195472717 s, accu: 0.861008882522583, loss_yt: 0.3356209397315979\n",
      "epocht 4, batch_num 2800, step 181361, time: 116.21922659873962 s, accu: 0.8610114455223083, loss_yt: 0.28376632928848267\n",
      "epocht 4, batch_num 3000, step 181561, time: 124.31560945510864 s, accu: 0.8610159754753113, loss_yt: 0.33643630146980286\n",
      "epocht 4, batch_num 3200, step 181761, time: 132.50268483161926 s, accu: 0.8610169887542725, loss_yt: 0.4817841947078705\n",
      "epocht 4, batch_num 3400, step 181961, time: 140.7077443599701 s, accu: 0.8610225915908813, loss_yt: 0.30657047033309937\n",
      "epocht 4, batch_num 3600, step 182161, time: 148.93474411964417 s, accu: 0.8610255718231201, loss_yt: 0.28877973556518555\n",
      "epocht 4, batch_num 3800, step 182361, time: 157.48092484474182 s, accu: 0.8610250949859619, loss_yt: 0.22811317443847656\n",
      "epocht 4, batch_num 4000, step 182561, time: 165.84353160858154 s, accu: 0.8610249161720276, loss_yt: 0.4039447009563446\n",
      "epocht 4, batch_num 4200, step 182761, time: 174.00271320343018 s, accu: 0.8610270619392395, loss_yt: 0.35332539677619934\n",
      "epocht 4, batch_num 4400, step 182961, time: 182.39427495002747 s, accu: 0.8610357642173767, loss_yt: 0.2937655448913574\n",
      "epocht 4, batch_num 4600, step 183161, time: 190.75192523002625 s, accu: 0.8610333800315857, loss_yt: 0.2578803598880768\n",
      "epocht 4, batch_num 4800, step 183361, time: 198.9789595603943 s, accu: 0.8610373735427856, loss_yt: 0.2351890206336975\n",
      "epocht 4, batch_num 5000, step 183561, time: 207.29970836639404 s, accu: 0.8610394597053528, loss_yt: 0.2909034490585327\n",
      "epocht 4, batch_num 5200, step 183761, time: 215.84582495689392 s, accu: 0.8610408902168274, loss_yt: 0.2576141655445099\n",
      "epocht 4, batch_num 5400, step 183961, time: 224.10972833633423 s, accu: 0.8610477447509766, loss_yt: 0.2583363652229309\n",
      "epocht 4, batch_num 5600, step 184161, time: 232.5122606754303 s, accu: 0.8610507249832153, loss_yt: 0.3731260299682617\n",
      "epocht 4, batch_num 5800, step 184361, time: 240.81807231903076 s, accu: 0.8610491156578064, loss_yt: 0.28980809450149536\n",
      "epocht 4, batch_num 6000, step 184561, time: 249.09790658950806 s, accu: 0.8610512018203735, loss_yt: 0.4034150540828705\n",
      "epocht 4, batch_num 6200, step 184761, time: 257.3518371582031 s, accu: 0.8610557317733765, loss_yt: 0.49301877617836\n",
      "epocht 4, batch_num 6400, step 184961, time: 265.47017669677734 s, accu: 0.8610605001449585, loss_yt: 0.2371361255645752\n",
      "epocht 4, batch_num 6600, step 185161, time: 274.13299536705017 s, accu: 0.8610625863075256, loss_yt: 0.2954748570919037\n",
      "epocht 4, batch_num 6800, step 185361, time: 282.40384674072266 s, accu: 0.8610645532608032, loss_yt: 0.3633042573928833\n",
      "epocht 4, batch_num 7000, step 185561, time: 291.0118272304535 s, accu: 0.861065149307251, loss_yt: 0.22810731828212738\n",
      "epocht 4, batch_num 7200, step 185761, time: 299.09321784973145 s, accu: 0.8610751628875732, loss_yt: 0.26263779401779175\n",
      "epocht 4, batch_num 7400, step 185961, time: 307.6563193798065 s, accu: 0.8610775470733643, loss_yt: 0.1712752878665924\n",
      "iter_validnum 1860\n",
      "epochv 4, step 186000, stop_n 0, time: 367.8423840999603 s, accu_va: 0.8610907612628834, loss_yv: 0.2994627520361895\n",
      "iter_trainnum 7440\n",
      "epocht 5, batch_num 0, step 186001, time: 0.34906864166259766 s, accu: 0.8611078262329102, loss_yt: 0.2730374038219452\n",
      "epocht 5, batch_num 200, step 186201, time: 8.818410396575928 s, accu: 0.8611094355583191, loss_yt: 0.13171015679836273\n",
      "epocht 5, batch_num 400, step 186401, time: 17.05043125152588 s, accu: 0.8611147999763489, loss_yt: 0.48361942172050476\n",
      "epocht 5, batch_num 600, step 186601, time: 25.371148824691772 s, accu: 0.8611253499984741, loss_yt: 0.21213698387145996\n",
      "epocht 5, batch_num 800, step 186801, time: 33.529332637786865 s, accu: 0.8611393570899963, loss_yt: 0.2833084166049957\n",
      "epocht 5, batch_num 1000, step 187001, time: 41.97176742553711 s, accu: 0.8611444234848022, loss_yt: 0.39259105920791626\n",
      "epocht 5, batch_num 1200, step 187201, time: 50.15986633300781 s, accu: 0.8611472845077515, loss_yt: 0.21004116535186768\n",
      "epocht 5, batch_num 1400, step 187401, time: 58.59831500053406 s, accu: 0.8611451387405396, loss_yt: 0.3815728724002838\n",
      "epocht 5, batch_num 1600, step 187601, time: 67.20927262306213 s, accu: 0.8611450791358948, loss_yt: 0.585241973400116\n",
      "epocht 5, batch_num 1800, step 187801, time: 75.69657754898071 s, accu: 0.8611465096473694, loss_yt: 0.345310777425766\n",
      "epocht 5, batch_num 2000, step 188001, time: 84.08215403556824 s, accu: 0.8611465692520142, loss_yt: 0.3407292068004608\n",
      "epocht 5, batch_num 2200, step 188201, time: 92.44279909133911 s, accu: 0.8611493110656738, loss_yt: 0.45246633887290955\n",
      "epocht 5, batch_num 2400, step 188401, time: 101.02484893798828 s, accu: 0.8611493706703186, loss_yt: 0.32881051301956177\n",
      "epocht 5, batch_num 2600, step 188601, time: 109.20597648620605 s, accu: 0.861149251461029, loss_yt: 0.34467992186546326\n",
      "epocht 5, batch_num 2800, step 188801, time: 117.9426097869873 s, accu: 0.8611412644386292, loss_yt: 0.2517082691192627\n",
      "epocht 5, batch_num 3000, step 189001, time: 126.37506246566772 s, accu: 0.8611437082290649, loss_yt: 0.15637797117233276\n",
      "epocht 5, batch_num 3200, step 189201, time: 134.65392398834229 s, accu: 0.8611471652984619, loss_yt: 0.16893234848976135\n",
      "epocht 5, batch_num 3400, step 189401, time: 143.07839608192444 s, accu: 0.8611482381820679, loss_yt: 0.2967044711112976\n",
      "epocht 5, batch_num 3600, step 189601, time: 151.5756893157959 s, accu: 0.8611524105072021, loss_yt: 0.2596947252750397\n",
      "epocht 5, batch_num 3800, step 189801, time: 159.9133803844452 s, accu: 0.8611496686935425, loss_yt: 0.2668645679950714\n",
      "epocht 5, batch_num 4000, step 190001, time: 168.20520901679993 s, accu: 0.8611503839492798, loss_yt: 0.2938281297683716\n",
      "epocht 5, batch_num 4200, step 190201, time: 176.43619775772095 s, accu: 0.8611561059951782, loss_yt: 0.22028665244579315\n",
      "epocht 5, batch_num 4400, step 190401, time: 185.0471706390381 s, accu: 0.8611530065536499, loss_yt: 0.4720805287361145\n",
      "epocht 5, batch_num 4600, step 190601, time: 193.44172430038452 s, accu: 0.86115562915802, loss_yt: 0.28398990631103516\n",
      "epocht 5, batch_num 4800, step 190801, time: 201.44335412979126 s, accu: 0.8611613512039185, loss_yt: 0.677447497844696\n",
      "epocht 5, batch_num 5000, step 191001, time: 209.86381101608276 s, accu: 0.8611640334129333, loss_yt: 0.31051790714263916\n",
      "epocht 5, batch_num 5200, step 191201, time: 218.0000560283661 s, accu: 0.8611654043197632, loss_yt: 0.24792613089084625\n",
      "epocht 5, batch_num 5400, step 191401, time: 226.32183480262756 s, accu: 0.8611727356910706, loss_yt: 0.20780381560325623\n",
      "epocht 5, batch_num 5600, step 191601, time: 234.34636425971985 s, accu: 0.8611779808998108, loss_yt: 0.1458480805158615\n",
      "epocht 5, batch_num 5800, step 191801, time: 242.5853135585785 s, accu: 0.8611798286437988, loss_yt: 0.2770704925060272\n",
      "epocht 5, batch_num 6000, step 192001, time: 251.11450719833374 s, accu: 0.8611833453178406, loss_yt: 0.19237220287322998\n",
      "epocht 5, batch_num 6200, step 192201, time: 259.1958968639374 s, accu: 0.8611884117126465, loss_yt: 0.42293623089790344\n",
      "epocht 5, batch_num 6400, step 192401, time: 267.25634360313416 s, accu: 0.8611947894096375, loss_yt: 0.25229257345199585\n",
      "epocht 5, batch_num 6600, step 192601, time: 275.3038249015808 s, accu: 0.8611952066421509, loss_yt: 0.253939151763916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 5, batch_num 6800, step 192801, time: 283.6226122379303 s, accu: 0.8611996173858643, loss_yt: 0.31756412982940674\n",
      "epocht 5, batch_num 7000, step 193001, time: 291.6122143268585 s, accu: 0.8612012267112732, loss_yt: 0.31945887207984924\n",
      "epocht 5, batch_num 7200, step 193201, time: 299.6866252422333 s, accu: 0.8612080216407776, loss_yt: 0.35138416290283203\n",
      "epocht 5, batch_num 7400, step 193401, time: 307.88869071006775 s, accu: 0.8612155318260193, loss_yt: 0.43586239218711853\n",
      "iter_validnum 1860\n",
      "epochv 5, step 193440, stop_n 0, time: 367.4992907047272 s, accu_va: 0.8612251221492726, loss_yv: 0.30110920040758066\n",
      "iter_trainnum 7440\n",
      "epocht 5, batch_num 0, step 193441, time: 0.6562473773956299 s, accu: 0.8612332940101624, loss_yt: 0.2548524737358093\n",
      "epocht 5, batch_num 200, step 193641, time: 8.86030912399292 s, accu: 0.861237645149231, loss_yt: 0.3164549171924591\n",
      "epocht 5, batch_num 400, step 193841, time: 16.910781383514404 s, accu: 0.8612343072891235, loss_yt: 0.3449763059616089\n",
      "epocht 5, batch_num 600, step 194041, time: 24.94330382347107 s, accu: 0.8612368702888489, loss_yt: 0.18542443215847015\n",
      "epocht 5, batch_num 800, step 194241, time: 32.73150372505188 s, accu: 0.8612366318702698, loss_yt: 0.33471769094467163\n",
      "epocht 5, batch_num 1000, step 194441, time: 40.37404155731201 s, accu: 0.861240029335022, loss_yt: 0.23549649119377136\n",
      "epocht 5, batch_num 1200, step 194641, time: 48.38661575317383 s, accu: 0.8612467050552368, loss_yt: 0.2583138048648834\n",
      "epocht 5, batch_num 1400, step 194841, time: 56.401214838027954 s, accu: 0.8612495064735413, loss_yt: 0.5187538862228394\n",
      "epocht 5, batch_num 1600, step 195041, time: 64.48157525062561 s, accu: 0.8612536191940308, loss_yt: 0.28079086542129517\n",
      "epocht 5, batch_num 1800, step 195241, time: 72.64773869514465 s, accu: 0.8612573742866516, loss_yt: 0.22755694389343262\n",
      "epocht 5, batch_num 2000, step 195441, time: 80.35114073753357 s, accu: 0.8612578511238098, loss_yt: 0.36276185512542725\n",
      "epocht 5, batch_num 2200, step 195641, time: 88.30088353157043 s, accu: 0.861257791519165, loss_yt: 0.2107360064983368\n",
      "epocht 5, batch_num 2400, step 195841, time: 95.95644426345825 s, accu: 0.8612619638442993, loss_yt: 0.25840258598327637\n",
      "epocht 5, batch_num 2600, step 196041, time: 103.8872058391571 s, accu: 0.8612716794013977, loss_yt: 0.31485018134117126\n",
      "epocht 5, batch_num 2800, step 196241, time: 111.84994888305664 s, accu: 0.86127108335495, loss_yt: 0.3257245123386383\n",
      "epocht 5, batch_num 3000, step 196441, time: 119.57924461364746 s, accu: 0.8612760901451111, loss_yt: 0.3254036009311676\n",
      "epocht 5, batch_num 3200, step 196641, time: 127.43822932243347 s, accu: 0.861280620098114, loss_yt: 0.2535143792629242\n",
      "epocht 5, batch_num 3400, step 196841, time: 135.14462041854858 s, accu: 0.8612856268882751, loss_yt: 0.37513604760169983\n",
      "epocht 5, batch_num 3600, step 197041, time: 142.99064111709595 s, accu: 0.8612887263298035, loss_yt: 0.2635015547275543\n",
      "epocht 5, batch_num 3800, step 197241, time: 150.67911410331726 s, accu: 0.8612934350967407, loss_yt: 0.31782132387161255\n",
      "epocht 5, batch_num 4000, step 197441, time: 158.74354934692383 s, accu: 0.8612926602363586, loss_yt: 0.3292554020881653\n",
      "epocht 5, batch_num 4200, step 197641, time: 166.6304268836975 s, accu: 0.8612964153289795, loss_yt: 0.2214111089706421\n",
      "epocht 5, batch_num 4400, step 197841, time: 174.70483589172363 s, accu: 0.8612974882125854, loss_yt: 0.37621307373046875\n",
      "epocht 5, batch_num 4600, step 198041, time: 182.69347620010376 s, accu: 0.8613012433052063, loss_yt: 0.4790599048137665\n",
      "epocht 5, batch_num 4800, step 198241, time: 190.53650283813477 s, accu: 0.8613020777702332, loss_yt: 0.2469189167022705\n",
      "epocht 5, batch_num 5000, step 198441, time: 198.49126315116882 s, accu: 0.8613010048866272, loss_yt: 0.24701526761054993\n",
      "epocht 5, batch_num 5200, step 198641, time: 206.21957397460938 s, accu: 0.861306369304657, loss_yt: 0.4454522132873535\n",
      "epocht 5, batch_num 5400, step 198841, time: 214.28998374938965 s, accu: 0.8613023161888123, loss_yt: 0.28079116344451904\n",
      "epocht 5, batch_num 5600, step 199041, time: 222.47509670257568 s, accu: 0.8613059520721436, loss_yt: 0.25143083930015564\n",
      "epocht 5, batch_num 5800, step 199241, time: 230.70612621307373 s, accu: 0.8613064289093018, loss_yt: 0.27894970774650574\n",
      "epocht 5, batch_num 6000, step 199441, time: 238.7565598487854 s, accu: 0.8613123893737793, loss_yt: 0.8526006937026978\n",
      "epocht 5, batch_num 6200, step 199641, time: 246.38020706176758 s, accu: 0.8613184690475464, loss_yt: 0.30268430709838867\n",
      "epocht 5, batch_num 6400, step 199841, time: 254.25411868095398 s, accu: 0.8613196611404419, loss_yt: 0.5723987817764282\n",
      "epocht 5, batch_num 6600, step 200041, time: 262.0662293434143 s, accu: 0.8613170981407166, loss_yt: 0.37715333700180054\n",
      "epocht 5, batch_num 6800, step 200241, time: 269.93821382522583 s, accu: 0.8613208532333374, loss_yt: 0.1724163144826889\n",
      "epocht 5, batch_num 7000, step 200441, time: 278.16020107269287 s, accu: 0.8613207936286926, loss_yt: 0.307329386472702\n",
      "epocht 5, batch_num 7200, step 200641, time: 285.84464597702026 s, accu: 0.8613284230232239, loss_yt: 0.28143104910850525\n",
      "epocht 5, batch_num 7400, step 200841, time: 293.7375395298004 s, accu: 0.861335277557373, loss_yt: 0.3414696455001831\n",
      "iter_validnum 1860\n",
      "epochv 5, step 200880, stop_n 0, time: 349.8644549846649 s, accu_va: 0.8613424522261466, loss_yv: 0.3031608352738042\n",
      "iter_trainnum 7440\n",
      "epocht 5, batch_num 0, step 200881, time: 0.3461015224456787 s, accu: 0.861348032951355, loss_yt: 0.1911075860261917\n",
      "epocht 5, batch_num 200, step 201081, time: 8.05545425415039 s, accu: 0.8613517880439758, loss_yt: 0.23225577175617218\n",
      "epocht 5, batch_num 400, step 201281, time: 15.943388223648071 s, accu: 0.8613548874855042, loss_yt: 0.3054130971431732\n",
      "epocht 5, batch_num 600, step 201481, time: 24.076617002487183 s, accu: 0.8613573312759399, loss_yt: 0.27713510394096375\n",
      "epocht 5, batch_num 800, step 201681, time: 32.32754945755005 s, accu: 0.8613554239273071, loss_yt: 0.15328025817871094\n",
      "epocht 5, batch_num 1000, step 201881, time: 40.200523138046265 s, accu: 0.861355721950531, loss_yt: 0.16849127411842346\n",
      "epocht 5, batch_num 1200, step 202081, time: 48.0564911365509 s, accu: 0.8613649606704712, loss_yt: 0.3591143786907196\n",
      "epocht 5, batch_num 1400, step 202281, time: 55.61627531051636 s, accu: 0.861370861530304, loss_yt: 0.30825677514076233\n",
      "epocht 5, batch_num 1600, step 202481, time: 63.616880893707275 s, accu: 0.8613688349723816, loss_yt: 0.2966604232788086\n",
      "epocht 5, batch_num 1800, step 202681, time: 71.45695185661316 s, accu: 0.8613734245300293, loss_yt: 0.3187078535556793\n",
      "epocht 5, batch_num 2000, step 202881, time: 79.42261862754822 s, accu: 0.861377477645874, loss_yt: 0.2768232524394989\n",
      "epocht 5, batch_num 2200, step 203081, time: 87.38435888290405 s, accu: 0.8613827228546143, loss_yt: 0.3894365727901459\n",
      "epocht 5, batch_num 2400, step 203281, time: 95.1067099571228 s, accu: 0.8613858222961426, loss_yt: 0.2765941917896271\n",
      "epocht 5, batch_num 2600, step 203481, time: 103.00156545639038 s, accu: 0.8613930940628052, loss_yt: 0.1547919362783432\n",
      "epocht 5, batch_num 2800, step 203681, time: 110.72192168235779 s, accu: 0.861392617225647, loss_yt: 0.29125016927719116\n",
      "epocht 5, batch_num 3000, step 203881, time: 118.80131673812866 s, accu: 0.8613954186439514, loss_yt: 0.3002914488315582\n",
      "epocht 5, batch_num 3200, step 204081, time: 126.76103401184082 s, accu: 0.8613954782485962, loss_yt: 0.22672583162784576\n",
      "epocht 5, batch_num 3400, step 204281, time: 134.6688871383667 s, accu: 0.8613978028297424, loss_yt: 0.21064920723438263\n",
      "epocht 5, batch_num 3600, step 204481, time: 142.62760424613953 s, accu: 0.8613983392715454, loss_yt: 0.3389143943786621\n",
      "epocht 5, batch_num 3800, step 204681, time: 150.43173623085022 s, accu: 0.8613921999931335, loss_yt: 0.18499885499477386\n",
      "epocht 5, batch_num 4000, step 204881, time: 158.5031909942627 s, accu: 0.8613882660865784, loss_yt: 0.3549109399318695\n",
      "epocht 5, batch_num 4200, step 205081, time: 166.24944043159485 s, accu: 0.8613904714584351, loss_yt: 0.3040259778499603\n",
      "epocht 5, batch_num 4400, step 205281, time: 174.11241340637207 s, accu: 0.8613970875740051, loss_yt: 0.17332421243190765\n",
      "epocht 5, batch_num 4600, step 205481, time: 181.8846299648285 s, accu: 0.861399233341217, loss_yt: 0.4569762051105499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 5, batch_num 4800, step 205681, time: 189.90119576454163 s, accu: 0.8613993525505066, loss_yt: 0.24022017419338226\n",
      "epocht 5, batch_num 5000, step 205881, time: 197.88388180732727 s, accu: 0.8614006638526917, loss_yt: 0.3700058162212372\n",
      "epocht 5, batch_num 5200, step 206081, time: 205.6680371761322 s, accu: 0.8614023923873901, loss_yt: 0.3673359751701355\n",
      "epocht 5, batch_num 5400, step 206281, time: 213.54198002815247 s, accu: 0.861402153968811, loss_yt: 0.27400583028793335\n",
      "epocht 5, batch_num 5600, step 206481, time: 221.3879988193512 s, accu: 0.8614069819450378, loss_yt: 0.4061902165412903\n",
      "epocht 5, batch_num 5800, step 206681, time: 229.5172634124756 s, accu: 0.8614110946655273, loss_yt: 0.3303207755088806\n",
      "epocht 5, batch_num 6000, step 206881, time: 237.2874960899353 s, accu: 0.8614149689674377, loss_yt: 0.3078581988811493\n",
      "epocht 5, batch_num 6200, step 207081, time: 245.13848972320557 s, accu: 0.8614156246185303, loss_yt: 0.24711135029792786\n",
      "epocht 5, batch_num 6400, step 207281, time: 253.08324432373047 s, accu: 0.8614211082458496, loss_yt: 0.22433696687221527\n",
      "epocht 5, batch_num 6600, step 207481, time: 261.12573862075806 s, accu: 0.8614222407341003, loss_yt: 0.32406049966812134\n",
      "epocht 5, batch_num 6800, step 207681, time: 268.9887454509735 s, accu: 0.8614233136177063, loss_yt: 0.22387340664863586\n",
      "epocht 5, batch_num 7000, step 207881, time: 276.7768862247467 s, accu: 0.8614271879196167, loss_yt: 0.15083763003349304\n",
      "epocht 5, batch_num 7200, step 208081, time: 284.7964427471161 s, accu: 0.8614290952682495, loss_yt: 0.2931535542011261\n",
      "epocht 5, batch_num 7400, step 208281, time: 292.59359192848206 s, accu: 0.8614317774772644, loss_yt: 0.27702438831329346\n",
      "iter_validnum 1860\n",
      "epochv 5, step 208320, stop_n 0, time: 348.321576833725 s, accu_va: 0.861438319054983, loss_yv: 0.2968715549356514\n",
      "iter_trainnum 7440\n",
      "epocht 5, batch_num 0, step 208321, time: 0.3301503658294678 s, accu: 0.8614557385444641, loss_yt: 0.29080823063850403\n",
      "epocht 5, batch_num 200, step 208521, time: 8.42945671081543 s, accu: 0.8614560961723328, loss_yt: 0.2144050896167755\n",
      "epocht 5, batch_num 400, step 208721, time: 16.13285803794861 s, accu: 0.8614600896835327, loss_yt: 0.3755311369895935\n",
      "epocht 5, batch_num 600, step 208921, time: 24.149420738220215 s, accu: 0.8614621162414551, loss_yt: 0.48568037152290344\n",
      "epocht 5, batch_num 800, step 209121, time: 32.473164796829224 s, accu: 0.8614620566368103, loss_yt: 0.2959534227848053\n",
      "epocht 5, batch_num 1000, step 209321, time: 40.43786573410034 s, accu: 0.861469030380249, loss_yt: 0.17735037207603455\n",
      "epocht 5, batch_num 1200, step 209521, time: 48.241997957229614 s, accu: 0.8614691495895386, loss_yt: 0.15201173722743988\n",
      "epocht 5, batch_num 1400, step 209721, time: 56.06709337234497 s, accu: 0.861471951007843, loss_yt: 0.5335984230041504\n",
      "epocht 5, batch_num 1600, step 209921, time: 64.01881098747253 s, accu: 0.861473023891449, loss_yt: 0.2530129849910736\n",
      "epocht 5, batch_num 1800, step 210121, time: 71.72723937034607 s, accu: 0.8614736795425415, loss_yt: 0.31482037901878357\n",
      "epocht 5, batch_num 2000, step 210321, time: 79.52933382987976 s, accu: 0.8614733219146729, loss_yt: 0.32323870062828064\n",
      "epocht 5, batch_num 2200, step 210521, time: 87.73439359664917 s, accu: 0.8614760041236877, loss_yt: 0.26048973202705383\n",
      "epocht 5, batch_num 2400, step 210721, time: 95.76591944694519 s, accu: 0.861476719379425, loss_yt: 0.38296326994895935\n",
      "epocht 5, batch_num 2600, step 210921, time: 103.57403993606567 s, accu: 0.8614770770072937, loss_yt: 0.14317838847637177\n",
      "epocht 5, batch_num 2800, step 211121, time: 111.53774309158325 s, accu: 0.8614820837974548, loss_yt: 0.4401821196079254\n",
      "epocht 5, batch_num 3000, step 211321, time: 119.54632830619812 s, accu: 0.8614799976348877, loss_yt: 0.4897027313709259\n",
      "epocht 5, batch_num 3200, step 211521, time: 127.44520807266235 s, accu: 0.8614765405654907, loss_yt: 0.4062730669975281\n",
      "epocht 5, batch_num 3400, step 211721, time: 135.39495134353638 s, accu: 0.8614820241928101, loss_yt: 0.24942536652088165\n",
      "epocht 5, batch_num 3600, step 211921, time: 143.31576824188232 s, accu: 0.8614838123321533, loss_yt: 0.3710656464099884\n",
      "epocht 5, batch_num 3800, step 212121, time: 151.03811979293823 s, accu: 0.8614879846572876, loss_yt: 0.3686050474643707\n",
      "epocht 5, batch_num 4000, step 212321, time: 159.21226024627686 s, accu: 0.8614906072616577, loss_yt: 0.301131010055542\n",
      "epocht 5, batch_num 4200, step 212521, time: 167.22882509231567 s, accu: 0.8614945411682129, loss_yt: 0.2427774965763092\n",
      "epocht 5, batch_num 4400, step 212721, time: 175.1686191558838 s, accu: 0.8615003228187561, loss_yt: 0.23744207620620728\n",
      "epocht 5, batch_num 4600, step 212921, time: 182.99068069458008 s, accu: 0.8614979386329651, loss_yt: 0.36384978890419006\n",
      "epocht 5, batch_num 4800, step 213121, time: 191.10098886489868 s, accu: 0.8614947199821472, loss_yt: 0.36415842175483704\n",
      "epocht 5, batch_num 5000, step 213321, time: 199.05474758148193 s, accu: 0.8614975214004517, loss_yt: 0.2473592758178711\n",
      "epocht 5, batch_num 5200, step 213521, time: 206.95659160614014 s, accu: 0.861497700214386, loss_yt: 0.29233479499816895\n",
      "epocht 5, batch_num 5400, step 213721, time: 215.00109887123108 s, accu: 0.8614981770515442, loss_yt: 0.22944968938827515\n",
      "epocht 5, batch_num 5600, step 213921, time: 223.0994267463684 s, accu: 0.8615023493766785, loss_yt: 0.3752724528312683\n",
      "epocht 5, batch_num 5800, step 214121, time: 231.17184138298035 s, accu: 0.8615022897720337, loss_yt: 0.3226131498813629\n",
      "epocht 5, batch_num 6000, step 214321, time: 238.9280984401703 s, accu: 0.861504077911377, loss_yt: 0.3369126617908478\n",
      "epocht 5, batch_num 6200, step 214521, time: 246.8050684928894 s, accu: 0.8615083694458008, loss_yt: 0.3240193724632263\n",
      "epocht 5, batch_num 6400, step 214721, time: 254.67399311065674 s, accu: 0.8615113496780396, loss_yt: 0.2349967658519745\n",
      "epocht 5, batch_num 6600, step 214921, time: 262.4851064682007 s, accu: 0.8615134954452515, loss_yt: 0.16935907304286957\n",
      "epocht 5, batch_num 6800, step 215121, time: 270.4607813358307 s, accu: 0.8615167737007141, loss_yt: 0.30033549666404724\n",
      "epocht 5, batch_num 7000, step 215321, time: 278.34671998023987 s, accu: 0.8615238070487976, loss_yt: 0.4325554072856903\n",
      "epocht 5, batch_num 7200, step 215521, time: 286.5876567363739 s, accu: 0.8615246415138245, loss_yt: 0.34201377630233765\n",
      "epocht 5, batch_num 7400, step 215721, time: 294.27214074134827 s, accu: 0.8615298867225647, loss_yt: 0.22446784377098083\n",
      "iter_validnum 1860\n",
      "epochv 5, step 215760, stop_n 0, time: 350.03801822662354 s, accu_va: 0.8615397970202149, loss_yv: 0.29823801853964405\n",
      "iter_trainnum 7440\n",
      "epocht 5, batch_num 0, step 215761, time: 0.5305807590484619 s, accu: 0.861557126045227, loss_yt: 0.33051398396492004\n",
      "epocht 5, batch_num 200, step 215961, time: 8.528202295303345 s, accu: 0.8615609407424927, loss_yt: 0.2848982810974121\n",
      "epocht 5, batch_num 400, step 216161, time: 16.393165111541748 s, accu: 0.8615638017654419, loss_yt: 0.35091862082481384\n",
      "epocht 5, batch_num 600, step 216361, time: 24.296032905578613 s, accu: 0.8615636825561523, loss_yt: 0.5192552804946899\n",
      "epocht 5, batch_num 800, step 216561, time: 31.910695791244507 s, accu: 0.8615707159042358, loss_yt: 0.3177769184112549\n",
      "epocht 5, batch_num 1000, step 216761, time: 39.7377667427063 s, accu: 0.8615733981132507, loss_yt: 0.6930235624313354\n",
      "epocht 5, batch_num 1200, step 216961, time: 47.55483794212341 s, accu: 0.8615730404853821, loss_yt: 0.2415185570716858\n",
      "epocht 5, batch_num 1400, step 217161, time: 55.838685274124146 s, accu: 0.861574649810791, loss_yt: 0.3377019762992859\n",
      "epocht 5, batch_num 1600, step 217361, time: 64.07167053222656 s, accu: 0.861575722694397, loss_yt: 0.2841986119747162\n",
      "epocht 5, batch_num 1800, step 217561, time: 71.88378047943115 s, accu: 0.8615776896476746, loss_yt: 0.2678750455379486\n",
      "epocht 5, batch_num 2000, step 217761, time: 79.88142228126526 s, accu: 0.861575722694397, loss_yt: 0.19400498270988464\n",
      "epocht 5, batch_num 2200, step 217961, time: 87.60773491859436 s, accu: 0.8615809679031372, loss_yt: 0.32510942220687866\n",
      "epocht 5, batch_num 2400, step 218161, time: 95.66921162605286 s, accu: 0.8615807294845581, loss_yt: 0.3066016733646393\n",
      "epocht 5, batch_num 2600, step 218361, time: 103.35961365699768 s, accu: 0.8615840077400208, loss_yt: 0.24927058815956116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 5, batch_num 2800, step 218561, time: 111.17574858665466 s, accu: 0.8615874648094177, loss_yt: 0.36104127764701843\n",
      "epocht 5, batch_num 3000, step 218761, time: 119.23419260978699 s, accu: 0.8615913391113281, loss_yt: 0.2540806233882904\n",
      "epocht 5, batch_num 3200, step 218961, time: 127.14604187011719 s, accu: 0.8615925312042236, loss_yt: 0.36135002970695496\n",
      "epocht 5, batch_num 3400, step 219161, time: 135.0429286956787 s, accu: 0.8615999817848206, loss_yt: 0.2481435239315033\n",
      "epocht 5, batch_num 3600, step 219361, time: 142.96969723701477 s, accu: 0.8615987300872803, loss_yt: 0.3395672142505646\n",
      "epocht 5, batch_num 3800, step 219561, time: 150.85261607170105 s, accu: 0.8616015911102295, loss_yt: 0.1285366415977478\n",
      "epocht 5, batch_num 4000, step 219761, time: 158.9768934249878 s, accu: 0.8616020083427429, loss_yt: 0.36698952317237854\n",
      "epocht 5, batch_num 4200, step 219961, time: 166.7501344680786 s, accu: 0.8616083860397339, loss_yt: 0.25338977575302124\n",
      "epocht 5, batch_num 4400, step 220161, time: 174.65998673439026 s, accu: 0.8616093397140503, loss_yt: 0.27124351263046265\n",
      "epocht 5, batch_num 4600, step 220361, time: 182.41423845291138 s, accu: 0.861611008644104, loss_yt: 0.17177274823188782\n",
      "epocht 5, batch_num 4800, step 220561, time: 190.50857615470886 s, accu: 0.861616313457489, loss_yt: 0.27260032296180725\n",
      "epocht 5, batch_num 5000, step 220761, time: 198.34262776374817 s, accu: 0.861617386341095, loss_yt: 0.18315593898296356\n",
      "epocht 5, batch_num 5200, step 220961, time: 206.09290480613708 s, accu: 0.861621081829071, loss_yt: 0.3631680905818939\n",
      "epocht 5, batch_num 5400, step 221161, time: 213.89603805541992 s, accu: 0.861617386341095, loss_yt: 0.3384877145290375\n",
      "epocht 5, batch_num 5600, step 221361, time: 222.04826664924622 s, accu: 0.8616210222244263, loss_yt: 0.2576049268245697\n",
      "epocht 5, batch_num 5800, step 221561, time: 230.31416749954224 s, accu: 0.8616189956665039, loss_yt: 0.34222397208213806\n",
      "epocht 5, batch_num 6000, step 221761, time: 238.18212747573853 s, accu: 0.8616214394569397, loss_yt: 0.2687396705150604\n",
      "epocht 5, batch_num 6200, step 221961, time: 246.0720248222351 s, accu: 0.8616244792938232, loss_yt: 0.23611220717430115\n",
      "epocht 5, batch_num 6400, step 222161, time: 253.7764151096344 s, accu: 0.8616247773170471, loss_yt: 0.15988831222057343\n",
      "epocht 5, batch_num 6600, step 222361, time: 261.5915358066559 s, accu: 0.8616256713867188, loss_yt: 0.39607444405555725\n",
      "epocht 5, batch_num 6800, step 222561, time: 269.4844183921814 s, accu: 0.861625075340271, loss_yt: 0.2858370840549469\n",
      "epocht 5, batch_num 7000, step 222761, time: 277.260600566864 s, accu: 0.8616283535957336, loss_yt: 0.32723063230514526\n",
      "epocht 5, batch_num 7200, step 222961, time: 285.0118725299835 s, accu: 0.8616382479667664, loss_yt: 0.2360737919807434\n",
      "epocht 5, batch_num 7400, step 223161, time: 292.74423933029175 s, accu: 0.8616414070129395, loss_yt: 0.3362378776073456\n",
      "iter_validnum 1860\n",
      "epochv 5, step 223200, stop_n 0, time: 348.5579478740692 s, accu_va: 0.8616457837243234, loss_yv: 0.29858298317719534\n",
      "iter_trainnum 7440\n",
      "epocht 6, batch_num 0, step 223201, time: 0.47472691535949707 s, accu: 0.8616586327552795, loss_yt: 0.37522295117378235\n",
      "epocht 6, batch_num 200, step 223401, time: 8.508270263671875 s, accu: 0.8616628050804138, loss_yt: 0.38475117087364197\n",
      "epocht 6, batch_num 400, step 223601, time: 16.181726217269897 s, accu: 0.8616620302200317, loss_yt: 0.3810940980911255\n",
      "epocht 6, batch_num 600, step 223801, time: 23.863184690475464 s, accu: 0.861661970615387, loss_yt: 0.36663493514060974\n",
      "epocht 6, batch_num 800, step 224001, time: 31.500762701034546 s, accu: 0.8616660833358765, loss_yt: 0.3035150170326233\n",
      "epocht 6, batch_num 1000, step 224201, time: 39.024669885635376 s, accu: 0.8616663813591003, loss_yt: 0.31737080216407776\n",
      "epocht 6, batch_num 1200, step 224401, time: 46.855730056762695 s, accu: 0.861667811870575, loss_yt: 0.35845229029655457\n",
      "epocht 6, batch_num 1400, step 224601, time: 54.663856983184814 s, accu: 0.8616690039634705, loss_yt: 0.1800428181886673\n",
      "epocht 6, batch_num 1600, step 224801, time: 62.61456298828125 s, accu: 0.8616624474525452, loss_yt: 0.3512836992740631\n",
      "epocht 6, batch_num 1800, step 225001, time: 70.45659303665161 s, accu: 0.8616679310798645, loss_yt: 0.2954043447971344\n",
      "epocht 6, batch_num 2000, step 225201, time: 78.2278401851654 s, accu: 0.8616725206375122, loss_yt: 0.1398339420557022\n",
      "epocht 6, batch_num 2200, step 225401, time: 85.74271774291992 s, accu: 0.8616765141487122, loss_yt: 0.313126802444458\n",
      "epocht 6, batch_num 2400, step 225601, time: 93.2386839389801 s, accu: 0.8616811633110046, loss_yt: 0.23452919721603394\n",
      "epocht 6, batch_num 2600, step 225801, time: 101.1624858379364 s, accu: 0.8616815805435181, loss_yt: 0.31704795360565186\n",
      "epocht 6, batch_num 2800, step 226001, time: 109.16010117530823 s, accu: 0.8616840839385986, loss_yt: 0.2777552902698517\n",
      "epocht 6, batch_num 3000, step 226201, time: 117.04302191734314 s, accu: 0.8616862297058105, loss_yt: 0.24632027745246887\n",
      "epocht 6, batch_num 3200, step 226401, time: 125.10947728157043 s, accu: 0.8616856336593628, loss_yt: 0.3254145681858063\n",
      "epocht 6, batch_num 3400, step 226601, time: 132.7649793624878 s, accu: 0.8616858720779419, loss_yt: 0.520024299621582\n",
      "epocht 6, batch_num 3600, step 226801, time: 140.47137594223022 s, accu: 0.8616889715194702, loss_yt: 0.37597164511680603\n",
      "epocht 6, batch_num 3800, step 227001, time: 148.08202481269836 s, accu: 0.8616933822631836, loss_yt: 0.11889471858739853\n",
      "epocht 6, batch_num 4000, step 227201, time: 155.8024034500122 s, accu: 0.8616988062858582, loss_yt: 0.5478998422622681\n",
      "epocht 6, batch_num 4200, step 227401, time: 163.77505946159363 s, accu: 0.8616957664489746, loss_yt: 0.2653612196445465\n",
      "epocht 6, batch_num 4400, step 227601, time: 171.68291330337524 s, accu: 0.8616975545883179, loss_yt: 0.29803594946861267\n",
      "epocht 6, batch_num 4600, step 227801, time: 179.50103306770325 s, accu: 0.8616986870765686, loss_yt: 0.4605333209037781\n",
      "epocht 6, batch_num 4800, step 228001, time: 187.3291027545929 s, accu: 0.8616986870765686, loss_yt: 0.40773043036460876\n",
      "epocht 6, batch_num 5000, step 228201, time: 194.93972444534302 s, accu: 0.8617061376571655, loss_yt: 0.1993151307106018\n",
      "epocht 6, batch_num 5200, step 228401, time: 202.7009961605072 s, accu: 0.8617061376571655, loss_yt: 0.32215237617492676\n",
      "epocht 6, batch_num 5400, step 228601, time: 210.7983169555664 s, accu: 0.8617067337036133, loss_yt: 0.27872318029403687\n",
      "epocht 6, batch_num 5600, step 228801, time: 218.71514654159546 s, accu: 0.8617088198661804, loss_yt: 0.26689860224723816\n",
      "epocht 6, batch_num 5800, step 229001, time: 226.4793860912323 s, accu: 0.861709475517273, loss_yt: 0.3095411956310272\n",
      "epocht 6, batch_num 6000, step 229201, time: 234.08404994010925 s, accu: 0.8617129921913147, loss_yt: 0.24741512537002563\n",
      "epocht 6, batch_num 6200, step 229401, time: 241.99389934539795 s, accu: 0.8617135286331177, loss_yt: 0.2570804953575134\n",
      "epocht 6, batch_num 6400, step 229601, time: 249.77013301849365 s, accu: 0.8617177605628967, loss_yt: 0.37469902634620667\n",
      "epocht 6, batch_num 6600, step 229801, time: 257.5014581680298 s, accu: 0.8617223501205444, loss_yt: 0.18099218606948853\n",
      "epocht 6, batch_num 6800, step 230001, time: 265.5199890136719 s, accu: 0.8617225289344788, loss_yt: 0.271413117647171\n",
      "epocht 6, batch_num 7000, step 230201, time: 273.3480587005615 s, accu: 0.8617250919342041, loss_yt: 0.4757324457168579\n",
      "epocht 6, batch_num 7200, step 230401, time: 281.26791310310364 s, accu: 0.8617244362831116, loss_yt: 0.37531009316444397\n",
      "epocht 6, batch_num 7400, step 230601, time: 289.00519371032715 s, accu: 0.8617339730262756, loss_yt: 0.27511075139045715\n",
      "iter_validnum 1860\n",
      "epochv 6, step 230640, stop_n 0, time: 344.33224606513977 s, accu_va: 0.8617433748258058, loss_yv: 0.3010731090120571\n",
      "iter_trainnum 7440\n",
      "epocht 6, batch_num 0, step 230641, time: 0.44081926345825195 s, accu: 0.8617466688156128, loss_yt: 0.2298569232225418\n",
      "epocht 6, batch_num 200, step 230841, time: 8.165166139602661 s, accu: 0.8617500066757202, loss_yt: 0.24360114336013794\n",
      "epocht 6, batch_num 400, step 231041, time: 15.982262372970581 s, accu: 0.8617518544197083, loss_yt: 0.24481572210788727\n",
      "epocht 6, batch_num 600, step 231241, time: 24.042708158493042 s, accu: 0.8617523312568665, loss_yt: 0.31745004653930664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 6, batch_num 800, step 231441, time: 31.934633016586304 s, accu: 0.8617525696754456, loss_yt: 0.2381875365972519\n",
      "epocht 6, batch_num 1000, step 231641, time: 39.67191410064697 s, accu: 0.8617559671401978, loss_yt: 0.13241860270500183\n",
      "epocht 6, batch_num 1200, step 231841, time: 47.321491956710815 s, accu: 0.8617609739303589, loss_yt: 0.5550335049629211\n",
      "epocht 6, batch_num 1400, step 232041, time: 55.37592148780823 s, accu: 0.8617662787437439, loss_yt: 0.31361034512519836\n",
      "epocht 6, batch_num 1600, step 232241, time: 63.23690152168274 s, accu: 0.8617674112319946, loss_yt: 0.32926255464553833\n",
      "epocht 6, batch_num 1800, step 232441, time: 71.00413131713867 s, accu: 0.8617711067199707, loss_yt: 0.3378317654132843\n",
      "epocht 6, batch_num 2000, step 232641, time: 78.96484565734863 s, accu: 0.8617722392082214, loss_yt: 0.2917417287826538\n",
      "epocht 6, batch_num 2200, step 232841, time: 86.91358876228333 s, accu: 0.8617724180221558, loss_yt: 0.47468411922454834\n",
      "epocht 6, batch_num 2400, step 233041, time: 94.572110414505 s, accu: 0.8617748022079468, loss_yt: 0.4650094211101532\n",
      "epocht 6, batch_num 2600, step 233241, time: 102.12391757965088 s, accu: 0.8617767095565796, loss_yt: 0.1981755644083023\n",
      "epocht 6, batch_num 2800, step 233441, time: 109.8532485961914 s, accu: 0.8617799282073975, loss_yt: 0.27369585633277893\n",
      "epocht 6, batch_num 3000, step 233641, time: 117.87185049057007 s, accu: 0.861782968044281, loss_yt: 0.5155648589134216\n",
      "epocht 6, batch_num 3200, step 233841, time: 125.59219646453857 s, accu: 0.8617845773696899, loss_yt: 0.32483962178230286\n",
      "epocht 6, batch_num 3400, step 234041, time: 133.44219660758972 s, accu: 0.8617843389511108, loss_yt: 0.19331780076026917\n",
      "epocht 6, batch_num 3600, step 234241, time: 141.18745970726013 s, accu: 0.8617835640907288, loss_yt: 0.148722305893898\n",
      "epocht 6, batch_num 3800, step 234441, time: 149.0235071182251 s, accu: 0.8617900609970093, loss_yt: 0.2404489517211914\n",
      "epocht 6, batch_num 4000, step 234641, time: 156.74585604667664 s, accu: 0.8617861866950989, loss_yt: 0.29910314083099365\n",
      "epocht 6, batch_num 4200, step 234841, time: 164.56295347213745 s, accu: 0.8617885708808899, loss_yt: 0.3365658223628998\n",
      "epocht 6, batch_num 4400, step 235041, time: 172.4010214805603 s, accu: 0.8617887496948242, loss_yt: 0.3102343678474426\n",
      "epocht 6, batch_num 4600, step 235241, time: 180.17021989822388 s, accu: 0.8617925643920898, loss_yt: 0.2829674780368805\n",
      "epocht 6, batch_num 4800, step 235441, time: 187.93848705291748 s, accu: 0.8617928624153137, loss_yt: 0.2795060873031616\n",
      "epocht 6, batch_num 5000, step 235641, time: 195.9061403274536 s, accu: 0.8617971539497375, loss_yt: 0.2617492973804474\n",
      "epocht 6, batch_num 5200, step 235841, time: 203.735205411911 s, accu: 0.8617978096008301, loss_yt: 0.25874194502830505\n",
      "epocht 6, batch_num 5400, step 236041, time: 211.37677264213562 s, accu: 0.8618008494377136, loss_yt: 0.6351132392883301\n",
      "epocht 6, batch_num 5600, step 236241, time: 219.3614206314087 s, accu: 0.8617997765541077, loss_yt: 0.30926787853240967\n",
      "epocht 6, batch_num 5800, step 236441, time: 227.3859899044037 s, accu: 0.861796498298645, loss_yt: 0.2886488735675812\n",
      "epocht 6, batch_num 6000, step 236641, time: 235.1472086906433 s, accu: 0.8617995977401733, loss_yt: 0.32677915692329407\n",
      "epocht 6, batch_num 6200, step 236841, time: 243.10492992401123 s, accu: 0.8618048429489136, loss_yt: 0.35881656408309937\n",
      "epocht 6, batch_num 6400, step 237041, time: 250.87914180755615 s, accu: 0.8618046641349792, loss_yt: 0.4029798209667206\n",
      "epocht 6, batch_num 6600, step 237241, time: 258.43792939186096 s, accu: 0.8618096709251404, loss_yt: 0.29352882504463196\n",
      "epocht 6, batch_num 6800, step 237441, time: 266.25502586364746 s, accu: 0.8618144989013672, loss_yt: 0.15295842289924622\n",
      "epocht 6, batch_num 7000, step 237641, time: 274.2725872993469 s, accu: 0.8618158102035522, loss_yt: 0.2387319654226303\n",
      "epocht 6, batch_num 7200, step 237841, time: 282.428777217865 s, accu: 0.8618177175521851, loss_yt: 0.3228941857814789\n",
      "epocht 6, batch_num 7400, step 238041, time: 290.04045963287354 s, accu: 0.8618203401565552, loss_yt: 0.3142145574092865\n",
      "iter_validnum 1860\n",
      "epochv 6, step 238080, stop_n 0, time: 345.266747713089 s, accu_va: 0.8618254429230126, loss_yv: 0.30264280557392104\n",
      "iter_trainnum 7440\n",
      "epocht 6, batch_num 0, step 238081, time: 0.3779914379119873 s, accu: 0.8618289828300476, loss_yt: 0.20445001125335693\n",
      "epocht 6, batch_num 200, step 238281, time: 8.077400207519531 s, accu: 0.8618345856666565, loss_yt: 0.2973215878009796\n",
      "epocht 6, batch_num 400, step 238481, time: 15.962316274642944 s, accu: 0.8618342876434326, loss_yt: 0.21471361815929413\n",
      "epocht 6, batch_num 600, step 238681, time: 24.024756908416748 s, accu: 0.8618404269218445, loss_yt: 0.38019394874572754\n",
      "epocht 6, batch_num 800, step 238881, time: 31.93759822845459 s, accu: 0.8618409633636475, loss_yt: 0.2839253544807434\n",
      "epocht 6, batch_num 1000, step 239081, time: 39.7068235874176 s, accu: 0.8618410229682922, loss_yt: 0.24888229370117188\n",
      "epocht 6, batch_num 1200, step 239281, time: 47.433162212371826 s, accu: 0.861842155456543, loss_yt: 0.2806555926799774\n",
      "epocht 6, batch_num 1400, step 239481, time: 55.257239818573 s, accu: 0.8618436455726624, loss_yt: 0.3763187527656555\n",
      "epocht 6, batch_num 1600, step 239681, time: 62.93670606613159 s, accu: 0.861844003200531, loss_yt: 0.18989281356334686\n",
      "epocht 6, batch_num 1800, step 239881, time: 70.86151647567749 s, accu: 0.8618457913398743, loss_yt: 0.36395764350891113\n",
      "epocht 6, batch_num 2000, step 240081, time: 78.93296909332275 s, accu: 0.8618449568748474, loss_yt: 0.30185893177986145\n",
      "epocht 6, batch_num 2200, step 240281, time: 86.75800895690918 s, accu: 0.8618484735488892, loss_yt: 0.12360715866088867\n",
      "epocht 6, batch_num 2400, step 240481, time: 94.53122186660767 s, accu: 0.8618530035018921, loss_yt: 0.2518114447593689\n",
      "epocht 6, batch_num 2600, step 240681, time: 102.2984516620636 s, accu: 0.8618525266647339, loss_yt: 0.39938390254974365\n",
      "epocht 6, batch_num 2800, step 240881, time: 110.06667876243591 s, accu: 0.8618568778038025, loss_yt: 0.2821721136569977\n",
      "epocht 6, batch_num 3000, step 241081, time: 117.72320532798767 s, accu: 0.8618568778038025, loss_yt: 0.1611609309911728\n",
      "epocht 6, batch_num 3200, step 241281, time: 125.47450518608093 s, accu: 0.8618555665016174, loss_yt: 0.29803526401519775\n",
      "epocht 6, batch_num 3400, step 241481, time: 133.3643798828125 s, accu: 0.8618576526641846, loss_yt: 0.34551340341567993\n",
      "epocht 6, batch_num 3600, step 241681, time: 141.27622437477112 s, accu: 0.8618602156639099, loss_yt: 0.49163058400154114\n",
      "epocht 6, batch_num 3800, step 241881, time: 148.94870734214783 s, accu: 0.8618622422218323, loss_yt: 0.22397957742214203\n",
      "epocht 6, batch_num 4000, step 242081, time: 156.62817406654358 s, accu: 0.861870288848877, loss_yt: 0.26590174436569214\n",
      "epocht 6, batch_num 4200, step 242281, time: 164.2667555809021 s, accu: 0.8618707060813904, loss_yt: 0.1548137217760086\n",
      "epocht 6, batch_num 4400, step 242481, time: 172.2563817501068 s, accu: 0.8618671894073486, loss_yt: 0.3180270493030548\n",
      "epocht 6, batch_num 4600, step 242681, time: 180.28292036056519 s, accu: 0.8618713021278381, loss_yt: 0.3291168212890625\n",
      "epocht 6, batch_num 4800, step 242881, time: 188.13292789459229 s, accu: 0.8618751764297485, loss_yt: 0.2478773593902588\n",
      "epocht 6, batch_num 5000, step 243081, time: 195.67778539657593 s, accu: 0.8618772029876709, loss_yt: 0.26938432455062866\n",
      "epocht 6, batch_num 5200, step 243281, time: 203.43800282478333 s, accu: 0.8618766665458679, loss_yt: 0.2788076102733612\n",
      "epocht 6, batch_num 5400, step 243481, time: 211.11846351623535 s, accu: 0.8618820309638977, loss_yt: 0.23155760765075684\n",
      "epocht 6, batch_num 5600, step 243681, time: 218.73908805847168 s, accu: 0.8618856072425842, loss_yt: 0.2858923375606537\n",
      "epocht 6, batch_num 5800, step 243881, time: 226.7407250404358 s, accu: 0.861882209777832, loss_yt: 0.26514437794685364\n",
      "epocht 6, batch_num 6000, step 244081, time: 234.54781556129456 s, accu: 0.8618825674057007, loss_yt: 0.3704684376716614\n",
      "epocht 6, batch_num 6200, step 244281, time: 242.52050065994263 s, accu: 0.861885130405426, loss_yt: 0.32334622740745544\n",
      "epocht 6, batch_num 6400, step 244481, time: 250.16605019569397 s, accu: 0.8618861436843872, loss_yt: 0.22265982627868652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 6, batch_num 6600, step 244681, time: 257.73684096336365 s, accu: 0.8618854880332947, loss_yt: 0.24630123376846313\n",
      "epocht 6, batch_num 6800, step 244881, time: 265.35945105552673 s, accu: 0.8618878126144409, loss_yt: 0.2854171395301819\n",
      "epocht 6, batch_num 7000, step 245081, time: 272.96308994293213 s, accu: 0.8618870973587036, loss_yt: 0.30568936467170715\n",
      "epocht 6, batch_num 7200, step 245281, time: 280.7213706970215 s, accu: 0.8618915677070618, loss_yt: 0.319106787443161\n",
      "epocht 6, batch_num 7400, step 245481, time: 288.5733497142792 s, accu: 0.8618903756141663, loss_yt: 0.2113194316625595\n",
      "iter_validnum 1860\n",
      "epochv 6, step 245520, stop_n 1, time: 342.55703926086426 s, accu_va: 0.8618994544590673, loss_yv: 0.29778195701699745\n",
      "iter_trainnum 7440\n",
      "epocht 6, batch_num 0, step 245521, time: 0.32616114616394043 s, accu: 0.8619080185890198, loss_yt: 0.11897990107536316\n",
      "epocht 6, batch_num 200, step 245721, time: 8.0684232711792 s, accu: 0.861910343170166, loss_yt: 0.18622291088104248\n",
      "epocht 6, batch_num 400, step 245921, time: 15.68306565284729 s, accu: 0.8619130849838257, loss_yt: 0.21819929778575897\n",
      "epocht 6, batch_num 600, step 246121, time: 23.312659978866577 s, accu: 0.8619098663330078, loss_yt: 0.785507321357727\n",
      "epocht 6, batch_num 800, step 246321, time: 31.057948112487793 s, accu: 0.8619112968444824, loss_yt: 0.32852473855018616\n",
      "epocht 6, batch_num 1000, step 246521, time: 38.90898108482361 s, accu: 0.8619093894958496, loss_yt: 0.20630855858325958\n",
      "epocht 6, batch_num 1200, step 246721, time: 46.48173809051514 s, accu: 0.861913800239563, loss_yt: 0.47392457723617554\n",
      "epocht 6, batch_num 1400, step 246921, time: 54.08238196372986 s, accu: 0.8619149327278137, loss_yt: 0.45349234342575073\n",
      "epocht 6, batch_num 1600, step 247121, time: 61.787776708602905 s, accu: 0.8619160056114197, loss_yt: 0.3722933828830719\n",
      "epocht 6, batch_num 1800, step 247321, time: 69.11418604850769 s, accu: 0.8619202375411987, loss_yt: 0.2794630825519562\n",
      "epocht 6, batch_num 2000, step 247521, time: 76.8036241531372 s, accu: 0.8619193434715271, loss_yt: 0.15500950813293457\n",
      "epocht 6, batch_num 2200, step 247721, time: 84.33647990226746 s, accu: 0.8619203567504883, loss_yt: 0.19349375367164612\n",
      "epocht 6, batch_num 2400, step 247921, time: 92.26927328109741 s, accu: 0.861924946308136, loss_yt: 0.3476139307022095\n",
      "epocht 6, batch_num 2600, step 248121, time: 99.96867966651917 s, accu: 0.8619230389595032, loss_yt: 0.281328022480011\n",
      "epocht 6, batch_num 2800, step 248321, time: 107.53843927383423 s, accu: 0.8619263768196106, loss_yt: 0.058189116418361664\n",
      "epocht 6, batch_num 3000, step 248521, time: 115.01748371124268 s, accu: 0.8619297742843628, loss_yt: 0.220054492354393\n",
      "epocht 6, batch_num 3200, step 248721, time: 122.54135274887085 s, accu: 0.8619310855865479, loss_yt: 0.25677689909935\n",
      "epocht 6, batch_num 3400, step 248921, time: 130.05027961730957 s, accu: 0.8619346022605896, loss_yt: 0.27327534556388855\n",
      "epocht 6, batch_num 3600, step 249121, time: 137.53722167015076 s, accu: 0.8619341254234314, loss_yt: 0.26878201961517334\n",
      "epocht 6, batch_num 3800, step 249321, time: 145.43514704704285 s, accu: 0.8619335293769836, loss_yt: 0.29638102650642395\n",
      "epocht 6, batch_num 4000, step 249521, time: 153.4317181110382 s, accu: 0.8619327545166016, loss_yt: 0.25210678577423096\n",
      "epocht 6, batch_num 4200, step 249721, time: 161.14708709716797 s, accu: 0.8619329333305359, loss_yt: 0.34645673632621765\n",
      "epocht 6, batch_num 4400, step 249921, time: 168.68098068237305 s, accu: 0.861933708190918, loss_yt: 0.6119023561477661\n",
      "epocht 6, batch_num 4600, step 250121, time: 176.33149886131287 s, accu: 0.861931562423706, loss_yt: 0.12248434126377106\n",
      "epocht 6, batch_num 4800, step 250321, time: 183.7326943874359 s, accu: 0.8619361519813538, loss_yt: 0.22631129622459412\n",
      "epocht 6, batch_num 5000, step 250521, time: 191.2615942955017 s, accu: 0.8619371056556702, loss_yt: 0.3862994909286499\n",
      "epocht 6, batch_num 5200, step 250721, time: 199.08866095542908 s, accu: 0.8619413375854492, loss_yt: 0.46345487236976624\n",
      "epocht 6, batch_num 5400, step 250921, time: 206.9526035785675 s, accu: 0.8619428873062134, loss_yt: 0.3436180055141449\n",
      "epocht 6, batch_num 5600, step 251121, time: 214.47751307487488 s, accu: 0.8619443774223328, loss_yt: 0.2734445631504059\n",
      "epocht 6, batch_num 5800, step 251321, time: 222.1250638961792 s, accu: 0.8619468808174133, loss_yt: 0.2628646194934845\n",
      "epocht 6, batch_num 6000, step 251521, time: 229.7885389328003 s, accu: 0.861945390701294, loss_yt: 0.17301549017429352\n",
      "epocht 6, batch_num 6200, step 251721, time: 237.47700762748718 s, accu: 0.8619492650032043, loss_yt: 0.2094690203666687\n",
      "epocht 6, batch_num 6400, step 251921, time: 245.07665944099426 s, accu: 0.8619544506072998, loss_yt: 0.16000133752822876\n",
      "epocht 6, batch_num 6600, step 252121, time: 252.5656328201294 s, accu: 0.8619610071182251, loss_yt: 0.2999342083930969\n",
      "epocht 6, batch_num 6800, step 252321, time: 260.2949631214142 s, accu: 0.8619632124900818, loss_yt: 0.29988792538642883\n",
      "epocht 6, batch_num 7000, step 252521, time: 268.0801796913147 s, accu: 0.8619645237922668, loss_yt: 0.3456166684627533\n",
      "epocht 6, batch_num 7200, step 252721, time: 275.6519238948822 s, accu: 0.8619649410247803, loss_yt: 0.3117785155773163\n",
      "epocht 6, batch_num 7400, step 252921, time: 283.34133672714233 s, accu: 0.8619657754898071, loss_yt: 0.3469521701335907\n",
      "iter_validnum 1860\n",
      "epochv 6, step 252960, stop_n 0, time: 337.1644127368927 s, accu_va: 0.8619801304994091, loss_yv: 0.29760092244513575\n",
      "iter_trainnum 7440\n",
      "epocht 6, batch_num 0, step 252961, time: 0.3590402603149414 s, accu: 0.8619868159294128, loss_yt: 0.08331544697284698\n",
      "epocht 6, batch_num 200, step 253161, time: 8.074410438537598 s, accu: 0.8619904518127441, loss_yt: 0.2826441824436188\n",
      "epocht 6, batch_num 400, step 253361, time: 15.644168138504028 s, accu: 0.8619896173477173, loss_yt: 0.3814203441143036\n",
      "epocht 6, batch_num 600, step 253561, time: 23.435335159301758 s, accu: 0.8619910478591919, loss_yt: 0.2609735429286957\n",
      "epocht 6, batch_num 800, step 253761, time: 30.847546577453613 s, accu: 0.8619944453239441, loss_yt: 0.27910807728767395\n",
      "epocht 6, batch_num 1000, step 253961, time: 38.24676465988159 s, accu: 0.8619998693466187, loss_yt: 0.49831101298332214\n",
      "epocht 6, batch_num 1200, step 254161, time: 46.0329110622406 s, accu: 0.8620010614395142, loss_yt: 0.25103551149368286\n",
      "epocht 6, batch_num 1400, step 254361, time: 53.535845041275024 s, accu: 0.8619979619979858, loss_yt: 0.16889189183712006\n",
      "epocht 6, batch_num 1600, step 254561, time: 61.321051836013794 s, accu: 0.8619977831840515, loss_yt: 0.15978902578353882\n",
      "epocht 6, batch_num 1800, step 254761, time: 69.05634236335754 s, accu: 0.86199951171875, loss_yt: 0.22227013111114502\n",
      "epocht 6, batch_num 2000, step 254961, time: 76.9093759059906 s, accu: 0.8620039224624634, loss_yt: 0.33034783601760864\n",
      "epocht 6, batch_num 2200, step 255161, time: 84.52198672294617 s, accu: 0.8620062470436096, loss_yt: 0.36079084873199463\n",
      "epocht 6, batch_num 2400, step 255361, time: 92.1047112941742 s, accu: 0.8620102405548096, loss_yt: 0.2856109142303467\n",
      "epocht 6, batch_num 2600, step 255561, time: 99.80910873413086 s, accu: 0.8620100617408752, loss_yt: 0.2058565616607666\n",
      "epocht 6, batch_num 2800, step 255761, time: 107.28116035461426 s, accu: 0.8620073199272156, loss_yt: 0.5368324518203735\n",
      "epocht 6, batch_num 3000, step 255961, time: 115.25780296325684 s, accu: 0.8620096445083618, loss_yt: 0.35450029373168945\n",
      "epocht 6, batch_num 3200, step 256161, time: 122.81462073326111 s, accu: 0.8620151877403259, loss_yt: 0.23994307219982147\n",
      "epocht 6, batch_num 3400, step 256361, time: 130.47510838508606 s, accu: 0.8620166182518005, loss_yt: 0.1278444081544876\n",
      "epocht 6, batch_num 3600, step 256561, time: 138.0737874507904 s, accu: 0.8620205521583557, loss_yt: 0.30155640840530396\n",
      "epocht 6, batch_num 3800, step 256761, time: 145.65853309631348 s, accu: 0.8620207905769348, loss_yt: 1.1645374298095703\n",
      "epocht 6, batch_num 4000, step 256961, time: 153.19838190078735 s, accu: 0.8620220422744751, loss_yt: 0.24582116305828094\n",
      "epocht 6, batch_num 4200, step 257161, time: 160.66039085388184 s, accu: 0.8620259165763855, loss_yt: 0.15473249554634094\n",
      "epocht 6, batch_num 4400, step 257361, time: 168.19125294685364 s, accu: 0.8620258569717407, loss_yt: 0.2611693739891052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 6, batch_num 4600, step 257561, time: 175.96546483039856 s, accu: 0.8620262145996094, loss_yt: 0.14572317898273468\n",
      "epocht 6, batch_num 4800, step 257761, time: 183.48835062980652 s, accu: 0.8620277047157288, loss_yt: 0.2091740369796753\n",
      "epocht 6, batch_num 5000, step 257961, time: 191.2755253314972 s, accu: 0.8620270490646362, loss_yt: 0.2687707841396332\n",
      "epocht 6, batch_num 5200, step 258161, time: 198.85426020622253 s, accu: 0.8620319366455078, loss_yt: 0.35863953828811646\n",
      "epocht 6, batch_num 5400, step 258361, time: 206.48286080360413 s, accu: 0.8620302081108093, loss_yt: 0.132920041680336\n",
      "epocht 6, batch_num 5600, step 258561, time: 213.89407515525818 s, accu: 0.8620307445526123, loss_yt: 0.2755213975906372\n",
      "epocht 6, batch_num 5800, step 258761, time: 221.58149361610413 s, accu: 0.8620288372039795, loss_yt: 0.18218883872032166\n",
      "epocht 6, batch_num 6000, step 258961, time: 229.46543383598328 s, accu: 0.8620275855064392, loss_yt: 0.2565546929836273\n",
      "epocht 6, batch_num 6200, step 259161, time: 236.9444317817688 s, accu: 0.862027645111084, loss_yt: 0.34750550985336304\n",
      "epocht 6, batch_num 6400, step 259361, time: 244.55704998970032 s, accu: 0.862028956413269, loss_yt: 0.1951202005147934\n",
      "epocht 6, batch_num 6600, step 259561, time: 252.3831226825714 s, accu: 0.8620332479476929, loss_yt: 0.3005492091178894\n",
      "epocht 6, batch_num 6800, step 259761, time: 260.0077660083771 s, accu: 0.8620330095291138, loss_yt: 0.2636125385761261\n",
      "epocht 6, batch_num 7000, step 259961, time: 267.49673652648926 s, accu: 0.8620385527610779, loss_yt: 0.28553441166877747\n",
      "epocht 6, batch_num 7200, step 260161, time: 275.2579550743103 s, accu: 0.862041175365448, loss_yt: 0.36271438002586365\n",
      "epocht 6, batch_num 7400, step 260361, time: 282.85564160346985 s, accu: 0.8620448112487793, loss_yt: 0.1615959256887436\n",
      "iter_validnum 1860\n",
      "epochv 6, step 260400, stop_n 0, time: 336.4682779312134 s, accu_va: 0.8620511985594227, loss_yv: 0.2986978246960589\n",
      "iter_trainnum 7440\n",
      "epocht 7, batch_num 0, step 260401, time: 0.6751947402954102 s, accu: 0.8620591163635254, loss_yt: 0.4186539649963379\n",
      "epocht 7, batch_num 200, step 260601, time: 8.346681356430054 s, accu: 0.8620645999908447, loss_yt: 0.21124033629894257\n",
      "epocht 7, batch_num 400, step 260801, time: 16.074049711227417 s, accu: 0.8620680570602417, loss_yt: 0.37469351291656494\n",
      "epocht 7, batch_num 600, step 261001, time: 23.666714429855347 s, accu: 0.8620709776878357, loss_yt: 0.3469860255718231\n",
      "epocht 7, batch_num 800, step 261201, time: 31.30129909515381 s, accu: 0.8620718717575073, loss_yt: 0.35498636960983276\n",
      "epocht 7, batch_num 1000, step 261401, time: 38.833187103271484 s, accu: 0.8620752692222595, loss_yt: 0.2828604280948639\n",
      "epocht 7, batch_num 1200, step 261601, time: 46.564486265182495 s, accu: 0.8620731830596924, loss_yt: 0.39710232615470886\n",
      "epocht 7, batch_num 1400, step 261801, time: 54.297810554504395 s, accu: 0.8620717525482178, loss_yt: 0.3189903795719147\n",
      "epocht 7, batch_num 1600, step 262001, time: 62.269526958465576 s, accu: 0.8620701432228088, loss_yt: 0.33000612258911133\n",
      "epocht 7, batch_num 1800, step 262201, time: 69.953941822052 s, accu: 0.8620718717575073, loss_yt: 0.23483984172344208\n",
      "epocht 7, batch_num 2000, step 262401, time: 77.43995594978333 s, accu: 0.8620762228965759, loss_yt: 0.21199986338615417\n",
      "epocht 7, batch_num 2200, step 262601, time: 85.18523907661438 s, accu: 0.8620761632919312, loss_yt: 0.42712655663490295\n",
      "epocht 7, batch_num 2400, step 262801, time: 92.6751856803894 s, accu: 0.8620774745941162, loss_yt: 0.24472405016422272\n",
      "epocht 7, batch_num 2600, step 263001, time: 100.45441603660583 s, accu: 0.8620791435241699, loss_yt: 0.41497641801834106\n",
      "epocht 7, batch_num 2800, step 263201, time: 108.10093712806702 s, accu: 0.8620812892913818, loss_yt: 0.4257282614707947\n",
      "epocht 7, batch_num 3000, step 263401, time: 115.78342795372009 s, accu: 0.8620855212211609, loss_yt: 0.29157885909080505\n",
      "epocht 7, batch_num 3200, step 263601, time: 123.37708878517151 s, accu: 0.8620885014533997, loss_yt: 0.2841528654098511\n",
      "epocht 7, batch_num 3400, step 263801, time: 130.80326628684998 s, accu: 0.8620901703834534, loss_yt: 0.29198381304740906\n",
      "epocht 7, batch_num 3600, step 264001, time: 138.26826739311218 s, accu: 0.8620922565460205, loss_yt: 0.326212078332901\n",
      "epocht 7, batch_num 3800, step 264201, time: 145.9666826725006 s, accu: 0.862093448638916, loss_yt: 0.38579946756362915\n",
      "epocht 7, batch_num 4000, step 264401, time: 153.7777988910675 s, accu: 0.862090528011322, loss_yt: 0.27855637669563293\n",
      "epocht 7, batch_num 4200, step 264601, time: 161.35553097724915 s, accu: 0.8620921969413757, loss_yt: 0.2968220114707947\n",
      "epocht 7, batch_num 4400, step 264801, time: 169.0958342552185 s, accu: 0.8620951175689697, loss_yt: 0.3769308030605316\n",
      "epocht 7, batch_num 4600, step 265001, time: 176.76532626152039 s, accu: 0.8620949387550354, loss_yt: 0.2486530840396881\n",
      "epocht 7, batch_num 4800, step 265201, time: 184.29020380973816 s, accu: 0.8620944619178772, loss_yt: 0.29496246576309204\n",
      "epocht 7, batch_num 5000, step 265401, time: 191.86295557022095 s, accu: 0.862095057964325, loss_yt: 0.47423455119132996\n",
      "epocht 7, batch_num 5200, step 265601, time: 199.16542840003967 s, accu: 0.8620989918708801, loss_yt: 0.4337935745716095\n",
      "epocht 7, batch_num 5400, step 265801, time: 206.8239803314209 s, accu: 0.8621021509170532, loss_yt: 0.43368813395500183\n",
      "epocht 7, batch_num 5600, step 266001, time: 214.7158718109131 s, accu: 0.8621074557304382, loss_yt: 0.2749001681804657\n",
      "epocht 7, batch_num 5800, step 266201, time: 222.24074959754944 s, accu: 0.8621143102645874, loss_yt: 0.3340263068675995\n",
      "epocht 7, batch_num 6000, step 266401, time: 230.32311081886292 s, accu: 0.8621166348457336, loss_yt: 0.36531686782836914\n",
      "epocht 7, batch_num 6200, step 266601, time: 237.8649435043335 s, accu: 0.8621167540550232, loss_yt: 0.34471556544303894\n",
      "epocht 7, batch_num 6400, step 266801, time: 245.63815927505493 s, accu: 0.862117350101471, loss_yt: 0.522016704082489\n",
      "epocht 7, batch_num 6600, step 267001, time: 253.32264399528503 s, accu: 0.8621209263801575, loss_yt: 0.2698405385017395\n",
      "epocht 7, batch_num 6800, step 267201, time: 261.22747349739075 s, accu: 0.8621224761009216, loss_yt: 0.2778742015361786\n",
      "epocht 7, batch_num 7000, step 267401, time: 268.89198565483093 s, accu: 0.862119734287262, loss_yt: 0.28068462014198303\n",
      "epocht 7, batch_num 7200, step 267601, time: 276.4078814983368 s, accu: 0.8621168732643127, loss_yt: 0.13507255911827087\n",
      "epocht 7, batch_num 7400, step 267801, time: 284.16814041137695 s, accu: 0.862118661403656, loss_yt: 0.2665289640426636\n",
      "iter_validnum 1860\n",
      "epochv 7, step 267840, stop_n 0, time: 338.10292983055115 s, accu_va: 0.8621234817850975, loss_yv: 0.30055212471834436\n",
      "iter_trainnum 7440\n",
      "epocht 7, batch_num 0, step 267841, time: 0.23534631729125977 s, accu: 0.86212557554245, loss_yt: 0.38857999444007874\n",
      "epocht 7, batch_num 200, step 268041, time: 7.817073822021484 s, accu: 0.862129271030426, loss_yt: 0.3022875189781189\n",
      "epocht 7, batch_num 400, step 268241, time: 15.432741165161133 s, accu: 0.862130343914032, loss_yt: 0.1989974081516266\n",
      "epocht 7, batch_num 600, step 268441, time: 23.323607921600342 s, accu: 0.8621335029602051, loss_yt: 0.2562465965747833\n",
      "epocht 7, batch_num 800, step 268641, time: 30.809608459472656 s, accu: 0.8621383309364319, loss_yt: 0.3019546568393707\n",
      "epocht 7, batch_num 1000, step 268841, time: 38.541953563690186 s, accu: 0.8621400594711304, loss_yt: 0.2571648061275482\n",
      "epocht 7, batch_num 1200, step 269041, time: 46.056819915771484 s, accu: 0.862139105796814, loss_yt: 0.08333972096443176\n",
      "epocht 7, batch_num 1400, step 269241, time: 53.70237469673157 s, accu: 0.8621407151222229, loss_yt: 0.21032753586769104\n",
      "epocht 7, batch_num 1600, step 269441, time: 61.388821601867676 s, accu: 0.8621450662612915, loss_yt: 0.2675918936729431\n",
      "epocht 7, batch_num 1800, step 269641, time: 68.79202461242676 s, accu: 0.8621470332145691, loss_yt: 0.3793778419494629\n",
      "epocht 7, batch_num 2000, step 269841, time: 76.43758010864258 s, accu: 0.8621506690979004, loss_yt: 0.3230992555618286\n",
      "epocht 7, batch_num 2200, step 270041, time: 84.03726077079773 s, accu: 0.8621519207954407, loss_yt: 0.42599472403526306\n",
      "epocht 7, batch_num 2400, step 270241, time: 91.890291929245 s, accu: 0.8621580004692078, loss_yt: 0.20203354954719543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 7, batch_num 2600, step 270441, time: 99.48495411872864 s, accu: 0.862159252166748, loss_yt: 0.41519299149513245\n",
      "epocht 7, batch_num 2800, step 270641, time: 106.98789119720459 s, accu: 0.8621610403060913, loss_yt: 0.2803373634815216\n",
      "epocht 7, batch_num 3000, step 270841, time: 114.55667543411255 s, accu: 0.862162709236145, loss_yt: 0.4463152289390564\n",
      "epocht 7, batch_num 3200, step 271041, time: 122.09648704528809 s, accu: 0.8621615171432495, loss_yt: 0.23788635432720184\n",
      "epocht 7, batch_num 3400, step 271241, time: 129.59443950653076 s, accu: 0.8621645569801331, loss_yt: 0.340660035610199\n",
      "epocht 7, batch_num 3600, step 271441, time: 137.15526795387268 s, accu: 0.8621671199798584, loss_yt: 0.29027488827705383\n",
      "epocht 7, batch_num 3800, step 271641, time: 144.7309672832489 s, accu: 0.8621661067008972, loss_yt: 0.3504290282726288\n",
      "epocht 7, batch_num 4000, step 271841, time: 152.26085948944092 s, accu: 0.8621646761894226, loss_yt: 0.12624137103557587\n",
      "epocht 7, batch_num 4200, step 272041, time: 159.61117482185364 s, accu: 0.8621682524681091, loss_yt: 0.3495382070541382\n",
      "epocht 7, batch_num 4400, step 272241, time: 167.31161403656006 s, accu: 0.8621733784675598, loss_yt: 0.22103333473205566\n",
      "epocht 7, batch_num 4600, step 272441, time: 174.96910429000854 s, accu: 0.8621764779090881, loss_yt: 0.15359771251678467\n",
      "epocht 7, batch_num 4800, step 272641, time: 182.66353058815002 s, accu: 0.8621785640716553, loss_yt: 0.37563568353652954\n",
      "epocht 7, batch_num 5000, step 272841, time: 190.49957585334778 s, accu: 0.8621742129325867, loss_yt: 0.28942665457725525\n",
      "epocht 7, batch_num 5200, step 273041, time: 198.24586176872253 s, accu: 0.8621734976768494, loss_yt: 0.1847163438796997\n",
      "epocht 7, batch_num 5400, step 273241, time: 205.8635127544403 s, accu: 0.8621723055839539, loss_yt: 0.3339006006717682\n",
      "epocht 7, batch_num 5600, step 273441, time: 213.3564555644989 s, accu: 0.8621712923049927, loss_yt: 0.37209466099739075\n",
      "epocht 7, batch_num 5800, step 273641, time: 221.02498626708984 s, accu: 0.8621718287467957, loss_yt: 0.276018351316452\n",
      "epocht 7, batch_num 6000, step 273841, time: 228.58373761177063 s, accu: 0.8621724247932434, loss_yt: 0.3725564777851105\n",
      "epocht 7, batch_num 6200, step 274041, time: 236.27217960357666 s, accu: 0.8621750473976135, loss_yt: 0.5146223902702332\n",
      "epocht 7, batch_num 6400, step 274241, time: 243.83000206947327 s, accu: 0.8621761798858643, loss_yt: 0.32563701272010803\n",
      "epocht 7, batch_num 6600, step 274441, time: 251.67701864242554 s, accu: 0.862176239490509, loss_yt: 0.2989412248134613\n",
      "epocht 7, batch_num 6800, step 274641, time: 259.3444836139679 s, accu: 0.8621754050254822, loss_yt: 0.1170656681060791\n",
      "epocht 7, batch_num 7000, step 274841, time: 266.78162932395935 s, accu: 0.8621785640716553, loss_yt: 0.13614484667778015\n",
      "epocht 7, batch_num 7200, step 275041, time: 274.653550863266 s, accu: 0.8621835112571716, loss_yt: 0.34301504492759705\n",
      "epocht 7, batch_num 7400, step 275241, time: 282.26323080062866 s, accu: 0.8621826171875, loss_yt: 0.24262964725494385\n",
      "iter_validnum 1860\n",
      "epochv 7, step 275280, stop_n 0, time: 335.9835546016693 s, accu_va: 0.8621879953530527, loss_yv: 0.3029560727497903\n",
      "iter_trainnum 7440\n",
      "epocht 7, batch_num 0, step 275281, time: 0.22040748596191406 s, accu: 0.8621885776519775, loss_yt: 0.2907487154006958\n",
      "epocht 7, batch_num 200, step 275481, time: 8.150202512741089 s, accu: 0.862187922000885, loss_yt: 0.25510451197624207\n",
      "epocht 7, batch_num 400, step 275681, time: 15.770869016647339 s, accu: 0.8621889352798462, loss_yt: 0.2532140910625458\n",
      "epocht 7, batch_num 600, step 275881, time: 23.27176785469055 s, accu: 0.862187922000885, loss_yt: 0.1589016318321228\n",
      "epocht 7, batch_num 800, step 276081, time: 30.867483377456665 s, accu: 0.8621869087219238, loss_yt: 0.21014316380023956\n",
      "epocht 7, batch_num 1000, step 276281, time: 38.565903425216675 s, accu: 0.8621903657913208, loss_yt: 0.4308639466762543\n",
      "epocht 7, batch_num 1200, step 276481, time: 46.47671914100647 s, accu: 0.8621885180473328, loss_yt: 0.49499961733818054\n",
      "epocht 7, batch_num 1400, step 276681, time: 54.361634731292725 s, accu: 0.8621894121170044, loss_yt: 0.276348352432251\n",
      "epocht 7, batch_num 1600, step 276881, time: 61.851627588272095 s, accu: 0.862189769744873, loss_yt: 0.3278081715106964\n",
      "epocht 7, batch_num 1800, step 277081, time: 69.4812331199646 s, accu: 0.8621923327445984, loss_yt: 0.3146117031574249\n",
      "epocht 7, batch_num 2000, step 277281, time: 77.0360004901886 s, accu: 0.8621931672096252, loss_yt: 0.3118278682231903\n",
      "epocht 7, batch_num 2200, step 277481, time: 84.51205945014954 s, accu: 0.8621926307678223, loss_yt: 0.19756801426410675\n",
      "epocht 7, batch_num 2400, step 277681, time: 92.7539701461792 s, accu: 0.8621904850006104, loss_yt: 0.1436934471130371\n",
      "epocht 7, batch_num 2600, step 277881, time: 100.42548274993896 s, accu: 0.8621935844421387, loss_yt: 0.137243390083313\n",
      "epocht 7, batch_num 2800, step 278081, time: 108.31835150718689 s, accu: 0.8621940612792969, loss_yt: 0.32875362038612366\n",
      "epocht 7, batch_num 3000, step 278281, time: 115.91005206108093 s, accu: 0.8621967434883118, loss_yt: 0.2689002752304077\n",
      "epocht 7, batch_num 3200, step 278481, time: 123.29134106636047 s, accu: 0.8621974587440491, loss_yt: 0.2027740329504013\n",
      "epocht 7, batch_num 3400, step 278681, time: 130.83417582511902 s, accu: 0.8622031211853027, loss_yt: 0.24495594203472137\n",
      "epocht 7, batch_num 3600, step 278881, time: 138.48172664642334 s, accu: 0.8622023463249207, loss_yt: 0.22338809072971344\n",
      "epocht 7, batch_num 3800, step 279081, time: 145.96671152114868 s, accu: 0.8622033596038818, loss_yt: 0.2995440363883972\n",
      "epocht 7, batch_num 4000, step 279281, time: 153.6930389404297 s, accu: 0.8622064590454102, loss_yt: 0.3241272270679474\n",
      "epocht 7, batch_num 4200, step 279481, time: 161.3305962085724 s, accu: 0.8622077107429504, loss_yt: 0.38161084055900574\n",
      "epocht 7, batch_num 4400, step 279681, time: 169.20159649848938 s, accu: 0.8622061014175415, loss_yt: 0.15857285261154175\n",
      "epocht 7, batch_num 4600, step 279881, time: 176.49009132385254 s, accu: 0.8622115850448608, loss_yt: 0.18030838668346405\n",
      "epocht 7, batch_num 4800, step 280081, time: 184.0189278125763 s, accu: 0.8622124195098877, loss_yt: 0.28097906708717346\n",
      "epocht 7, batch_num 5000, step 280281, time: 191.59566569328308 s, accu: 0.8622154593467712, loss_yt: 0.23551660776138306\n",
      "epocht 7, batch_num 5200, step 280481, time: 199.0826473236084 s, accu: 0.8622206449508667, loss_yt: 0.27256089448928833\n",
      "epocht 7, batch_num 5400, step 280681, time: 206.72919940948486 s, accu: 0.8622240424156189, loss_yt: 0.37648430466651917\n",
      "epocht 7, batch_num 5600, step 280881, time: 214.307932138443 s, accu: 0.8622286319732666, loss_yt: 0.274831622838974\n",
      "epocht 7, batch_num 5800, step 281081, time: 222.0811722278595 s, accu: 0.8622287511825562, loss_yt: 0.6865152716636658\n",
      "epocht 7, batch_num 6000, step 281281, time: 229.5083191394806 s, accu: 0.8622304201126099, loss_yt: 0.29456138610839844\n",
      "epocht 7, batch_num 6200, step 281481, time: 237.1518473625183 s, accu: 0.8622324466705322, loss_yt: 0.2581879794597626\n",
      "epocht 7, batch_num 6400, step 281681, time: 244.66977334022522 s, accu: 0.8622347712516785, loss_yt: 0.22814461588859558\n",
      "epocht 7, batch_num 6600, step 281881, time: 252.28239011764526 s, accu: 0.8622347712516785, loss_yt: 0.3106074035167694\n",
      "epocht 7, batch_num 6800, step 282081, time: 260.21921133995056 s, accu: 0.8622331023216248, loss_yt: 0.35340002179145813\n",
      "epocht 7, batch_num 7000, step 282281, time: 267.51967573165894 s, accu: 0.8622345924377441, loss_yt: 0.4161105751991272\n",
      "epocht 7, batch_num 7200, step 282481, time: 275.52426648139954 s, accu: 0.8622349500656128, loss_yt: 0.21718543767929077\n",
      "epocht 7, batch_num 7400, step 282681, time: 282.9892771244049 s, accu: 0.862234354019165, loss_yt: 0.318725049495697\n",
      "iter_validnum 1860\n",
      "epochv 7, step 282720, stop_n 1, time: 336.7445740699768 s, accu_va: 0.8622421257598426, loss_yv: 0.2979996206018553\n",
      "iter_trainnum 7440\n",
      "epocht 7, batch_num 0, step 282721, time: 0.29318881034851074 s, accu: 0.8622512221336365, loss_yt: 0.36428847908973694\n",
      "epocht 7, batch_num 200, step 282921, time: 7.678440093994141 s, accu: 0.8622549772262573, loss_yt: 0.3528374433517456\n",
      "epocht 7, batch_num 400, step 283121, time: 15.231244325637817 s, accu: 0.8622549176216125, loss_yt: 0.2401799112558365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 7, batch_num 600, step 283321, time: 22.922711849212646 s, accu: 0.8622608780860901, loss_yt: 0.20662939548492432\n",
      "epocht 7, batch_num 800, step 283521, time: 30.596158981323242 s, accu: 0.8622568249702454, loss_yt: 0.26450395584106445\n",
      "epocht 7, batch_num 1000, step 283721, time: 38.103084325790405 s, accu: 0.8622575998306274, loss_yt: 0.31266769766807556\n",
      "epocht 7, batch_num 1200, step 283921, time: 45.63596749305725 s, accu: 0.8622599840164185, loss_yt: 0.25851133465766907\n",
      "epocht 7, batch_num 1400, step 284121, time: 53.707393646240234 s, accu: 0.862263560295105, loss_yt: 0.29009178280830383\n",
      "epocht 7, batch_num 1600, step 284321, time: 61.406771421432495 s, accu: 0.8622673153877258, loss_yt: 0.2815224826335907\n",
      "epocht 7, batch_num 1800, step 284521, time: 69.17800951004028 s, accu: 0.8622684478759766, loss_yt: 0.25776028633117676\n",
      "epocht 7, batch_num 2000, step 284721, time: 76.74578261375427 s, accu: 0.862269401550293, loss_yt: 0.3105762302875519\n",
      "epocht 7, batch_num 2200, step 284921, time: 84.47309017181396 s, accu: 0.862267017364502, loss_yt: 0.3494179844856262\n",
      "epocht 7, batch_num 2400, step 285121, time: 91.99298143386841 s, accu: 0.862267017364502, loss_yt: 0.2489476352930069\n",
      "epocht 7, batch_num 2600, step 285321, time: 99.54978108406067 s, accu: 0.8622693419456482, loss_yt: 0.2689535617828369\n",
      "epocht 7, batch_num 2800, step 285521, time: 107.5703272819519 s, accu: 0.8622696995735168, loss_yt: 0.126115620136261\n",
      "epocht 7, batch_num 3000, step 285721, time: 115.34154653549194 s, accu: 0.8622709512710571, loss_yt: 0.28736621141433716\n",
      "epocht 7, batch_num 3200, step 285921, time: 122.96220469474792 s, accu: 0.8622707724571228, loss_yt: 0.23759771883487701\n",
      "epocht 7, batch_num 3400, step 286121, time: 130.60273790359497 s, accu: 0.8622739911079407, loss_yt: 0.3747149705886841\n",
      "epocht 7, batch_num 3600, step 286321, time: 138.2443070411682 s, accu: 0.8622726798057556, loss_yt: 0.23707856237888336\n",
      "epocht 7, batch_num 3800, step 286521, time: 145.89085698127747 s, accu: 0.8622698783874512, loss_yt: 0.5082640051841736\n",
      "epocht 7, batch_num 4000, step 286721, time: 153.36191296577454 s, accu: 0.8622692823410034, loss_yt: 0.4572344720363617\n",
      "epocht 7, batch_num 4200, step 286921, time: 160.88077449798584 s, accu: 0.8622714877128601, loss_yt: 0.35378479957580566\n",
      "epocht 7, batch_num 4400, step 287121, time: 168.3109049797058 s, accu: 0.862276554107666, loss_yt: 0.2185438722372055\n",
      "epocht 7, batch_num 4600, step 287321, time: 175.79090404510498 s, accu: 0.8622761964797974, loss_yt: 0.2763230800628662\n",
      "epocht 7, batch_num 4800, step 287521, time: 183.74866223335266 s, accu: 0.862276017665863, loss_yt: 0.35192590951919556\n",
      "epocht 7, batch_num 5000, step 287721, time: 191.48194670677185 s, accu: 0.862276017665863, loss_yt: 0.47863274812698364\n",
      "epocht 7, batch_num 5200, step 287921, time: 198.88315415382385 s, accu: 0.8622775673866272, loss_yt: 0.35910341143608093\n",
      "epocht 7, batch_num 5400, step 288121, time: 206.93063688278198 s, accu: 0.8622779846191406, loss_yt: 0.38396984338760376\n",
      "epocht 7, batch_num 5600, step 288321, time: 214.51934814453125 s, accu: 0.8622779250144958, loss_yt: 0.42154791951179504\n",
      "epocht 7, batch_num 5800, step 288521, time: 222.14299082756042 s, accu: 0.8622788786888123, loss_yt: 0.4086434841156006\n",
      "epocht 7, batch_num 6000, step 288721, time: 229.70078253746033 s, accu: 0.8622812628746033, loss_yt: 0.2687371075153351\n",
      "epocht 7, batch_num 6200, step 288921, time: 237.35827136039734 s, accu: 0.8622807860374451, loss_yt: 0.1199079230427742\n",
      "epocht 7, batch_num 6400, step 289121, time: 244.95496320724487 s, accu: 0.8622826933860779, loss_yt: 0.27266860008239746\n",
      "epocht 7, batch_num 6600, step 289321, time: 252.29233813285828 s, accu: 0.862286388874054, loss_yt: 0.14303158223628998\n",
      "epocht 7, batch_num 6800, step 289521, time: 259.96880984306335 s, accu: 0.8622899055480957, loss_yt: 0.31804513931274414\n",
      "epocht 7, batch_num 7000, step 289721, time: 267.3002059459686 s, accu: 0.8622907400131226, loss_yt: 0.1487291157245636\n",
      "epocht 7, batch_num 7200, step 289921, time: 274.8510150909424 s, accu: 0.8622907400131226, loss_yt: 0.42925581336021423\n",
      "epocht 7, batch_num 7400, step 290121, time: 282.36292719841003 s, accu: 0.8622913360595703, loss_yt: 0.45856863260269165\n",
      "iter_validnum 1860\n",
      "epochv 7, step 290160, stop_n 0, time: 336.1710772514343 s, accu_va: 0.8622988020861021, loss_yv: 0.29796070253816986\n",
      "iter_trainnum 7440\n",
      "epocht 7, batch_num 0, step 290161, time: 0.5136268138885498 s, accu: 0.8623079061508179, loss_yt: 0.13225702941417694\n",
      "epocht 7, batch_num 200, step 290361, time: 8.404525518417358 s, accu: 0.8623101115226746, loss_yt: 0.36147189140319824\n",
      "epocht 7, batch_num 400, step 290561, time: 15.825681209564209 s, accu: 0.8623113632202148, loss_yt: 0.34225279092788696\n",
      "epocht 7, batch_num 600, step 290761, time: 23.469242334365845 s, accu: 0.862311065196991, loss_yt: 0.10640135407447815\n",
      "epocht 7, batch_num 800, step 290961, time: 31.05495810508728 s, accu: 0.8623112440109253, loss_yt: 0.2152004987001419\n",
      "epocht 7, batch_num 1000, step 291161, time: 38.72345471382141 s, accu: 0.8623143434524536, loss_yt: 0.3976108431816101\n",
      "epocht 7, batch_num 1200, step 291361, time: 46.259340047836304 s, accu: 0.8623190522193909, loss_yt: 0.1506931632757187\n",
      "epocht 7, batch_num 1400, step 291561, time: 53.841060161590576 s, accu: 0.8623202443122864, loss_yt: 0.2204199880361557\n",
      "epocht 7, batch_num 1600, step 291761, time: 61.30609893798828 s, accu: 0.8623268008232117, loss_yt: 0.24537904560565948\n",
      "epocht 7, batch_num 1800, step 291961, time: 68.66538715362549 s, accu: 0.862328290939331, loss_yt: 0.2095506340265274\n",
      "epocht 7, batch_num 2000, step 292161, time: 76.00977563858032 s, accu: 0.8623325228691101, loss_yt: 0.32154330611228943\n",
      "epocht 7, batch_num 2200, step 292361, time: 83.6473639011383 s, accu: 0.8623338341712952, loss_yt: 0.25596484541893005\n",
      "epocht 7, batch_num 2400, step 292561, time: 91.28194260597229 s, accu: 0.8623339533805847, loss_yt: 0.4065690338611603\n",
      "epocht 7, batch_num 2600, step 292761, time: 99.03218531608582 s, accu: 0.8623336553573608, loss_yt: 0.3829415738582611\n",
      "epocht 7, batch_num 2800, step 292961, time: 106.67776608467102 s, accu: 0.8623360991477966, loss_yt: 0.19118693470954895\n",
      "epocht 7, batch_num 3000, step 293161, time: 114.03506731987 s, accu: 0.8623388409614563, loss_yt: 0.23870466649532318\n",
      "epocht 7, batch_num 3200, step 293361, time: 121.66466665267944 s, accu: 0.8623387813568115, loss_yt: 0.22062885761260986\n",
      "epocht 7, batch_num 3400, step 293561, time: 129.3002483844757 s, accu: 0.862337589263916, loss_yt: 0.4750899076461792\n",
      "epocht 7, batch_num 3600, step 293761, time: 136.96378207206726 s, accu: 0.862338662147522, loss_yt: 0.27460601925849915\n",
      "epocht 7, batch_num 3800, step 293961, time: 144.75192999839783 s, accu: 0.8623371720314026, loss_yt: 0.3039386570453644\n",
      "epocht 7, batch_num 4000, step 294161, time: 152.3336570262909 s, accu: 0.8623377084732056, loss_yt: 0.3540593683719635\n",
      "epocht 7, batch_num 4200, step 294361, time: 160.09193801879883 s, accu: 0.8623396158218384, loss_yt: 0.13926908373832703\n",
      "epocht 7, batch_num 4400, step 294561, time: 167.50807929039001 s, accu: 0.8623372316360474, loss_yt: 0.33921000361442566\n",
      "epocht 7, batch_num 4600, step 294761, time: 175.37504291534424 s, accu: 0.8623364567756653, loss_yt: 0.29813146591186523\n",
      "epocht 7, batch_num 4800, step 294961, time: 183.03954792022705 s, accu: 0.8623385429382324, loss_yt: 0.3965495228767395\n",
      "epocht 7, batch_num 5000, step 295161, time: 190.70704531669617 s, accu: 0.8623339533805847, loss_yt: 0.7627122402191162\n",
      "epocht 7, batch_num 5200, step 295361, time: 198.25089836120605 s, accu: 0.862335205078125, loss_yt: 0.508762538433075\n",
      "epocht 7, batch_num 5400, step 295561, time: 205.81168794631958 s, accu: 0.862339973449707, loss_yt: 0.18346992135047913\n",
      "epocht 7, batch_num 5600, step 295761, time: 213.47020888328552 s, accu: 0.8623385429382324, loss_yt: 0.43210819363594055\n",
      "epocht 7, batch_num 5800, step 295961, time: 221.01802587509155 s, accu: 0.8623411059379578, loss_yt: 0.23962616920471191\n",
      "epocht 7, batch_num 6000, step 296161, time: 228.4999861717224 s, accu: 0.8623448014259338, loss_yt: 0.28124120831489563\n",
      "epocht 7, batch_num 6200, step 296361, time: 236.07076907157898 s, accu: 0.8623413443565369, loss_yt: 0.247650146484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 7, batch_num 6400, step 296561, time: 243.72430849075317 s, accu: 0.8623396754264832, loss_yt: 0.33662131428718567\n",
      "epocht 7, batch_num 6600, step 296761, time: 251.37481832504272 s, accu: 0.8623409867286682, loss_yt: 0.2817540466785431\n",
      "epocht 7, batch_num 6800, step 296961, time: 258.9804832935333 s, accu: 0.8623431921005249, loss_yt: 0.3617532551288605\n",
      "epocht 7, batch_num 7000, step 297161, time: 266.7078239917755 s, accu: 0.8623461723327637, loss_yt: 0.23069196939468384\n",
      "epocht 7, batch_num 7200, step 297361, time: 274.2606222629547 s, accu: 0.8623477220535278, loss_yt: 0.2564725875854492\n",
      "epocht 7, batch_num 7400, step 297561, time: 281.62093925476074 s, accu: 0.8623480796813965, loss_yt: 0.12284623086452484\n",
      "iter_validnum 1860\n",
      "epochv 7, step 297600, stop_n 0, time: 335.33132815361023 s, accu_va: 0.8623586541542443, loss_yv: 0.29865352716897764\n",
      "iter_trainnum 7440\n",
      "epocht 8, batch_num 0, step 297601, time: 0.44583988189697266 s, accu: 0.8623638153076172, loss_yt: 0.19559147953987122\n",
      "epocht 8, batch_num 200, step 297801, time: 7.958719253540039 s, accu: 0.8623650670051575, loss_yt: 0.322939932346344\n",
      "epocht 8, batch_num 400, step 298001, time: 15.765842199325562 s, accu: 0.8623664975166321, loss_yt: 0.22856765985488892\n",
      "epocht 8, batch_num 600, step 298201, time: 23.30468249320984 s, accu: 0.8623682260513306, loss_yt: 0.28423821926116943\n",
      "epocht 8, batch_num 800, step 298401, time: 30.88441562652588 s, accu: 0.8623650670051575, loss_yt: 0.20678511261940002\n",
      "epocht 8, batch_num 1000, step 298601, time: 38.34746193885803 s, accu: 0.8623700141906738, loss_yt: 0.29689842462539673\n",
      "epocht 8, batch_num 1200, step 298801, time: 45.786569118499756 s, accu: 0.862375020980835, loss_yt: 0.3107283115386963\n",
      "epocht 8, batch_num 1400, step 299001, time: 53.4760377407074 s, accu: 0.862377941608429, loss_yt: 0.19074319303035736\n",
      "epocht 8, batch_num 1600, step 299201, time: 61.03179883956909 s, accu: 0.8623824119567871, loss_yt: 0.2415659874677658\n",
      "epocht 8, batch_num 1800, step 299401, time: 68.87086987495422 s, accu: 0.862382173538208, loss_yt: 0.3108338713645935\n",
      "epocht 8, batch_num 2000, step 299601, time: 76.7059109210968 s, accu: 0.8623812198638916, loss_yt: 0.2664378881454468\n",
      "epocht 8, batch_num 2200, step 299801, time: 84.343496799469 s, accu: 0.8623829483985901, loss_yt: 0.247659370303154\n",
      "epocht 8, batch_num 2400, step 300001, time: 91.78858757019043 s, accu: 0.8623834252357483, loss_yt: 0.5055065155029297\n",
      "epocht 8, batch_num 2600, step 300201, time: 99.2466185092926 s, accu: 0.8623900413513184, loss_yt: 0.15728914737701416\n",
      "epocht 8, batch_num 2800, step 300401, time: 106.88718271255493 s, accu: 0.8623883128166199, loss_yt: 0.38264280557632446\n",
      "epocht 8, batch_num 3000, step 300601, time: 114.50085496902466 s, accu: 0.8623896241188049, loss_yt: 0.14300160109996796\n",
      "epocht 8, batch_num 3200, step 300801, time: 122.19425010681152 s, accu: 0.8623859286308289, loss_yt: 0.273662269115448\n",
      "epocht 8, batch_num 3400, step 301001, time: 129.83382081985474 s, accu: 0.862386167049408, loss_yt: 0.6479063630104065\n",
      "epocht 8, batch_num 3600, step 301201, time: 137.2629554271698 s, accu: 0.8623843789100647, loss_yt: 0.12257084995508194\n",
      "epocht 8, batch_num 3800, step 301401, time: 144.8526895046234 s, accu: 0.8623859882354736, loss_yt: 0.40989166498184204\n",
      "epocht 8, batch_num 4000, step 301601, time: 152.3974859714508 s, accu: 0.8623877763748169, loss_yt: 0.18770045042037964\n",
      "epocht 8, batch_num 4200, step 301801, time: 160.06598114967346 s, accu: 0.8623895049095154, loss_yt: 0.17594511806964874\n",
      "epocht 8, batch_num 4400, step 302001, time: 167.63972663879395 s, accu: 0.862391471862793, loss_yt: 0.5756193995475769\n",
      "epocht 8, batch_num 4600, step 302201, time: 175.2643404006958 s, accu: 0.8623908758163452, loss_yt: 0.25098973512649536\n",
      "epocht 8, batch_num 4800, step 302401, time: 182.85307931900024 s, accu: 0.8623932003974915, loss_yt: 0.11235843598842621\n",
      "epocht 8, batch_num 5000, step 302601, time: 190.31911516189575 s, accu: 0.8623950481414795, loss_yt: 0.3530540466308594\n",
      "epocht 8, batch_num 5200, step 302801, time: 197.9157681465149 s, accu: 0.862395167350769, loss_yt: 0.3207278847694397\n",
      "epocht 8, batch_num 5400, step 303001, time: 205.67804479599 s, accu: 0.8623958826065063, loss_yt: 0.3574869632720947\n",
      "epocht 8, batch_num 5600, step 303201, time: 213.14504599571228 s, accu: 0.8623979091644287, loss_yt: 0.23782308399677277\n",
      "epocht 8, batch_num 5800, step 303401, time: 220.78262424468994 s, accu: 0.8623926639556885, loss_yt: 0.23664724826812744\n",
      "epocht 8, batch_num 6000, step 303601, time: 228.6186683177948 s, accu: 0.862394392490387, loss_yt: 0.34082546830177307\n",
      "epocht 8, batch_num 6200, step 303801, time: 236.4058449268341 s, accu: 0.8623977899551392, loss_yt: 0.34882473945617676\n",
      "epocht 8, batch_num 6400, step 304001, time: 243.80007362365723 s, accu: 0.8624030947685242, loss_yt: 0.650250256061554\n",
      "epocht 8, batch_num 6600, step 304201, time: 251.25217366218567 s, accu: 0.862405002117157, loss_yt: 0.3366343080997467\n",
      "epocht 8, batch_num 6800, step 304401, time: 258.68131947517395 s, accu: 0.8624059557914734, loss_yt: 0.3142467439174652\n",
      "epocht 8, batch_num 7000, step 304601, time: 266.2809591293335 s, accu: 0.8624075651168823, loss_yt: 0.24967119097709656\n",
      "epocht 8, batch_num 7200, step 304801, time: 273.9713943004608 s, accu: 0.8624041080474854, loss_yt: 0.34120750427246094\n",
      "epocht 8, batch_num 7400, step 305001, time: 281.56708574295044 s, accu: 0.862408459186554, loss_yt: 0.38270410895347595\n",
      "iter_validnum 1860\n",
      "epochv 8, step 305040, stop_n 0, time: 335.84096598625183 s, accu_va: 0.8624129334765096, loss_yv: 0.3012835394490951\n",
      "iter_trainnum 7440\n",
      "epocht 8, batch_num 0, step 305041, time: 0.35804295539855957 s, accu: 0.862414538860321, loss_yt: 0.24350854754447937\n",
      "epocht 8, batch_num 200, step 305241, time: 8.371613264083862 s, accu: 0.8624173402786255, loss_yt: 0.274093896150589\n",
      "epocht 8, batch_num 400, step 305441, time: 15.817735433578491 s, accu: 0.8624215722084045, loss_yt: 0.33135172724723816\n",
      "epocht 8, batch_num 600, step 305641, time: 23.3106689453125 s, accu: 0.862420380115509, loss_yt: 0.43178075551986694\n",
      "epocht 8, batch_num 800, step 305841, time: 30.834547996520996 s, accu: 0.8624219298362732, loss_yt: 0.15802128612995148\n",
      "epocht 8, batch_num 1000, step 306041, time: 38.63872504234314 s, accu: 0.8624200224876404, loss_yt: 0.2788444459438324\n",
      "epocht 8, batch_num 1200, step 306241, time: 46.24633574485779 s, accu: 0.8624194264411926, loss_yt: 0.3062228560447693\n",
      "epocht 8, batch_num 1400, step 306441, time: 53.90887141227722 s, accu: 0.8624230027198792, loss_yt: 0.28906887769699097\n",
      "epocht 8, batch_num 1600, step 306641, time: 61.55943465232849 s, accu: 0.8624222874641418, loss_yt: 0.24572914838790894\n",
      "epocht 8, batch_num 1800, step 306841, time: 69.03440165519714 s, accu: 0.8624230623245239, loss_yt: 0.4283545911312103\n",
      "epocht 8, batch_num 2000, step 307041, time: 76.72084593772888 s, accu: 0.8624249696731567, loss_yt: 0.25577297806739807\n",
      "epocht 8, batch_num 2200, step 307241, time: 84.39233255386353 s, accu: 0.8624241352081299, loss_yt: 0.6380878686904907\n",
      "epocht 8, batch_num 2400, step 307441, time: 92.11867213249207 s, accu: 0.8624247908592224, loss_yt: 0.30421435832977295\n",
      "epocht 8, batch_num 2600, step 307641, time: 99.60664916038513 s, accu: 0.8624299168586731, loss_yt: 0.36806637048721313\n",
      "epocht 8, batch_num 2800, step 307841, time: 107.36590075492859 s, accu: 0.862429678440094, loss_yt: 0.2681159973144531\n",
      "epocht 8, batch_num 3000, step 308041, time: 115.18404412269592 s, accu: 0.8624289631843567, loss_yt: 0.2917577028274536\n",
      "epocht 8, batch_num 3200, step 308241, time: 122.61315965652466 s, accu: 0.8624292016029358, loss_yt: 0.4403606057167053\n",
      "epocht 8, batch_num 3400, step 308441, time: 130.19488954544067 s, accu: 0.862430214881897, loss_yt: 0.13855139911174774\n",
      "epocht 8, batch_num 3600, step 308641, time: 137.67388272285461 s, accu: 0.8624298572540283, loss_yt: 0.39295694231987\n",
      "epocht 8, batch_num 3800, step 308841, time: 145.51189756393433 s, accu: 0.8624283075332642, loss_yt: 0.5545729994773865\n",
      "epocht 8, batch_num 4000, step 309041, time: 153.18936824798584 s, accu: 0.8624281883239746, loss_yt: 0.24820764362812042\n",
      "epocht 8, batch_num 4200, step 309241, time: 160.67933917045593 s, accu: 0.862430989742279, loss_yt: 0.3946833312511444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 8, batch_num 4400, step 309441, time: 168.35980916023254 s, accu: 0.8624329566955566, loss_yt: 0.3509272634983063\n",
      "epocht 8, batch_num 4600, step 309641, time: 175.9136517047882 s, accu: 0.8624332547187805, loss_yt: 0.2589109241962433\n",
      "epocht 8, batch_num 4800, step 309841, time: 183.70576572418213 s, accu: 0.862434983253479, loss_yt: 0.316241979598999\n",
      "epocht 8, batch_num 5000, step 310041, time: 191.40719509124756 s, accu: 0.8624380230903625, loss_yt: 0.3366626501083374\n",
      "epocht 8, batch_num 5200, step 310241, time: 199.0816788673401 s, accu: 0.8624387383460999, loss_yt: 0.288299560546875\n",
      "epocht 8, batch_num 5400, step 310441, time: 206.76909613609314 s, accu: 0.862442135810852, loss_yt: 0.3250786364078522\n",
      "epocht 8, batch_num 5600, step 310641, time: 214.20623993873596 s, accu: 0.862443745136261, loss_yt: 0.329942524433136\n",
      "epocht 8, batch_num 5800, step 310841, time: 222.1819133758545 s, accu: 0.8624435663223267, loss_yt: 0.34697777032852173\n",
      "epocht 8, batch_num 6000, step 311041, time: 229.82644128799438 s, accu: 0.8624458312988281, loss_yt: 0.42541995644569397\n",
      "epocht 8, batch_num 6200, step 311241, time: 237.37924361228943 s, accu: 0.8624452948570251, loss_yt: 0.25309911370277405\n",
      "epocht 8, batch_num 6400, step 311441, time: 244.88716578483582 s, accu: 0.8624476194381714, loss_yt: 0.4704169034957886\n",
      "epocht 8, batch_num 6600, step 311641, time: 252.3581895828247 s, accu: 0.8624514937400818, loss_yt: 0.18998391926288605\n",
      "epocht 8, batch_num 6800, step 311841, time: 260.3498377799988 s, accu: 0.8624544739723206, loss_yt: 0.40714284777641296\n",
      "epocht 8, batch_num 7000, step 312041, time: 268.03726410865784 s, accu: 0.8624558448791504, loss_yt: 0.39875587821006775\n",
      "epocht 8, batch_num 7200, step 312241, time: 275.77859449386597 s, accu: 0.8624566793441772, loss_yt: 0.24568983912467957\n",
      "epocht 8, batch_num 7400, step 312441, time: 283.37524795532227 s, accu: 0.8624573349952698, loss_yt: 0.28792721033096313\n",
      "iter_validnum 1860\n",
      "epochv 8, step 312480, stop_n 0, time: 337.07265996932983 s, accu_va: 0.862457745209817, loss_yv: 0.30333960559018835\n",
      "iter_trainnum 7440\n",
      "epocht 8, batch_num 0, step 312481, time: 0.23241686820983887 s, accu: 0.8624617457389832, loss_yt: 0.14902351796627045\n",
      "epocht 8, batch_num 200, step 312681, time: 8.154227018356323 s, accu: 0.8624637126922607, loss_yt: 0.2559225261211395\n",
      "epocht 8, batch_num 400, step 312881, time: 15.991272211074829 s, accu: 0.8624632954597473, loss_yt: 0.24338486790657043\n",
      "epocht 8, batch_num 600, step 313081, time: 23.692646503448486 s, accu: 0.8624631762504578, loss_yt: 0.3653094172477722\n",
      "epocht 8, batch_num 800, step 313281, time: 31.20160150527954 s, accu: 0.8624668121337891, loss_yt: 0.3209167718887329\n",
      "epocht 8, batch_num 1000, step 313481, time: 38.91992688179016 s, accu: 0.8624688982963562, loss_yt: 0.32515987753868103\n",
      "epocht 8, batch_num 1200, step 313681, time: 46.566508293151855 s, accu: 0.8624701499938965, loss_yt: 0.2734855115413666\n",
      "epocht 8, batch_num 1400, step 313881, time: 54.033512592315674 s, accu: 0.8624712824821472, loss_yt: 0.2688581347465515\n",
      "epocht 8, batch_num 1600, step 314081, time: 61.74489235877991 s, accu: 0.8624668121337891, loss_yt: 0.13846030831336975\n",
      "epocht 8, batch_num 1800, step 314281, time: 69.30268383026123 s, accu: 0.8624662160873413, loss_yt: 0.27281689643859863\n",
      "epocht 8, batch_num 2000, step 314481, time: 76.78968286514282 s, accu: 0.8624701499938965, loss_yt: 0.190189927816391\n",
      "epocht 8, batch_num 2200, step 314681, time: 84.23178744316101 s, accu: 0.8624716401100159, loss_yt: 0.43616437911987305\n",
      "epocht 8, batch_num 2400, step 314881, time: 91.87436437606812 s, accu: 0.8624722957611084, loss_yt: 0.18320338428020477\n",
      "epocht 8, batch_num 2600, step 315081, time: 99.40817999839783 s, accu: 0.8624746799468994, loss_yt: 0.4559488594532013\n",
      "epocht 8, batch_num 2800, step 315281, time: 107.04480004310608 s, accu: 0.8624773621559143, loss_yt: 0.267566978931427\n",
      "epocht 8, batch_num 3000, step 315481, time: 114.65740489959717 s, accu: 0.8624786138534546, loss_yt: 0.2932743728160858\n",
      "epocht 8, batch_num 3200, step 315681, time: 122.32589769363403 s, accu: 0.8624761700630188, loss_yt: 0.26984548568725586\n",
      "epocht 8, batch_num 3400, step 315881, time: 129.7989399433136 s, accu: 0.8624751567840576, loss_yt: 0.32354164123535156\n",
      "epocht 8, batch_num 3600, step 316081, time: 137.45045399665833 s, accu: 0.8624752759933472, loss_yt: 0.6608183979988098\n",
      "epocht 8, batch_num 3800, step 316281, time: 145.21672534942627 s, accu: 0.8624757528305054, loss_yt: 0.4370643198490143\n",
      "epocht 8, batch_num 4000, step 316481, time: 152.9909222126007 s, accu: 0.8624747395515442, loss_yt: 0.2915794849395752\n",
      "epocht 8, batch_num 4200, step 316681, time: 160.4739224910736 s, accu: 0.8624783754348755, loss_yt: 0.34763839840888977\n",
      "epocht 8, batch_num 4400, step 316881, time: 168.05761122703552 s, accu: 0.8624839186668396, loss_yt: 0.2521097660064697\n",
      "epocht 8, batch_num 4600, step 317081, time: 175.49076795578003 s, accu: 0.8624890446662903, loss_yt: 0.3889365494251251\n",
      "epocht 8, batch_num 4800, step 317281, time: 183.07744646072388 s, accu: 0.8624902963638306, loss_yt: 0.27922680974006653\n",
      "epocht 8, batch_num 5000, step 317481, time: 190.52951955795288 s, accu: 0.8624908924102783, loss_yt: 0.29867932200431824\n",
      "epocht 8, batch_num 5200, step 317681, time: 198.1152629852295 s, accu: 0.8624932765960693, loss_yt: 0.3072870969772339\n",
      "epocht 8, batch_num 5400, step 317881, time: 205.77674961090088 s, accu: 0.8624907732009888, loss_yt: 0.15952616930007935\n",
      "epocht 8, batch_num 5600, step 318081, time: 213.50308990478516 s, accu: 0.8624924421310425, loss_yt: 0.2671002745628357\n",
      "epocht 8, batch_num 5800, step 318281, time: 221.15961384773254 s, accu: 0.8624941110610962, loss_yt: 0.2574291527271271\n",
      "epocht 8, batch_num 6000, step 318481, time: 228.63861656188965 s, accu: 0.8624956607818604, loss_yt: 0.41850370168685913\n",
      "epocht 8, batch_num 6200, step 318681, time: 235.98001742362976 s, accu: 0.8624990582466125, loss_yt: 0.1698427051305771\n",
      "epocht 8, batch_num 6400, step 318881, time: 243.73923540115356 s, accu: 0.8624997735023499, loss_yt: 0.2539485692977905\n",
      "epocht 8, batch_num 6600, step 319081, time: 251.36384844779968 s, accu: 0.8624990582466125, loss_yt: 0.23410102725028992\n",
      "epocht 8, batch_num 6800, step 319281, time: 259.0652549266815 s, accu: 0.8624978065490723, loss_yt: 0.5433663725852966\n",
      "epocht 8, batch_num 7000, step 319481, time: 266.58813762664795 s, accu: 0.8624964952468872, loss_yt: 0.3139946460723877\n",
      "epocht 8, batch_num 7200, step 319681, time: 274.3274419307709 s, accu: 0.8624975085258484, loss_yt: 0.3310663104057312\n",
      "epocht 8, batch_num 7400, step 319881, time: 281.85232186317444 s, accu: 0.862496018409729, loss_yt: 0.32011497020721436\n",
      "iter_validnum 1860\n",
      "epochv 8, step 319920, stop_n 0, time: 335.8090658187866 s, accu_va: 0.8625069291681372, loss_yv: 0.2979960382465393\n",
      "iter_trainnum 7440\n",
      "epocht 8, batch_num 0, step 319921, time: 0.42287611961364746 s, accu: 0.8625087738037109, loss_yt: 0.3180742859840393\n",
      "epocht 8, batch_num 200, step 320121, time: 8.173150777816772 s, accu: 0.8625093102455139, loss_yt: 0.27840107679367065\n",
      "epocht 8, batch_num 400, step 320321, time: 15.666081428527832 s, accu: 0.8625120520591736, loss_yt: 0.4683135449886322\n",
      "epocht 8, batch_num 600, step 320521, time: 23.278742790222168 s, accu: 0.8625119924545288, loss_yt: 0.27951741218566895\n",
      "epocht 8, batch_num 800, step 320721, time: 30.96222949028015 s, accu: 0.8625115156173706, loss_yt: 0.1425325721502304\n",
      "epocht 8, batch_num 1000, step 320921, time: 38.517974853515625 s, accu: 0.8625118732452393, loss_yt: 0.3379789888858795\n",
      "epocht 8, batch_num 1200, step 321121, time: 46.19843935966492 s, accu: 0.8625131845474243, loss_yt: 0.2770553231239319\n",
      "epocht 8, batch_num 1400, step 321321, time: 53.767231941223145 s, accu: 0.8625167608261108, loss_yt: 0.2864350974559784\n",
      "epocht 8, batch_num 1600, step 321521, time: 61.272162437438965 s, accu: 0.8625190258026123, loss_yt: 0.26688307523727417\n",
      "epocht 8, batch_num 1800, step 321721, time: 68.91668939590454 s, accu: 0.8625195026397705, loss_yt: 0.2804655134677887\n",
      "epocht 8, batch_num 2000, step 321921, time: 76.7297956943512 s, accu: 0.8625193238258362, loss_yt: 0.2620297372341156\n",
      "epocht 8, batch_num 2200, step 322121, time: 84.30952763557434 s, accu: 0.8625190258026123, loss_yt: 0.27273815870285034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 8, batch_num 2400, step 322321, time: 91.98999452590942 s, accu: 0.8625211119651794, loss_yt: 0.1688365787267685\n",
      "epocht 8, batch_num 2600, step 322521, time: 99.47796773910522 s, accu: 0.8625245690345764, loss_yt: 0.27088040113449097\n",
      "epocht 8, batch_num 2800, step 322721, time: 107.20134735107422 s, accu: 0.8625272512435913, loss_yt: 0.27979153394699097\n",
      "epocht 8, batch_num 3000, step 322921, time: 114.78307628631592 s, accu: 0.862528383731842, loss_yt: 0.25944462418556213\n",
      "epocht 8, batch_num 3200, step 323121, time: 122.4694893360138 s, accu: 0.8625293374061584, loss_yt: 0.24606747925281525\n",
      "epocht 8, batch_num 3400, step 323321, time: 130.27561354637146 s, accu: 0.8625268936157227, loss_yt: 0.4228375256061554\n",
      "epocht 8, batch_num 3600, step 323521, time: 138.04583525657654 s, accu: 0.8625286817550659, loss_yt: 0.22419767081737518\n",
      "epocht 8, batch_num 3800, step 323721, time: 145.8370349407196 s, accu: 0.862525224685669, loss_yt: 0.22827598452568054\n",
      "epocht 8, batch_num 4000, step 323921, time: 153.8386070728302 s, accu: 0.8625257015228271, loss_yt: 0.5452136397361755\n",
      "epocht 8, batch_num 4200, step 324121, time: 161.6477246284485 s, accu: 0.8625273108482361, loss_yt: 0.28091147541999817\n",
      "epocht 8, batch_num 4400, step 324321, time: 169.6064703464508 s, accu: 0.8625248670578003, loss_yt: 0.2703837454319\n",
      "epocht 8, batch_num 4600, step 324521, time: 177.61801862716675 s, accu: 0.8625263571739197, loss_yt: 0.2490357607603073\n",
      "epocht 8, batch_num 4800, step 324721, time: 185.4550952911377 s, accu: 0.8625272512435913, loss_yt: 0.15893837809562683\n",
      "epocht 8, batch_num 5000, step 324921, time: 193.29210591316223 s, accu: 0.8625274896621704, loss_yt: 0.3297004997730255\n",
      "epocht 8, batch_num 5200, step 325121, time: 200.97755694389343 s, accu: 0.8625307083129883, loss_yt: 0.2645072340965271\n",
      "epocht 8, batch_num 5400, step 325321, time: 208.87244415283203 s, accu: 0.8625295758247375, loss_yt: 0.3696102499961853\n",
      "epocht 8, batch_num 5600, step 325521, time: 216.74642181396484 s, accu: 0.8625292778015137, loss_yt: 0.1653282344341278\n",
      "epocht 8, batch_num 5800, step 325721, time: 224.4747245311737 s, accu: 0.8625309467315674, loss_yt: 0.3237045407295227\n",
      "epocht 8, batch_num 6000, step 325921, time: 232.13723278045654 s, accu: 0.8625320792198181, loss_yt: 0.10391492396593094\n",
      "epocht 8, batch_num 6200, step 326121, time: 240.0341169834137 s, accu: 0.8625335693359375, loss_yt: 0.30336737632751465\n",
      "epocht 8, batch_num 6400, step 326321, time: 247.9230546951294 s, accu: 0.8625329732894897, loss_yt: 0.40973564982414246\n",
      "epocht 8, batch_num 6600, step 326521, time: 255.85880088806152 s, accu: 0.8625304102897644, loss_yt: 0.3239372670650482\n",
      "epocht 8, batch_num 6800, step 326721, time: 263.6948471069336 s, accu: 0.8625341057777405, loss_yt: 0.23883822560310364\n",
      "epocht 8, batch_num 7000, step 326921, time: 271.68750834465027 s, accu: 0.8625389337539673, loss_yt: 0.14696449041366577\n",
      "epocht 8, batch_num 7200, step 327121, time: 279.47864270210266 s, accu: 0.8625409603118896, loss_yt: 0.3208947479724884\n",
      "epocht 8, batch_num 7400, step 327321, time: 287.15212297439575 s, accu: 0.8625436425209045, loss_yt: 0.31279706954956055\n",
      "iter_validnum 1860\n",
      "epochv 8, step 327360, stop_n 0, time: 343.76174783706665 s, accu_va: 0.8625546904981777, loss_yv: 0.2982448151275035\n",
      "iter_trainnum 7440\n",
      "epocht 8, batch_num 0, step 327361, time: 0.4637608528137207 s, accu: 0.8625592589378357, loss_yt: 0.25867584347724915\n",
      "epocht 8, batch_num 200, step 327561, time: 8.628927946090698 s, accu: 0.8625616431236267, loss_yt: 0.2883140444755554\n",
      "epocht 8, batch_num 400, step 327761, time: 16.56869411468506 s, accu: 0.8625598549842834, loss_yt: 0.29741790890693665\n",
      "epocht 8, batch_num 600, step 327961, time: 24.683029174804688 s, accu: 0.8625603914260864, loss_yt: 0.2574777603149414\n",
      "epocht 8, batch_num 800, step 328161, time: 32.31857872009277 s, accu: 0.8625614047050476, loss_yt: 0.11029934138059616\n",
      "epocht 8, batch_num 1000, step 328361, time: 40.24338746070862 s, accu: 0.8625637292861938, loss_yt: 0.23500767350196838\n",
      "epocht 8, batch_num 1200, step 328561, time: 47.8999137878418 s, accu: 0.862566351890564, loss_yt: 0.10024700313806534\n",
      "epocht 8, batch_num 1400, step 328761, time: 56.11893677711487 s, accu: 0.8625643253326416, loss_yt: 0.49452513456344604\n",
      "epocht 8, batch_num 1600, step 328961, time: 64.0198106765747 s, accu: 0.8625630140304565, loss_yt: 0.46256762742996216\n",
      "epocht 8, batch_num 1800, step 329161, time: 72.09125137329102 s, accu: 0.8625649809837341, loss_yt: 0.3420107662677765\n",
      "epocht 8, batch_num 2000, step 329361, time: 79.91829776763916 s, accu: 0.8625655174255371, loss_yt: 0.1835932433605194\n",
      "epocht 8, batch_num 2200, step 329561, time: 87.6007866859436 s, accu: 0.8625687956809998, loss_yt: 0.3314867913722992\n",
      "epocht 8, batch_num 2400, step 329761, time: 95.50362086296082 s, accu: 0.8625706434249878, loss_yt: 0.22860059142112732\n",
      "epocht 8, batch_num 2600, step 329961, time: 103.54910945892334 s, accu: 0.862570583820343, loss_yt: 0.28643423318862915\n",
      "epocht 8, batch_num 2800, step 330161, time: 111.59957957267761 s, accu: 0.8625732660293579, loss_yt: 0.26703381538391113\n",
      "epocht 8, batch_num 3000, step 330361, time: 119.67102241516113 s, accu: 0.8625698685646057, loss_yt: 0.39580485224723816\n",
      "epocht 8, batch_num 3200, step 330561, time: 127.44724202156067 s, accu: 0.8625692129135132, loss_yt: 0.23004287481307983\n",
      "epocht 8, batch_num 3400, step 330761, time: 135.4168930053711 s, accu: 0.8625689744949341, loss_yt: 0.2598254978656769\n",
      "epocht 8, batch_num 3600, step 330961, time: 143.21803092956543 s, accu: 0.8625702261924744, loss_yt: 0.2747797667980194\n",
      "epocht 8, batch_num 3800, step 331161, time: 151.09197783470154 s, accu: 0.8625668287277222, loss_yt: 0.2572598457336426\n",
      "epocht 8, batch_num 4000, step 331361, time: 159.08264231681824 s, accu: 0.8625679612159729, loss_yt: 0.4205298125743866\n",
      "epocht 8, batch_num 4200, step 331561, time: 167.23281455039978 s, accu: 0.862568199634552, loss_yt: 0.33131569623947144\n",
      "epocht 8, batch_num 4400, step 331761, time: 175.1277039051056 s, accu: 0.862568736076355, loss_yt: 0.2513708770275116\n",
      "epocht 8, batch_num 4600, step 331961, time: 182.90893173217773 s, accu: 0.862571120262146, loss_yt: 0.5255739688873291\n",
      "epocht 8, batch_num 4800, step 332161, time: 190.88260769844055 s, accu: 0.8625711798667908, loss_yt: 0.28820180892944336\n",
      "epocht 8, batch_num 5000, step 332361, time: 198.75951313972473 s, accu: 0.8625751733779907, loss_yt: 0.23911671340465546\n",
      "epocht 8, batch_num 5200, step 332561, time: 206.783056974411 s, accu: 0.862576961517334, loss_yt: 0.3959367275238037\n",
      "epocht 8, batch_num 5400, step 332761, time: 215.0639169216156 s, accu: 0.8625751733779907, loss_yt: 0.3471047580242157\n",
      "epocht 8, batch_num 5600, step 332961, time: 222.79226517677307 s, accu: 0.8625789880752563, loss_yt: 0.4068683087825775\n",
      "epocht 8, batch_num 5800, step 333161, time: 230.69315433502197 s, accu: 0.862585186958313, loss_yt: 0.1416151076555252\n",
      "epocht 8, batch_num 6000, step 333361, time: 238.65383410453796 s, accu: 0.8625879287719727, loss_yt: 0.27018389105796814\n",
      "epocht 8, batch_num 6200, step 333561, time: 246.70530533790588 s, accu: 0.8625863194465637, loss_yt: 0.30135318636894226\n",
      "epocht 8, batch_num 6400, step 333761, time: 254.63310432434082 s, accu: 0.8625863194465637, loss_yt: 0.1671481728553772\n",
      "epocht 8, batch_num 6600, step 333961, time: 262.4721429347992 s, accu: 0.8625904321670532, loss_yt: 0.3327782154083252\n",
      "epocht 8, batch_num 6800, step 334161, time: 270.4897038936615 s, accu: 0.8625892996788025, loss_yt: 0.2920336127281189\n",
      "epocht 8, batch_num 7000, step 334361, time: 278.30680108070374 s, accu: 0.8625909686088562, loss_yt: 0.14314764738082886\n",
      "epocht 8, batch_num 7200, step 334561, time: 286.02715730667114 s, accu: 0.8625905513763428, loss_yt: 0.2572914958000183\n",
      "epocht 8, batch_num 7400, step 334761, time: 293.82633447647095 s, accu: 0.8625926971435547, loss_yt: 0.27623847126960754\n",
      "iter_validnum 1860\n",
      "epochv 8, step 334800, stop_n 0, time: 349.12144207954407 s, accu_va: 0.8625978875544763, loss_yv: 0.29866405263222673\n",
      "iter_trainnum 7440\n",
      "epocht 9, batch_num 0, step 334801, time: 0.42386651039123535 s, accu: 0.8626019954681396, loss_yt: 0.37562018632888794\n",
      "epocht 9, batch_num 200, step 335001, time: 8.148211479187012 s, accu: 0.8625999689102173, loss_yt: 0.3023506700992584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 9, batch_num 400, step 335201, time: 15.781797409057617 s, accu: 0.8626013398170471, loss_yt: 0.1885717660188675\n",
      "epocht 9, batch_num 600, step 335401, time: 23.508164167404175 s, accu: 0.8626018166542053, loss_yt: 0.2690924406051636\n",
      "epocht 9, batch_num 800, step 335601, time: 31.359143495559692 s, accu: 0.8626047372817993, loss_yt: 0.3014242947101593\n",
      "epocht 9, batch_num 1000, step 335801, time: 39.155327558517456 s, accu: 0.862605631351471, loss_yt: 0.241115540266037\n",
      "epocht 9, batch_num 1200, step 336001, time: 46.73203682899475 s, accu: 0.8626102209091187, loss_yt: 0.26225730776786804\n",
      "epocht 9, batch_num 1400, step 336201, time: 54.45139408111572 s, accu: 0.8626109957695007, loss_yt: 0.354638934135437\n",
      "epocht 9, batch_num 1600, step 336401, time: 62.43504548072815 s, accu: 0.862612783908844, loss_yt: 0.2805190086364746\n",
      "epocht 9, batch_num 1800, step 336601, time: 70.11850070953369 s, accu: 0.8626132607460022, loss_yt: 0.2696481943130493\n",
      "epocht 9, batch_num 2000, step 336801, time: 77.86877870559692 s, accu: 0.8626115322113037, loss_yt: 0.1756431758403778\n",
      "epocht 9, batch_num 2200, step 337001, time: 85.88234877586365 s, accu: 0.8626099228858948, loss_yt: 0.34362974762916565\n",
      "epocht 9, batch_num 2400, step 337201, time: 94.23201966285706 s, accu: 0.8626121282577515, loss_yt: 0.3530137240886688\n",
      "epocht 9, batch_num 2600, step 337401, time: 102.35529923439026 s, accu: 0.862610399723053, loss_yt: 0.2957259714603424\n",
      "epocht 9, batch_num 2800, step 337601, time: 110.8326313495636 s, accu: 0.8626075983047485, loss_yt: 0.4572440981864929\n",
      "epocht 9, batch_num 3000, step 337801, time: 119.19526934623718 s, accu: 0.8626074194908142, loss_yt: 0.19397175312042236\n",
      "epocht 9, batch_num 3200, step 338001, time: 127.23482131958008 s, accu: 0.8626086115837097, loss_yt: 0.31515929102897644\n",
      "epocht 9, batch_num 3400, step 338201, time: 135.07283997535706 s, accu: 0.8626091480255127, loss_yt: 0.29607465863227844\n",
      "epocht 9, batch_num 3600, step 338401, time: 143.27787041664124 s, accu: 0.8626104593276978, loss_yt: 0.20374280214309692\n",
      "epocht 9, batch_num 3800, step 338601, time: 151.55275106430054 s, accu: 0.8626115918159485, loss_yt: 0.5398638248443604\n",
      "epocht 9, batch_num 4000, step 338801, time: 159.163391828537 s, accu: 0.8626161217689514, loss_yt: 0.22710764408111572\n",
      "epocht 9, batch_num 4200, step 339001, time: 167.23680472373962 s, accu: 0.8626176118850708, loss_yt: 0.17758630216121674\n",
      "epocht 9, batch_num 4400, step 339201, time: 174.82152128219604 s, accu: 0.8626167178153992, loss_yt: 0.3169889748096466\n",
      "epocht 9, batch_num 4600, step 339401, time: 182.93283224105835 s, accu: 0.8626201748847961, loss_yt: 0.3385525047779083\n",
      "epocht 9, batch_num 4800, step 339601, time: 190.5574746131897 s, accu: 0.8626242280006409, loss_yt: 0.25246691703796387\n",
      "epocht 9, batch_num 5000, step 339801, time: 198.3007390499115 s, accu: 0.8626272082328796, loss_yt: 0.2908191978931427\n",
      "epocht 9, batch_num 5200, step 340001, time: 206.64941382408142 s, accu: 0.8626253604888916, loss_yt: 0.4542607367038727\n",
      "epocht 9, batch_num 5400, step 340201, time: 214.54330492019653 s, accu: 0.8626248836517334, loss_yt: 0.2543574273586273\n",
      "epocht 9, batch_num 5600, step 340401, time: 222.3793544769287 s, accu: 0.8626271486282349, loss_yt: 0.32709020376205444\n",
      "epocht 9, batch_num 5800, step 340601, time: 230.02593684196472 s, accu: 0.8626326322555542, loss_yt: 0.29610785841941833\n",
      "epocht 9, batch_num 6000, step 340801, time: 238.28781127929688 s, accu: 0.8626335263252258, loss_yt: 0.366558700799942\n",
      "epocht 9, batch_num 6200, step 341001, time: 246.9486527442932 s, accu: 0.8626344203948975, loss_yt: 0.12598088383674622\n",
      "epocht 9, batch_num 6400, step 341201, time: 254.99716520309448 s, accu: 0.8626364469528198, loss_yt: 0.5204694867134094\n",
      "epocht 9, batch_num 6600, step 341401, time: 263.0785207748413 s, accu: 0.8626375198364258, loss_yt: 0.20270001888275146\n",
      "epocht 9, batch_num 6800, step 341601, time: 270.8238101005554 s, accu: 0.8626360297203064, loss_yt: 0.167276993393898\n",
      "epocht 9, batch_num 7000, step 341801, time: 278.72471499443054 s, accu: 0.8626366257667542, loss_yt: 0.3247796893119812\n",
      "epocht 9, batch_num 7200, step 342001, time: 286.7392563819885 s, accu: 0.8626365661621094, loss_yt: 0.49118345975875854\n",
      "epocht 9, batch_num 7400, step 342201, time: 294.55335664749146 s, accu: 0.8626359105110168, loss_yt: 0.27089357376098633\n",
      "iter_validnum 1860\n",
      "epochv 9, step 342240, stop_n 0, time: 349.6121277809143 s, accu_va: 0.862638928621046, loss_yv: 0.30087939104245554\n",
      "iter_trainnum 7440\n",
      "epocht 9, batch_num 0, step 342241, time: 0.4827079772949219 s, accu: 0.8626412749290466, loss_yt: 0.14198021590709686\n",
      "epocht 9, batch_num 200, step 342441, time: 9.787859201431274 s, accu: 0.8626392483711243, loss_yt: 0.2674430310726166\n",
      "epocht 9, batch_num 400, step 342641, time: 17.69568133354187 s, accu: 0.8626404404640198, loss_yt: 0.27803942561149597\n",
      "epocht 9, batch_num 600, step 342841, time: 25.616514205932617 s, accu: 0.8626430630683899, loss_yt: 0.22494365274906158\n",
      "epocht 9, batch_num 800, step 343041, time: 33.21119141578674 s, accu: 0.8626454472541809, loss_yt: 0.16757860779762268\n",
      "epocht 9, batch_num 1000, step 343241, time: 41.10009837150574 s, accu: 0.862647294998169, loss_yt: 0.32894113659858704\n",
      "epocht 9, batch_num 1200, step 343441, time: 48.595054388046265 s, accu: 0.8626474142074585, loss_yt: 0.1363624781370163\n",
      "epocht 9, batch_num 1400, step 343641, time: 56.28053140640259 s, accu: 0.8626492023468018, loss_yt: 0.3558080196380615\n",
      "epocht 9, batch_num 1600, step 343841, time: 63.83032274246216 s, accu: 0.8626527786254883, loss_yt: 0.4682557284832001\n",
      "epocht 9, batch_num 1800, step 344041, time: 71.49880957603455 s, accu: 0.8626581430435181, loss_yt: 0.19926197826862335\n",
      "epocht 9, batch_num 2000, step 344241, time: 79.25410485267639 s, accu: 0.862656831741333, loss_yt: 0.36017560958862305\n",
      "epocht 9, batch_num 2200, step 344441, time: 86.74504232406616 s, accu: 0.8626553416252136, loss_yt: 0.13793309032917023\n",
      "epocht 9, batch_num 2400, step 344641, time: 94.55814814567566 s, accu: 0.8626545667648315, loss_yt: 0.15006569027900696\n",
      "epocht 9, batch_num 2600, step 344841, time: 102.00324082374573 s, accu: 0.8626583814620972, loss_yt: 0.15365181863307953\n",
      "epocht 9, batch_num 2800, step 345041, time: 109.83033084869385 s, accu: 0.8626574277877808, loss_yt: 0.12503719329833984\n",
      "epocht 9, batch_num 3000, step 345241, time: 117.34524869918823 s, accu: 0.862657368183136, loss_yt: 0.289145290851593\n",
      "epocht 9, batch_num 3200, step 345441, time: 124.96284508705139 s, accu: 0.8626580238342285, loss_yt: 0.2399408370256424\n",
      "epocht 9, batch_num 3400, step 345641, time: 132.40794324874878 s, accu: 0.8626602292060852, loss_yt: 0.28269729018211365\n",
      "epocht 9, batch_num 3600, step 345841, time: 140.0285608768463 s, accu: 0.8626620769500732, loss_yt: 0.23992757499217987\n",
      "epocht 9, batch_num 3800, step 346041, time: 147.962388753891 s, accu: 0.8626620769500732, loss_yt: 0.23193585872650146\n",
      "epocht 9, batch_num 4000, step 346241, time: 155.53612852096558 s, accu: 0.8626612424850464, loss_yt: 0.15136338770389557\n",
      "epocht 9, batch_num 4200, step 346441, time: 163.72220396995544 s, accu: 0.8626599907875061, loss_yt: 0.25026237964630127\n",
      "epocht 9, batch_num 4400, step 346641, time: 171.192227602005 s, accu: 0.8626613020896912, loss_yt: 0.316450834274292\n",
      "epocht 9, batch_num 4600, step 346841, time: 178.78791618347168 s, accu: 0.8626620769500732, loss_yt: 0.2737051248550415\n",
      "epocht 9, batch_num 4800, step 347041, time: 186.20109343528748 s, accu: 0.862662672996521, loss_yt: 0.21092402935028076\n",
      "epocht 9, batch_num 5000, step 347241, time: 193.86858987808228 s, accu: 0.8626642227172852, loss_yt: 0.20168693363666534\n",
      "epocht 9, batch_num 5200, step 347441, time: 201.69067978858948 s, accu: 0.8626648187637329, loss_yt: 0.38828152418136597\n",
      "epocht 9, batch_num 5400, step 347641, time: 209.3272988796234 s, accu: 0.862663984298706, loss_yt: 0.3181575536727905\n",
      "epocht 9, batch_num 5600, step 347841, time: 216.94790148735046 s, accu: 0.8626680374145508, loss_yt: 0.23735247552394867\n",
      "epocht 9, batch_num 5800, step 348041, time: 224.23143219947815 s, accu: 0.8626732230186462, loss_yt: 0.19940434396266937\n",
      "epocht 9, batch_num 6000, step 348241, time: 231.8540496826172 s, accu: 0.8626738786697388, loss_yt: 0.5422692894935608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 9, batch_num 6200, step 348441, time: 239.56938695907593 s, accu: 0.862671971321106, loss_yt: 0.29265132546424866\n",
      "epocht 9, batch_num 6400, step 348641, time: 247.30470061302185 s, accu: 0.8626725673675537, loss_yt: 0.37620630860328674\n",
      "epocht 9, batch_num 6600, step 348841, time: 255.25547313690186 s, accu: 0.8626721501350403, loss_yt: 0.4163377583026886\n",
      "epocht 9, batch_num 6800, step 349041, time: 262.9020285606384 s, accu: 0.8626728653907776, loss_yt: 0.32258814573287964\n",
      "epocht 9, batch_num 7000, step 349241, time: 270.5285997390747 s, accu: 0.862675130367279, loss_yt: 0.29784417152404785\n",
      "epocht 9, batch_num 7200, step 349441, time: 278.11232233047485 s, accu: 0.8626758456230164, loss_yt: 0.3692385256290436\n",
      "epocht 9, batch_num 7400, step 349641, time: 286.14586639404297 s, accu: 0.8626768589019775, loss_yt: 0.35237154364585876\n",
      "iter_validnum 1860\n",
      "epochv 9, step 349680, stop_n 0, time: 339.7365708351135 s, accu_va: 0.8626810955104007, loss_yv: 0.3030099401350624\n",
      "iter_trainnum 7440\n",
      "epocht 9, batch_num 0, step 349681, time: 0.3201417922973633 s, accu: 0.8626794815063477, loss_yt: 0.26978418231010437\n",
      "epocht 9, batch_num 200, step 349881, time: 7.970651626586914 s, accu: 0.8626806735992432, loss_yt: 0.34168246388435364\n",
      "epocht 9, batch_num 400, step 350081, time: 15.426757335662842 s, accu: 0.8626791834831238, loss_yt: 0.3474315106868744\n",
      "epocht 9, batch_num 600, step 350281, time: 22.88480281829834 s, accu: 0.862680196762085, loss_yt: 0.2685290277004242\n",
      "epocht 9, batch_num 800, step 350481, time: 30.270055770874023 s, accu: 0.8626810312271118, loss_yt: 0.15064571797847748\n",
      "epocht 9, batch_num 1000, step 350681, time: 37.89366793632507 s, accu: 0.86268150806427, loss_yt: 0.3174249827861786\n",
      "epocht 9, batch_num 1200, step 350881, time: 45.662861585617065 s, accu: 0.8626816868782043, loss_yt: 0.265625536441803\n",
      "epocht 9, batch_num 1400, step 351081, time: 53.33733773231506 s, accu: 0.8626843094825745, loss_yt: 0.2610258162021637\n",
      "epocht 9, batch_num 1600, step 351281, time: 61.03974175453186 s, accu: 0.86268150806427, loss_yt: 0.21324191987514496\n",
      "epocht 9, batch_num 1800, step 351481, time: 68.77306294441223 s, accu: 0.8626840114593506, loss_yt: 0.2714099586009979\n",
      "epocht 9, batch_num 2000, step 351681, time: 76.40567994117737 s, accu: 0.8626836538314819, loss_yt: 0.14688847959041595\n",
      "epocht 9, batch_num 2200, step 351881, time: 84.1429660320282 s, accu: 0.862686812877655, loss_yt: 0.42226889729499817\n",
      "epocht 9, batch_num 2400, step 352081, time: 91.76661133766174 s, accu: 0.8626857995986938, loss_yt: 0.2928806245326996\n",
      "epocht 9, batch_num 2600, step 352281, time: 99.54282879829407 s, accu: 0.8626857399940491, loss_yt: 0.3647453784942627\n",
      "epocht 9, batch_num 2800, step 352481, time: 107.30403184890747 s, accu: 0.8626870512962341, loss_yt: 0.383028507232666\n",
      "epocht 9, batch_num 3000, step 352681, time: 115.1510488986969 s, accu: 0.862687349319458, loss_yt: 0.16102588176727295\n",
      "epocht 9, batch_num 3200, step 352881, time: 122.65897059440613 s, accu: 0.8626860976219177, loss_yt: 0.30023106932640076\n",
      "epocht 9, batch_num 3400, step 353081, time: 130.42620158195496 s, accu: 0.8626906275749207, loss_yt: 0.32802391052246094\n",
      "epocht 9, batch_num 3600, step 353281, time: 137.8952624797821 s, accu: 0.8626933097839355, loss_yt: 0.24795636534690857\n",
      "epocht 9, batch_num 3800, step 353481, time: 145.5507574081421 s, accu: 0.8626941442489624, loss_yt: 0.3127581775188446\n",
      "epocht 9, batch_num 4000, step 353681, time: 152.95795035362244 s, accu: 0.8626963496208191, loss_yt: 0.2611096501350403\n",
      "epocht 9, batch_num 4200, step 353881, time: 160.43695163726807 s, accu: 0.8626968860626221, loss_yt: 0.4477092921733856\n",
      "epocht 9, batch_num 4400, step 354081, time: 168.26801204681396 s, accu: 0.8626985549926758, loss_yt: 0.5739145278930664\n",
      "epocht 9, batch_num 4600, step 354281, time: 175.8208155632019 s, accu: 0.8626999855041504, loss_yt: 0.2891230583190918\n",
      "epocht 9, batch_num 4800, step 354481, time: 183.656893491745 s, accu: 0.862699031829834, loss_yt: 0.29656311869621277\n",
      "epocht 9, batch_num 5000, step 354681, time: 191.22765040397644 s, accu: 0.8626993894577026, loss_yt: 0.32606735825538635\n",
      "epocht 9, batch_num 5200, step 354881, time: 198.79538011550903 s, accu: 0.8627033233642578, loss_yt: 0.2921488881111145\n",
      "epocht 9, batch_num 5400, step 355081, time: 206.34522461891174 s, accu: 0.8627054691314697, loss_yt: 0.2739033102989197\n",
      "epocht 9, batch_num 5600, step 355281, time: 213.89201283454895 s, accu: 0.8627055883407593, loss_yt: 0.24311339855194092\n",
      "epocht 9, batch_num 5800, step 355481, time: 221.7490029335022 s, accu: 0.8627036213874817, loss_yt: 0.41771185398101807\n",
      "epocht 9, batch_num 6000, step 355681, time: 229.34270215034485 s, accu: 0.8627039194107056, loss_yt: 0.44486004114151\n",
      "epocht 9, batch_num 6200, step 355881, time: 237.37521839141846 s, accu: 0.8627032041549683, loss_yt: 0.29813843965530396\n",
      "epocht 9, batch_num 6400, step 356081, time: 245.01280283927917 s, accu: 0.8627034425735474, loss_yt: 0.29655539989471436\n",
      "epocht 9, batch_num 6600, step 356281, time: 252.62842893600464 s, accu: 0.8627035021781921, loss_yt: 0.29440802335739136\n",
      "epocht 9, batch_num 6800, step 356481, time: 260.1154088973999 s, accu: 0.8627042770385742, loss_yt: 0.36830905079841614\n",
      "epocht 9, batch_num 7000, step 356681, time: 267.5066833496094 s, accu: 0.8627067804336548, loss_yt: 0.26474031805992126\n",
      "epocht 9, batch_num 7200, step 356881, time: 275.2539448738098 s, accu: 0.8627052903175354, loss_yt: 0.2848227322101593\n",
      "epocht 9, batch_num 7400, step 357081, time: 282.9882798194885 s, accu: 0.8627053499221802, loss_yt: 0.11857765167951584\n",
      "iter_validnum 1860\n",
      "epochv 9, step 357120, stop_n 1, time: 337.0357222557068 s, accu_va: 0.8627124202507799, loss_yv: 0.29816381470250186\n",
      "iter_trainnum 7440\n",
      "epocht 9, batch_num 0, step 357121, time: 0.4727358818054199 s, accu: 0.8627176880836487, loss_yt: 0.3565422594547272\n",
      "epocht 9, batch_num 200, step 357321, time: 7.82806921005249 s, accu: 0.8627204895019531, loss_yt: 0.3135623037815094\n",
      "epocht 9, batch_num 400, step 357521, time: 15.249261140823364 s, accu: 0.862722635269165, loss_yt: 0.23186929523944855\n",
      "epocht 9, batch_num 600, step 357721, time: 22.941686868667603 s, accu: 0.8627233505249023, loss_yt: 0.32666924595832825\n",
      "epocht 9, batch_num 800, step 357921, time: 30.73082995414734 s, accu: 0.8627241253852844, loss_yt: 0.2217542678117752\n",
      "epocht 9, batch_num 1000, step 358121, time: 38.33748650550842 s, accu: 0.862722635269165, loss_yt: 0.31012800335884094\n",
      "epocht 9, batch_num 1200, step 358321, time: 45.826459646224976 s, accu: 0.8627240657806396, loss_yt: 0.40019264817237854\n",
      "epocht 9, batch_num 1400, step 358521, time: 53.538838386535645 s, accu: 0.8627220392227173, loss_yt: 0.2932807207107544\n",
      "epocht 9, batch_num 1600, step 358721, time: 61.005868673324585 s, accu: 0.8627225160598755, loss_yt: 0.4042350649833679\n",
      "epocht 9, batch_num 1800, step 358921, time: 68.5656988620758 s, accu: 0.8627228140830994, loss_yt: 0.513920783996582\n",
      "epocht 9, batch_num 2000, step 359121, time: 76.1553590297699 s, accu: 0.8627249002456665, loss_yt: 0.43600592017173767\n",
      "epocht 9, batch_num 2200, step 359321, time: 83.96750283241272 s, accu: 0.8627256751060486, loss_yt: 0.20205865800380707\n",
      "epocht 9, batch_num 2400, step 359521, time: 91.62501883506775 s, accu: 0.862724781036377, loss_yt: 0.37493354082107544\n",
      "epocht 9, batch_num 2600, step 359721, time: 99.27656555175781 s, accu: 0.8627227544784546, loss_yt: 0.24999547004699707\n",
      "epocht 9, batch_num 2800, step 359921, time: 106.80942249298096 s, accu: 0.8627236485481262, loss_yt: 0.15161854028701782\n",
      "epocht 9, batch_num 3000, step 360121, time: 114.30737709999084 s, accu: 0.8627272844314575, loss_yt: 0.5201299786567688\n",
      "epocht 9, batch_num 3200, step 360321, time: 121.87111568450928 s, accu: 0.8627269268035889, loss_yt: 0.22628699243068695\n",
      "epocht 9, batch_num 3400, step 360521, time: 129.5007393360138 s, accu: 0.8627228140830994, loss_yt: 0.26027947664260864\n",
      "epocht 9, batch_num 3600, step 360721, time: 137.1692395210266 s, accu: 0.8627238273620605, loss_yt: 0.1985854059457779\n",
      "epocht 9, batch_num 3800, step 360921, time: 144.7928204536438 s, accu: 0.8627243638038635, loss_yt: 0.28827357292175293\n",
      "epocht 9, batch_num 4000, step 361121, time: 152.1690971851349 s, accu: 0.8627265095710754, loss_yt: 0.357217401266098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 9, batch_num 4200, step 361321, time: 159.55235385894775 s, accu: 0.8627271056175232, loss_yt: 0.2054743617773056\n",
      "epocht 9, batch_num 4400, step 361521, time: 167.24977278709412 s, accu: 0.8627280592918396, loss_yt: 0.3687201142311096\n",
      "epocht 9, batch_num 4600, step 361721, time: 175.1336967945099 s, accu: 0.8627290725708008, loss_yt: 0.2724210321903229\n",
      "epocht 9, batch_num 4800, step 361921, time: 182.70643997192383 s, accu: 0.862730085849762, loss_yt: 0.26240217685699463\n",
      "epocht 9, batch_num 5000, step 362121, time: 190.33803176879883 s, accu: 0.8627296686172485, loss_yt: 0.3834371864795685\n",
      "epocht 9, batch_num 5200, step 362321, time: 198.12022185325623 s, accu: 0.8627308011054993, loss_yt: 0.2789261043071747\n",
      "epocht 9, batch_num 5400, step 362521, time: 205.77076601982117 s, accu: 0.8627321124076843, loss_yt: 0.27385956048965454\n",
      "epocht 9, batch_num 5600, step 362721, time: 213.40435242652893 s, accu: 0.8627321720123291, loss_yt: 0.25932618975639343\n",
      "epocht 9, batch_num 5800, step 362921, time: 220.9242434501648 s, accu: 0.862732470035553, loss_yt: 0.28530389070510864\n",
      "epocht 9, batch_num 6000, step 363121, time: 229.11434316635132 s, accu: 0.8627355098724365, loss_yt: 0.2723076045513153\n",
      "epocht 9, batch_num 6200, step 363321, time: 236.6980905532837 s, accu: 0.86273592710495, loss_yt: 0.30457770824432373\n",
      "epocht 9, batch_num 6400, step 363521, time: 244.84926843643188 s, accu: 0.8627375960350037, loss_yt: 0.5542834401130676\n",
      "epocht 9, batch_num 6600, step 363721, time: 252.7920286655426 s, accu: 0.862737238407135, loss_yt: 0.22188259661197662\n",
      "epocht 9, batch_num 6800, step 363921, time: 260.8564658164978 s, accu: 0.8627395629882812, loss_yt: 0.5010119676589966\n",
      "epocht 9, batch_num 7000, step 364121, time: 268.47808718681335 s, accu: 0.8627386093139648, loss_yt: 0.2472468465566635\n",
      "epocht 9, batch_num 7200, step 364321, time: 276.24232244491577 s, accu: 0.8627392053604126, loss_yt: 0.31830644607543945\n",
      "epocht 9, batch_num 7400, step 364521, time: 284.45536184310913 s, accu: 0.862740695476532, loss_yt: 0.1696079522371292\n",
      "iter_validnum 1860\n",
      "epochv 9, step 364560, stop_n 2, time: 341.81198716163635 s, accu_va: 0.8627470536257631, loss_yv: 0.29810191608004033\n",
      "iter_trainnum 7440\n",
      "epocht 9, batch_num 0, step 364561, time: 0.5515272617340088 s, accu: 0.8627530932426453, loss_yt: 0.30531418323516846\n",
      "epocht 9, batch_num 200, step 364761, time: 8.6997389793396 s, accu: 0.862754225730896, loss_yt: 0.2599455416202545\n",
      "epocht 9, batch_num 400, step 364961, time: 16.76319694519043 s, accu: 0.862754225730896, loss_yt: 0.30497148633003235\n",
      "epocht 9, batch_num 600, step 365161, time: 24.84758996963501 s, accu: 0.8627563118934631, loss_yt: 0.19758927822113037\n",
      "epocht 9, batch_num 800, step 365361, time: 32.987823486328125 s, accu: 0.8627535104751587, loss_yt: 0.5018634796142578\n",
      "epocht 9, batch_num 1000, step 365561, time: 41.29461050033569 s, accu: 0.8627516031265259, loss_yt: 0.394401490688324\n",
      "epocht 9, batch_num 1200, step 365761, time: 48.92720103263855 s, accu: 0.8627517819404602, loss_yt: 0.3956761956214905\n",
      "epocht 9, batch_num 1400, step 365961, time: 56.42016553878784 s, accu: 0.8627529144287109, loss_yt: 0.24617703258991241\n",
      "epocht 9, batch_num 1600, step 366161, time: 64.1395034790039 s, accu: 0.8627529740333557, loss_yt: 0.3465490937232971\n",
      "epocht 9, batch_num 1800, step 366361, time: 72.03441143035889 s, accu: 0.8627525568008423, loss_yt: 0.2928202748298645\n",
      "epocht 9, batch_num 2000, step 366561, time: 79.40965795516968 s, accu: 0.8627539873123169, loss_yt: 0.2298765331506729\n",
      "epocht 9, batch_num 2200, step 366761, time: 87.02532505989075 s, accu: 0.862754762172699, loss_yt: 0.19844463467597961\n",
      "epocht 9, batch_num 2400, step 366961, time: 94.5661289691925 s, accu: 0.8627548813819885, loss_yt: 0.31738224625587463\n",
      "epocht 9, batch_num 2600, step 367161, time: 102.1009795665741 s, accu: 0.8627562522888184, loss_yt: 0.14396172761917114\n",
      "epocht 9, batch_num 2800, step 367361, time: 109.5051805973053 s, accu: 0.8627575635910034, loss_yt: 0.1863095909357071\n",
      "epocht 9, batch_num 3000, step 367561, time: 117.21257090568542 s, accu: 0.862759530544281, loss_yt: 0.21614773571491241\n",
      "epocht 9, batch_num 3200, step 367761, time: 124.94489479064941 s, accu: 0.8627619743347168, loss_yt: 0.37916797399520874\n",
      "epocht 9, batch_num 3400, step 367961, time: 132.53063941001892 s, accu: 0.8627636432647705, loss_yt: 0.25175124406814575\n",
      "epocht 9, batch_num 3600, step 368161, time: 140.10735082626343 s, accu: 0.8627655506134033, loss_yt: 0.34231239557266235\n",
      "epocht 9, batch_num 3800, step 368361, time: 147.92148876190186 s, accu: 0.8627665042877197, loss_yt: 0.30384984612464905\n",
      "epocht 9, batch_num 4000, step 368561, time: 155.55803513526917 s, accu: 0.8627675175666809, loss_yt: 0.39022722840309143\n",
      "epocht 9, batch_num 4200, step 368761, time: 163.05000138282776 s, accu: 0.862769365310669, loss_yt: 0.2746414840221405\n",
      "epocht 9, batch_num 4400, step 368961, time: 170.63077402114868 s, accu: 0.8627697825431824, loss_yt: 0.4554194211959839\n",
      "epocht 9, batch_num 4600, step 369161, time: 178.33612632751465 s, accu: 0.8627699613571167, loss_yt: 0.40009620785713196\n",
      "epocht 9, batch_num 4800, step 369361, time: 185.9148621559143 s, accu: 0.8627726435661316, loss_yt: 0.30221226811408997\n",
      "epocht 9, batch_num 5000, step 369561, time: 193.45868730545044 s, accu: 0.8627738952636719, loss_yt: 0.3165234625339508\n",
      "epocht 9, batch_num 5200, step 369761, time: 200.9566376209259 s, accu: 0.8627772927284241, loss_yt: 0.3803847134113312\n",
      "epocht 9, batch_num 5400, step 369961, time: 208.43164992332458 s, accu: 0.8627786636352539, loss_yt: 0.21775810420513153\n",
      "epocht 9, batch_num 5600, step 370161, time: 215.92165088653564 s, accu: 0.8627771735191345, loss_yt: 0.3805437684059143\n",
      "epocht 9, batch_num 5800, step 370361, time: 223.3737087249756 s, accu: 0.862775981426239, loss_yt: 0.28262409567832947\n",
      "epocht 9, batch_num 6000, step 370561, time: 231.07809209823608 s, accu: 0.8627749681472778, loss_yt: 0.3335797190666199\n",
      "epocht 9, batch_num 6200, step 370761, time: 238.6368808746338 s, accu: 0.8627753257751465, loss_yt: 0.26498502492904663\n",
      "epocht 9, batch_num 6400, step 370961, time: 246.27548670768738 s, accu: 0.8627786040306091, loss_yt: 0.23747047781944275\n",
      "epocht 9, batch_num 6600, step 371161, time: 253.90207648277283 s, accu: 0.8627786636352539, loss_yt: 0.2586739659309387\n",
      "epocht 9, batch_num 6800, step 371361, time: 261.5406348705292 s, accu: 0.8627792596817017, loss_yt: 0.3081618845462799\n",
      "epocht 9, batch_num 7000, step 371561, time: 269.0815079212189 s, accu: 0.862779438495636, loss_yt: 0.26803696155548096\n",
      "epocht 9, batch_num 7200, step 371761, time: 276.39491415023804 s, accu: 0.8627817630767822, loss_yt: 0.18044711649417877\n",
      "epocht 9, batch_num 7400, step 371961, time: 284.04745149612427 s, accu: 0.8627802729606628, loss_yt: 0.41094154119491577\n",
      "iter_validnum 1860\n",
      "epochv 9, step 372000, stop_n 0, time: 337.70497727394104 s, accu_va: 0.8627867584587425, loss_yv: 0.29863964308013197\n",
      "iter_trainnum 7440\n",
      "epocht 10, batch_num 0, step 372001, time: 0.4278559684753418 s, accu: 0.8627882599830627, loss_yt: 0.30638256669044495\n",
      "epocht 10, batch_num 200, step 372201, time: 8.061444282531738 s, accu: 0.8627901673316956, loss_yt: 0.2642817497253418\n",
      "epocht 10, batch_num 400, step 372401, time: 15.598289728164673 s, accu: 0.8627908229827881, loss_yt: 0.23030591011047363\n",
      "epocht 10, batch_num 600, step 372601, time: 23.231911659240723 s, accu: 0.8627899289131165, loss_yt: 0.30919307470321655\n",
      "epocht 10, batch_num 800, step 372801, time: 30.953232288360596 s, accu: 0.8627882599830627, loss_yt: 0.2940032482147217\n",
      "epocht 10, batch_num 1000, step 373001, time: 38.5050368309021 s, accu: 0.8627889752388, loss_yt: 0.15344691276550293\n",
      "epocht 10, batch_num 1200, step 373201, time: 46.17455720901489 s, accu: 0.8627903461456299, loss_yt: 0.2871866524219513\n",
      "epocht 10, batch_num 1400, step 373401, time: 53.74528646469116 s, accu: 0.8627918362617493, loss_yt: 0.4962533116340637\n",
      "epocht 10, batch_num 1600, step 373601, time: 61.1804039478302 s, accu: 0.8627961874008179, loss_yt: 0.29167094826698303\n",
      "epocht 10, batch_num 1800, step 373801, time: 68.64743542671204 s, accu: 0.8627969026565552, loss_yt: 0.2907995283603668\n",
      "epocht 10, batch_num 2000, step 374001, time: 76.14642882347107 s, accu: 0.8627980947494507, loss_yt: 0.4154072701931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 10, batch_num 2200, step 374201, time: 84.01833438873291 s, accu: 0.8627976775169373, loss_yt: 0.2399071455001831\n",
      "epocht 10, batch_num 2400, step 374401, time: 91.49836111068726 s, accu: 0.8627988696098328, loss_yt: 0.20120730996131897\n",
      "epocht 10, batch_num 2600, step 374601, time: 98.87061858177185 s, accu: 0.8628005981445312, loss_yt: 0.24812741577625275\n",
      "epocht 10, batch_num 2800, step 374801, time: 106.40048360824585 s, accu: 0.8628028631210327, loss_yt: 0.3091098964214325\n",
      "epocht 10, batch_num 3000, step 375001, time: 113.88250851631165 s, accu: 0.8628014922142029, loss_yt: 0.2979185879230499\n",
      "epocht 10, batch_num 3200, step 375201, time: 121.41632962226868 s, accu: 0.8628005981445312, loss_yt: 0.24626775085926056\n",
      "epocht 10, batch_num 3400, step 375401, time: 129.0618872642517 s, accu: 0.8628000020980835, loss_yt: 0.2950974106788635\n",
      "epocht 10, batch_num 3600, step 375601, time: 136.8580379486084 s, accu: 0.8628026843070984, loss_yt: 0.3611953556537628\n",
      "epocht 10, batch_num 3800, step 375801, time: 144.48265194892883 s, accu: 0.8628049492835999, loss_yt: 0.566335916519165\n",
      "epocht 10, batch_num 4000, step 376001, time: 151.89084005355835 s, accu: 0.8628063201904297, loss_yt: 0.3037014901638031\n",
      "epocht 10, batch_num 4200, step 376201, time: 159.65807104110718 s, accu: 0.8628053069114685, loss_yt: 0.16433671116828918\n",
      "epocht 10, batch_num 4400, step 376401, time: 167.06227326393127 s, accu: 0.8628071546554565, loss_yt: 0.32092100381851196\n",
      "epocht 10, batch_num 4600, step 376601, time: 174.58914422988892 s, accu: 0.8628098964691162, loss_yt: 0.34025365114212036\n",
      "epocht 10, batch_num 4800, step 376801, time: 182.19979453086853 s, accu: 0.8628102540969849, loss_yt: 0.3187263607978821\n",
      "epocht 10, batch_num 5000, step 377001, time: 189.88427448272705 s, accu: 0.8628084063529968, loss_yt: 0.2721830904483795\n",
      "epocht 10, batch_num 5200, step 377201, time: 197.4980525970459 s, accu: 0.8628102540969849, loss_yt: 0.3333006501197815\n",
      "epocht 10, batch_num 5400, step 377401, time: 204.93217587471008 s, accu: 0.8628131151199341, loss_yt: 0.3634284436702728\n",
      "epocht 10, batch_num 5600, step 377601, time: 212.78819942474365 s, accu: 0.8628109097480774, loss_yt: 0.3554971218109131\n",
      "epocht 10, batch_num 5800, step 377801, time: 220.59931755065918 s, accu: 0.8628115653991699, loss_yt: 0.24949440360069275\n",
      "epocht 10, batch_num 6000, step 378001, time: 228.30370903015137 s, accu: 0.8628129959106445, loss_yt: 0.27714550495147705\n",
      "epocht 10, batch_num 6200, step 378201, time: 235.90235805511475 s, accu: 0.8628133535385132, loss_yt: 0.24932238459587097\n",
      "epocht 10, batch_num 6400, step 378401, time: 243.51001691818237 s, accu: 0.8628160953521729, loss_yt: 0.4955388605594635\n",
      "epocht 10, batch_num 6600, step 378601, time: 251.0239224433899 s, accu: 0.8628166317939758, loss_yt: 0.28056833148002625\n",
      "epocht 10, batch_num 6800, step 378801, time: 258.3972272872925 s, accu: 0.8628172874450684, loss_yt: 0.36920449137687683\n",
      "epocht 10, batch_num 7000, step 379001, time: 265.99389481544495 s, accu: 0.8628167510032654, loss_yt: 0.3287387788295746\n",
      "epocht 10, batch_num 7200, step 379201, time: 273.7421827316284 s, accu: 0.8628159165382385, loss_yt: 0.30136916041374207\n",
      "epocht 10, batch_num 7400, step 379401, time: 281.4056830406189 s, accu: 0.8628180623054504, loss_yt: 0.24378255009651184\n",
      "iter_validnum 1860\n",
      "epochv 10, step 379440, stop_n 0, time: 335.58879470825195 s, accu_va: 0.8628202623577528, loss_yv: 0.30114073203976754\n",
      "iter_trainnum 7440\n",
      "epocht 10, batch_num 0, step 379441, time: 0.5176491737365723 s, accu: 0.8628209829330444, loss_yt: 0.28574851155281067\n",
      "epocht 10, batch_num 200, step 379641, time: 8.360676527023315 s, accu: 0.8628188371658325, loss_yt: 0.21156547963619232\n",
      "epocht 10, batch_num 400, step 379841, time: 16.051079988479614 s, accu: 0.862820029258728, loss_yt: 0.2494218796491623\n",
      "epocht 10, batch_num 600, step 380041, time: 23.92103624343872 s, accu: 0.8628181219100952, loss_yt: 0.1397055834531784\n",
      "epocht 10, batch_num 800, step 380241, time: 31.333214044570923 s, accu: 0.8628219366073608, loss_yt: 0.24914517998695374\n",
      "epocht 10, batch_num 1000, step 380441, time: 39.10247802734375 s, accu: 0.8628215193748474, loss_yt: 0.22629524767398834\n",
      "epocht 10, batch_num 1200, step 380641, time: 46.818838357925415 s, accu: 0.8628197908401489, loss_yt: 0.3070872724056244\n",
      "epocht 10, batch_num 1400, step 380841, time: 54.40851044654846 s, accu: 0.8628215789794922, loss_yt: 0.29199713468551636\n",
      "epocht 10, batch_num 1600, step 381041, time: 61.90347409248352 s, accu: 0.8628230690956116, loss_yt: 0.3197949528694153\n",
      "epocht 10, batch_num 1800, step 381241, time: 69.68167400360107 s, accu: 0.8628258109092712, loss_yt: 0.5102332234382629\n",
      "epocht 10, batch_num 2000, step 381441, time: 77.15468883514404 s, accu: 0.8628251552581787, loss_yt: 0.277974396944046\n",
      "epocht 10, batch_num 2200, step 381641, time: 84.86210989952087 s, accu: 0.8628264665603638, loss_yt: 0.28646042943000793\n",
      "epocht 10, batch_num 2400, step 381841, time: 92.59842276573181 s, accu: 0.8628271222114563, loss_yt: 0.14924994111061096\n",
      "epocht 10, batch_num 2600, step 382041, time: 100.20309257507324 s, accu: 0.8628284931182861, loss_yt: 0.2499541938304901\n",
      "epocht 10, batch_num 2800, step 382241, time: 107.80874943733215 s, accu: 0.8628262877464294, loss_yt: 0.2901102304458618\n",
      "epocht 10, batch_num 3000, step 382441, time: 115.46524381637573 s, accu: 0.8628277778625488, loss_yt: 0.1903688907623291\n",
      "epocht 10, batch_num 3200, step 382641, time: 123.03502750396729 s, accu: 0.86282879114151, loss_yt: 0.3539121747016907\n",
      "epocht 10, batch_num 3400, step 382841, time: 130.55492663383484 s, accu: 0.8628314137458801, loss_yt: 0.27011436223983765\n",
      "epocht 10, batch_num 3600, step 383041, time: 138.08080768585205 s, accu: 0.8628333210945129, loss_yt: 0.39029809832572937\n",
      "epocht 10, batch_num 3800, step 383241, time: 145.71635103225708 s, accu: 0.8628350496292114, loss_yt: 0.42711251974105835\n",
      "epocht 10, batch_num 4000, step 383441, time: 153.49857091903687 s, accu: 0.8628348708152771, loss_yt: 0.20762506127357483\n",
      "epocht 10, batch_num 4200, step 383641, time: 161.15407061576843 s, accu: 0.8628357648849487, loss_yt: 0.2245430052280426\n",
      "epocht 10, batch_num 4400, step 383841, time: 168.67798519134521 s, accu: 0.8628339171409607, loss_yt: 0.32146334648132324\n",
      "epocht 10, batch_num 4600, step 384041, time: 176.34647369384766 s, accu: 0.8628340363502502, loss_yt: 0.10203355550765991\n",
      "epocht 10, batch_num 4800, step 384241, time: 183.94014072418213 s, accu: 0.8628368973731995, loss_yt: 0.31841474771499634\n",
      "epocht 10, batch_num 5000, step 384441, time: 191.31243443489075 s, accu: 0.8628378510475159, loss_yt: 0.31687527894973755\n",
      "epocht 10, batch_num 5200, step 384641, time: 198.94202542304993 s, accu: 0.8628382682800293, loss_yt: 0.2676757574081421\n",
      "epocht 10, batch_num 5400, step 384841, time: 206.40307545661926 s, accu: 0.8628405928611755, loss_yt: 0.19594846665859222\n",
      "epocht 10, batch_num 5600, step 385041, time: 213.93197226524353 s, accu: 0.8628379106521606, loss_yt: 0.3766726553440094\n",
      "epocht 10, batch_num 5800, step 385241, time: 221.45185804367065 s, accu: 0.8628369569778442, loss_yt: 0.23099730908870697\n",
      "epocht 10, batch_num 6000, step 385441, time: 228.9518039226532 s, accu: 0.8628393411636353, loss_yt: 0.3708766996860504\n",
      "epocht 10, batch_num 6200, step 385641, time: 236.52253341674805 s, accu: 0.8628417253494263, loss_yt: 0.17022289335727692\n",
      "epocht 10, batch_num 6400, step 385841, time: 244.02048563957214 s, accu: 0.8628438711166382, loss_yt: 0.24645859003067017\n",
      "epocht 10, batch_num 6600, step 386041, time: 251.56832838058472 s, accu: 0.8628458976745605, loss_yt: 0.5420147776603699\n",
      "epocht 10, batch_num 6800, step 386241, time: 259.18396520614624 s, accu: 0.862847089767456, loss_yt: 0.3836229741573334\n",
      "epocht 10, batch_num 7000, step 386441, time: 266.85642170906067 s, accu: 0.8628493547439575, loss_yt: 0.34129539132118225\n",
      "epocht 10, batch_num 7200, step 386641, time: 274.33944272994995 s, accu: 0.8628506064414978, loss_yt: 0.1569170504808426\n",
      "epocht 10, batch_num 7400, step 386841, time: 281.94208216667175 s, accu: 0.8628520965576172, loss_yt: 0.23027557134628296\n",
      "iter_validnum 1860\n",
      "epochv 10, step 386880, stop_n 0, time: 335.43307757377625 s, accu_va: 0.8628538122741125, loss_yv: 0.30287739202700636\n",
      "iter_trainnum 7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 10, batch_num 0, step 386881, time: 0.3251302242279053 s, accu: 0.8628520369529724, loss_yt: 0.2507856488227844\n",
      "epocht 10, batch_num 200, step 387081, time: 7.860947847366333 s, accu: 0.862854540348053, loss_yt: 0.5318208932876587\n",
      "epocht 10, batch_num 400, step 387281, time: 15.576317071914673 s, accu: 0.8628545999526978, loss_yt: 0.19593608379364014\n",
      "epocht 10, batch_num 600, step 387481, time: 22.98051691055298 s, accu: 0.8628557920455933, loss_yt: 0.316471129655838\n",
      "epocht 10, batch_num 800, step 387681, time: 30.678930521011353 s, accu: 0.8628561496734619, loss_yt: 0.31523576378822327\n",
      "epocht 10, batch_num 1000, step 387881, time: 38.21078968048096 s, accu: 0.8628595471382141, loss_yt: 0.2649596333503723\n",
      "epocht 10, batch_num 1200, step 388081, time: 45.63396596908569 s, accu: 0.8628596067428589, loss_yt: 0.22962790727615356\n",
      "epocht 10, batch_num 1400, step 388281, time: 53.34933519363403 s, accu: 0.8628590703010559, loss_yt: 0.27406299114227295\n",
      "epocht 10, batch_num 1600, step 388481, time: 61.03878116607666 s, accu: 0.8628585338592529, loss_yt: 0.2506231665611267\n",
      "epocht 10, batch_num 1800, step 388681, time: 68.73120594024658 s, accu: 0.8628582954406738, loss_yt: 0.35896584391593933\n",
      "epocht 10, batch_num 2000, step 388881, time: 76.17427492141724 s, accu: 0.8628593683242798, loss_yt: 0.23410815000534058\n",
      "epocht 10, batch_num 2200, step 389081, time: 83.77993893623352 s, accu: 0.8628566861152649, loss_yt: 0.39535433053970337\n",
      "epocht 10, batch_num 2400, step 389281, time: 91.33573961257935 s, accu: 0.8628590106964111, loss_yt: 0.32292455434799194\n",
      "epocht 10, batch_num 2600, step 389481, time: 98.78082609176636 s, accu: 0.8628573417663574, loss_yt: 0.26703983545303345\n",
      "epocht 10, batch_num 2800, step 389681, time: 106.65277552604675 s, accu: 0.8628594875335693, loss_yt: 0.25986024737358093\n",
      "epocht 10, batch_num 3000, step 389881, time: 114.02209973335266 s, accu: 0.8628600239753723, loss_yt: 0.3895699977874756\n",
      "epocht 10, batch_num 3200, step 390081, time: 121.69458079338074 s, accu: 0.8628640174865723, loss_yt: 0.36999034881591797\n",
      "epocht 10, batch_num 3400, step 390281, time: 129.1396770477295 s, accu: 0.8628635406494141, loss_yt: 0.4103306233882904\n",
      "epocht 10, batch_num 3600, step 390481, time: 136.60567998886108 s, accu: 0.8628604412078857, loss_yt: 0.26708266139030457\n",
      "epocht 10, batch_num 3800, step 390681, time: 144.10566401481628 s, accu: 0.86285799741745, loss_yt: 0.21215657889842987\n",
      "epocht 10, batch_num 4000, step 390881, time: 151.50786447525024 s, accu: 0.8628588318824768, loss_yt: 0.4537453353404999\n",
      "epocht 10, batch_num 4200, step 391081, time: 159.51246619224548 s, accu: 0.8628597855567932, loss_yt: 0.25637444853782654\n",
      "epocht 10, batch_num 4400, step 391281, time: 166.97049069404602 s, accu: 0.8628634810447693, loss_yt: 0.38469362258911133\n",
      "epocht 10, batch_num 4600, step 391481, time: 174.6240518093109 s, accu: 0.8628659844398499, loss_yt: 0.341533899307251\n",
      "epocht 10, batch_num 4800, step 391681, time: 182.23566555976868 s, accu: 0.8628643751144409, loss_yt: 0.30813148617744446\n",
      "epocht 10, batch_num 5000, step 391881, time: 189.7525656223297 s, accu: 0.8628658056259155, loss_yt: 0.1405608355998993\n",
      "epocht 10, batch_num 5200, step 392081, time: 197.33731055259705 s, accu: 0.8628674745559692, loss_yt: 0.3645322918891907\n",
      "epocht 10, batch_num 5400, step 392281, time: 205.02475380897522 s, accu: 0.8628664612770081, loss_yt: 0.13555285334587097\n",
      "epocht 10, batch_num 5600, step 392481, time: 212.97549867630005 s, accu: 0.8628676533699036, loss_yt: 0.30588480830192566\n",
      "epocht 10, batch_num 5800, step 392681, time: 220.54722714424133 s, accu: 0.8628693222999573, loss_yt: 0.3286840617656708\n",
      "epocht 10, batch_num 6000, step 392881, time: 228.32143187522888 s, accu: 0.8628683686256409, loss_yt: 0.2132989764213562\n",
      "epocht 10, batch_num 6200, step 393081, time: 235.81143522262573 s, accu: 0.8628683090209961, loss_yt: 0.2473434954881668\n",
      "epocht 10, batch_num 6400, step 393281, time: 243.12687373161316 s, accu: 0.8628711700439453, loss_yt: 0.49436432123184204\n",
      "epocht 10, batch_num 6600, step 393481, time: 250.6188280582428 s, accu: 0.8628714084625244, loss_yt: 0.30862632393836975\n",
      "epocht 10, batch_num 6800, step 393681, time: 258.14468359947205 s, accu: 0.862870991230011, loss_yt: 0.25659045577049255\n",
      "epocht 10, batch_num 7000, step 393881, time: 265.7703242301941 s, accu: 0.8628716468811035, loss_yt: 0.2555992901325226\n",
      "epocht 10, batch_num 7200, step 394081, time: 273.6542549133301 s, accu: 0.8628699779510498, loss_yt: 0.2730126678943634\n",
      "epocht 10, batch_num 7400, step 394281, time: 281.5660581588745 s, accu: 0.8628717660903931, loss_yt: 0.19991862773895264\n",
      "iter_validnum 1860\n",
      "epochv 10, step 394320, stop_n 0, time: 335.2834131717682 s, accu_va: 0.8628767925244506, loss_yv: 0.29796849129901776\n",
      "iter_trainnum 7440\n",
      "epocht 10, batch_num 0, step 394321, time: 0.23439884185791016 s, accu: 0.8628814816474915, loss_yt: 0.36667415499687195\n",
      "epocht 10, batch_num 200, step 394521, time: 7.799194097518921 s, accu: 0.8628823161125183, loss_yt: 0.26912999153137207\n",
      "epocht 10, batch_num 400, step 394721, time: 15.252217292785645 s, accu: 0.862883448600769, loss_yt: 0.21376273036003113\n",
      "epocht 10, batch_num 600, step 394921, time: 22.973601818084717 s, accu: 0.8628855347633362, loss_yt: 0.27997347712516785\n",
      "epocht 10, batch_num 800, step 395121, time: 30.441606998443604 s, accu: 0.8628862500190735, loss_yt: 0.2903226315975189\n",
      "epocht 10, batch_num 1000, step 395321, time: 38.03529477119446 s, accu: 0.862887442111969, loss_yt: 0.30105847120285034\n",
      "epocht 10, batch_num 1200, step 395521, time: 45.61306309700012 s, accu: 0.862885057926178, loss_yt: 0.34773361682891846\n",
      "epocht 10, batch_num 1400, step 395721, time: 53.06412148475647 s, accu: 0.8628858923912048, loss_yt: 0.24154193699359894\n",
      "epocht 10, batch_num 1600, step 395921, time: 61.1305365562439 s, accu: 0.8628864884376526, loss_yt: 0.16534407436847687\n",
      "epocht 10, batch_num 1800, step 396121, time: 68.60056185722351 s, accu: 0.8628883957862854, loss_yt: 0.18875296413898468\n",
      "epocht 10, batch_num 2000, step 396321, time: 76.15137195587158 s, accu: 0.8628900051116943, loss_yt: 0.18823502957820892\n",
      "epocht 10, batch_num 2200, step 396521, time: 83.84679365158081 s, accu: 0.8628900051116943, loss_yt: 0.3034193515777588\n",
      "epocht 10, batch_num 2400, step 396721, time: 91.32778930664062 s, accu: 0.8628904223442078, loss_yt: 0.2246500551700592\n",
      "epocht 10, batch_num 2600, step 396921, time: 98.75592827796936 s, accu: 0.8628909587860107, loss_yt: 0.34051352739334106\n",
      "epocht 10, batch_num 2800, step 397121, time: 106.22694802284241 s, accu: 0.8628928661346436, loss_yt: 0.3102242052555084\n",
      "epocht 10, batch_num 3000, step 397321, time: 114.00814056396484 s, accu: 0.8628908395767212, loss_yt: 0.20108160376548767\n",
      "epocht 10, batch_num 3200, step 397521, time: 121.50011801719666 s, accu: 0.8628925085067749, loss_yt: 0.2722913324832916\n",
      "epocht 10, batch_num 3400, step 397721, time: 129.03795266151428 s, accu: 0.8628936409950256, loss_yt: 0.2492542266845703\n",
      "epocht 10, batch_num 3600, step 397921, time: 136.7064700126648 s, accu: 0.8628911972045898, loss_yt: 0.2421649545431137\n",
      "epocht 10, batch_num 3800, step 398121, time: 144.36301016807556 s, accu: 0.86288982629776, loss_yt: 0.4759926497936249\n",
      "epocht 10, batch_num 4000, step 398321, time: 151.96368026733398 s, accu: 0.8628886342048645, loss_yt: 0.38054385781288147\n",
      "epocht 10, batch_num 4200, step 398521, time: 159.5742962360382 s, accu: 0.8628885746002197, loss_yt: 0.34743714332580566\n",
      "epocht 10, batch_num 4400, step 398721, time: 167.19392013549805 s, accu: 0.8628878593444824, loss_yt: 0.4391821324825287\n",
      "epocht 10, batch_num 4600, step 398921, time: 174.83751440048218 s, accu: 0.8628857731819153, loss_yt: 0.4261522889137268\n",
      "epocht 10, batch_num 4800, step 399121, time: 182.82013511657715 s, accu: 0.8628859519958496, loss_yt: 0.2474241852760315\n",
      "epocht 10, batch_num 5000, step 399321, time: 190.60434865951538 s, accu: 0.8628861904144287, loss_yt: 0.33360546827316284\n",
      "epocht 10, batch_num 5200, step 399521, time: 198.17211198806763 s, accu: 0.862888514995575, loss_yt: 0.23085029423236847\n",
      "epocht 10, batch_num 5400, step 399721, time: 205.54436993598938 s, accu: 0.862891674041748, loss_yt: 0.17718066275119781\n",
      "epocht 10, batch_num 5600, step 399921, time: 213.0383324623108 s, accu: 0.8628947734832764, loss_yt: 0.2807440459728241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 10, batch_num 5800, step 400121, time: 220.45350408554077 s, accu: 0.8628947734832764, loss_yt: 0.2500578463077545\n",
      "epocht 10, batch_num 6000, step 400321, time: 228.1898491382599 s, accu: 0.8628940582275391, loss_yt: 0.35273444652557373\n",
      "epocht 10, batch_num 6200, step 400521, time: 235.73666286468506 s, accu: 0.8628954291343689, loss_yt: 0.3028053641319275\n",
      "epocht 10, batch_num 6400, step 400721, time: 243.52082228660583 s, accu: 0.8628930449485779, loss_yt: 0.19922375679016113\n",
      "epocht 10, batch_num 6600, step 400921, time: 251.22322511672974 s, accu: 0.862892210483551, loss_yt: 0.23824036121368408\n",
      "epocht 10, batch_num 6800, step 401121, time: 258.6523914337158 s, accu: 0.8628939390182495, loss_yt: 0.39934787154197693\n",
      "epocht 10, batch_num 7000, step 401321, time: 266.27697014808655 s, accu: 0.8628951907157898, loss_yt: 0.11456143110990524\n",
      "epocht 10, batch_num 7200, step 401521, time: 273.8646855354309 s, accu: 0.8628965616226196, loss_yt: 0.26294827461242676\n",
      "epocht 10, batch_num 7400, step 401721, time: 281.32378339767456 s, accu: 0.8629006147384644, loss_yt: 0.2443103790283203\n",
      "iter_validnum 1860\n",
      "epochv 10, step 401760, stop_n 0, time: 335.2216100692749 s, accu_va: 0.8629054066314492, loss_yv: 0.2985485083073057\n",
      "iter_trainnum 7440\n",
      "epocht 10, batch_num 0, step 401761, time: 0.3420877456665039 s, accu: 0.8629117608070374, loss_yt: 0.21368244290351868\n",
      "epocht 10, batch_num 200, step 401961, time: 7.93878698348999 s, accu: 0.8629118800163269, loss_yt: 0.3633613586425781\n",
      "epocht 10, batch_num 400, step 402161, time: 15.756898880004883 s, accu: 0.8629111647605896, loss_yt: 0.2776896059513092\n",
      "epocht 10, batch_num 600, step 402361, time: 23.174065113067627 s, accu: 0.8629115223884583, loss_yt: 0.2551381587982178\n",
      "epocht 10, batch_num 800, step 402561, time: 31.241517305374146 s, accu: 0.8629112839698792, loss_yt: 0.3846532702445984\n",
      "epocht 10, batch_num 1000, step 402761, time: 38.83319926261902 s, accu: 0.862912654876709, loss_yt: 0.29968562722206116\n",
      "epocht 10, batch_num 1200, step 402961, time: 46.22441005706787 s, accu: 0.8629127144813538, loss_yt: 0.2969154715538025\n",
      "epocht 10, batch_num 1400, step 403161, time: 53.95174837112427 s, accu: 0.8629118204116821, loss_yt: 0.4234195053577423\n",
      "epocht 10, batch_num 1600, step 403361, time: 61.656177043914795 s, accu: 0.862909197807312, loss_yt: 0.4057963192462921\n",
      "epocht 10, batch_num 1800, step 403561, time: 69.35159945487976 s, accu: 0.862909734249115, loss_yt: 0.26224440336227417\n",
      "epocht 10, batch_num 2000, step 403761, time: 76.72884964942932 s, accu: 0.8629105091094971, loss_yt: 0.26193544268608093\n",
      "epocht 10, batch_num 2200, step 403961, time: 84.16100978851318 s, accu: 0.8629137873649597, loss_yt: 0.20777557790279388\n",
      "epocht 10, batch_num 2400, step 404161, time: 91.82452416419983 s, accu: 0.8629146814346313, loss_yt: 0.5176001191139221\n",
      "epocht 10, batch_num 2600, step 404361, time: 99.34935235977173 s, accu: 0.8629158735275269, loss_yt: 0.4679778516292572\n",
      "epocht 10, batch_num 2800, step 404561, time: 106.99989533424377 s, accu: 0.8629155158996582, loss_yt: 0.12074963748455048\n",
      "epocht 10, batch_num 3000, step 404761, time: 114.7052891254425 s, accu: 0.8629148006439209, loss_yt: 0.32973194122314453\n",
      "epocht 10, batch_num 3200, step 404961, time: 122.44658875465393 s, accu: 0.8629190325737, loss_yt: 0.377967894077301\n",
      "epocht 10, batch_num 3400, step 405161, time: 129.93157958984375 s, accu: 0.8629202246665955, loss_yt: 0.32257017493247986\n",
      "epocht 10, batch_num 3600, step 405361, time: 137.45445942878723 s, accu: 0.8629240989685059, loss_yt: 0.39462608098983765\n",
      "epocht 10, batch_num 3800, step 405561, time: 144.7410225868225 s, accu: 0.8629266023635864, loss_yt: 0.12964121997356415\n",
      "epocht 10, batch_num 4000, step 405761, time: 152.321702003479 s, accu: 0.8629248142242432, loss_yt: 0.29562556743621826\n",
      "epocht 10, batch_num 4200, step 405961, time: 160.0700089931488 s, accu: 0.8629263043403625, loss_yt: 0.3602389693260193\n",
      "epocht 10, batch_num 4400, step 406161, time: 167.60483574867249 s, accu: 0.862928569316864, loss_yt: 0.2536391615867615\n",
      "epocht 10, batch_num 4600, step 406361, time: 175.5974633693695 s, accu: 0.8629292845726013, loss_yt: 0.36484840512275696\n",
      "epocht 10, batch_num 4800, step 406561, time: 183.23404455184937 s, accu: 0.862931489944458, loss_yt: 0.2455682009458542\n",
      "epocht 10, batch_num 5000, step 406761, time: 190.76490473747253 s, accu: 0.862930417060852, loss_yt: 0.3678542673587799\n",
      "epocht 10, batch_num 5200, step 406961, time: 198.2897834777832 s, accu: 0.8629314303398132, loss_yt: 0.1418873518705368\n",
      "epocht 10, batch_num 5400, step 407161, time: 205.82862424850464 s, accu: 0.8629348874092102, loss_yt: 0.18935401737689972\n",
      "epocht 10, batch_num 5600, step 407361, time: 213.46520709991455 s, accu: 0.8629363775253296, loss_yt: 0.36844515800476074\n",
      "epocht 10, batch_num 5800, step 407561, time: 221.07490062713623 s, accu: 0.8629361987113953, loss_yt: 0.28823286294937134\n",
      "epocht 10, batch_num 6000, step 407761, time: 228.8191466331482 s, accu: 0.8629363179206848, loss_yt: 0.35887131094932556\n",
      "epocht 10, batch_num 6200, step 407961, time: 236.68112516403198 s, accu: 0.862936794757843, loss_yt: 0.3117884397506714\n",
      "epocht 10, batch_num 6400, step 408161, time: 244.3835597038269 s, accu: 0.862934947013855, loss_yt: 0.32423919439315796\n",
      "epocht 10, batch_num 6600, step 408361, time: 251.92835211753845 s, accu: 0.8629360795021057, loss_yt: 0.3217059075832367\n",
      "epocht 10, batch_num 6800, step 408561, time: 259.6487376689911 s, accu: 0.8629366159439087, loss_yt: 0.2738555371761322\n",
      "epocht 10, batch_num 7000, step 408761, time: 267.409987449646 s, accu: 0.8629329800605774, loss_yt: 0.26267343759536743\n",
      "epocht 10, batch_num 7200, step 408961, time: 275.2719302177429 s, accu: 0.8629339337348938, loss_yt: 0.3425152003765106\n",
      "epocht 10, batch_num 7400, step 409161, time: 282.76589179039 s, accu: 0.8629344701766968, loss_yt: 0.4119812846183777\n",
      "iter_validnum 1860\n",
      "epochv 10, step 409200, stop_n 0, time: 336.5151948928833 s, accu_va: 0.8629374026611287, loss_yv: 0.29863448593244757\n",
      "iter_trainnum 7440\n",
      "epocht 11, batch_num 0, step 409201, time: 0.761962890625 s, accu: 0.8629412651062012, loss_yt: 0.2718312740325928\n",
      "epocht 11, batch_num 200, step 409401, time: 8.34568452835083 s, accu: 0.8629423975944519, loss_yt: 0.4020642936229706\n",
      "epocht 11, batch_num 400, step 409601, time: 15.756866455078125 s, accu: 0.8629459142684937, loss_yt: 0.46314477920532227\n",
      "epocht 11, batch_num 600, step 409801, time: 23.441316843032837 s, accu: 0.8629469871520996, loss_yt: 0.3288151025772095\n",
      "epocht 11, batch_num 800, step 410001, time: 31.058961153030396 s, accu: 0.8629487156867981, loss_yt: 0.4419999122619629\n",
      "epocht 11, batch_num 1000, step 410201, time: 38.60676574707031 s, accu: 0.8629472851753235, loss_yt: 0.15860754251480103\n",
      "epocht 11, batch_num 1200, step 410401, time: 46.06183171272278 s, accu: 0.8629497289657593, loss_yt: 0.22919151186943054\n",
      "epocht 11, batch_num 1400, step 410601, time: 53.76822257041931 s, accu: 0.8629505634307861, loss_yt: 0.07953579723834991\n",
      "epocht 11, batch_num 1600, step 410801, time: 61.37288737297058 s, accu: 0.8629514575004578, loss_yt: 0.09611624479293823\n",
      "epocht 11, batch_num 1800, step 411001, time: 68.92073822021484 s, accu: 0.8629509806632996, loss_yt: 0.24937835335731506\n",
      "epocht 11, batch_num 2000, step 411201, time: 76.52536940574646 s, accu: 0.8629516959190369, loss_yt: 0.15390139818191528\n",
      "epocht 11, batch_num 2200, step 411401, time: 84.0951280593872 s, accu: 0.8629536628723145, loss_yt: 0.3066490590572357\n",
      "epocht 11, batch_num 2400, step 411601, time: 91.55817127227783 s, accu: 0.8629592657089233, loss_yt: 0.25182127952575684\n",
      "epocht 11, batch_num 2600, step 411801, time: 99.19275784492493 s, accu: 0.8629603981971741, loss_yt: 0.14827102422714233\n",
      "epocht 11, batch_num 2800, step 412001, time: 106.86227822303772 s, accu: 0.8629599213600159, loss_yt: 0.2535513937473297\n",
      "epocht 11, batch_num 3000, step 412201, time: 114.65939903259277 s, accu: 0.8629601001739502, loss_yt: 0.3102184236049652\n",
      "epocht 11, batch_num 3200, step 412401, time: 122.09651207923889 s, accu: 0.8629619479179382, loss_yt: 0.1512279361486435\n",
      "epocht 11, batch_num 3400, step 412601, time: 129.75503182411194 s, accu: 0.8629642724990845, loss_yt: 0.21494567394256592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 11, batch_num 3600, step 412801, time: 137.46940445899963 s, accu: 0.8629637360572815, loss_yt: 0.2470703274011612\n",
      "epocht 11, batch_num 3800, step 413001, time: 144.77491283416748 s, accu: 0.8629644513130188, loss_yt: 0.38793715834617615\n",
      "epocht 11, batch_num 4000, step 413201, time: 152.53511762619019 s, accu: 0.8629641532897949, loss_yt: 0.2717016041278839\n",
      "epocht 11, batch_num 4200, step 413401, time: 160.1717312335968 s, accu: 0.8629648089408875, loss_yt: 0.2888599932193756\n",
      "epocht 11, batch_num 4400, step 413601, time: 167.67867469787598 s, accu: 0.8629655241966248, loss_yt: 0.35816890001296997\n",
      "epocht 11, batch_num 4600, step 413801, time: 175.23744893074036 s, accu: 0.8629654049873352, loss_yt: 0.2202734798192978\n",
      "epocht 11, batch_num 4800, step 414001, time: 182.9358265399933 s, accu: 0.8629655838012695, loss_yt: 0.3589056134223938\n",
      "epocht 11, batch_num 5000, step 414201, time: 190.42479991912842 s, accu: 0.8629698157310486, loss_yt: 0.35917899012565613\n",
      "epocht 11, batch_num 5200, step 414401, time: 197.8948254585266 s, accu: 0.862968385219574, loss_yt: 0.44258180260658264\n",
      "epocht 11, batch_num 5400, step 414601, time: 205.46059894561768 s, accu: 0.8629686832427979, loss_yt: 0.33292943239212036\n",
      "epocht 11, batch_num 5600, step 414801, time: 213.14606952667236 s, accu: 0.8629679679870605, loss_yt: 0.1740517020225525\n",
      "epocht 11, batch_num 5800, step 415001, time: 220.86340737342834 s, accu: 0.862966775894165, loss_yt: 0.11815179884433746\n",
      "epocht 11, batch_num 6000, step 415201, time: 228.31252145767212 s, accu: 0.8629693984985352, loss_yt: 0.2814970016479492\n",
      "epocht 11, batch_num 6200, step 415401, time: 235.92416191101074 s, accu: 0.862969160079956, loss_yt: 0.33141979575157166\n",
      "epocht 11, batch_num 6400, step 415601, time: 243.65849947929382 s, accu: 0.8629680871963501, loss_yt: 0.3352418839931488\n",
      "epocht 11, batch_num 6600, step 415801, time: 251.12448930740356 s, accu: 0.8629686236381531, loss_yt: 0.23710286617279053\n",
      "epocht 11, batch_num 6800, step 416001, time: 258.8428497314453 s, accu: 0.8629683256149292, loss_yt: 0.13468405604362488\n",
      "epocht 11, batch_num 7000, step 416201, time: 266.28096079826355 s, accu: 0.8629705905914307, loss_yt: 0.28307756781578064\n",
      "epocht 11, batch_num 7200, step 416401, time: 274.1439332962036 s, accu: 0.8629709482192993, loss_yt: 0.27116626501083374\n",
      "epocht 11, batch_num 7400, step 416601, time: 281.8473358154297 s, accu: 0.862967848777771, loss_yt: 0.32828202843666077\n",
      "iter_validnum 1860\n",
      "epochv 11, step 416640, stop_n 0, time: 336.1261942386627 s, accu_va: 0.8629691575483609, loss_yv: 0.3011268364085305\n",
      "iter_trainnum 7440\n",
      "epocht 11, batch_num 0, step 416641, time: 0.42386579513549805 s, accu: 0.8629685044288635, loss_yt: 0.3528231680393219\n",
      "epocht 11, batch_num 200, step 416841, time: 7.923810958862305 s, accu: 0.8629704713821411, loss_yt: 0.12812690436840057\n",
      "epocht 11, batch_num 400, step 417041, time: 15.544433355331421 s, accu: 0.8629722595214844, loss_yt: 0.1504664272069931\n",
      "epocht 11, batch_num 600, step 417241, time: 23.143113613128662 s, accu: 0.8629723787307739, loss_yt: 0.45953819155693054\n",
      "epocht 11, batch_num 800, step 417441, time: 31.00411891937256 s, accu: 0.8629759550094604, loss_yt: 0.2153133898973465\n",
      "epocht 11, batch_num 1000, step 417641, time: 38.6087601184845 s, accu: 0.8629785180091858, loss_yt: 0.25607749819755554\n",
      "epocht 11, batch_num 1200, step 417841, time: 46.18749260902405 s, accu: 0.8629776239395142, loss_yt: 0.28464531898498535\n",
      "epocht 11, batch_num 1400, step 418041, time: 53.77520751953125 s, accu: 0.8629785180091858, loss_yt: 0.30545708537101746\n",
      "epocht 11, batch_num 1600, step 418241, time: 61.52950096130371 s, accu: 0.8629789352416992, loss_yt: 0.26261574029922485\n",
      "epocht 11, batch_num 1800, step 418441, time: 69.07831001281738 s, accu: 0.8629777431488037, loss_yt: 0.30119001865386963\n",
      "epocht 11, batch_num 2000, step 418641, time: 76.66402387619019 s, accu: 0.8629798293113708, loss_yt: 0.268273264169693\n",
      "epocht 11, batch_num 2200, step 418841, time: 84.37537717819214 s, accu: 0.8629809617996216, loss_yt: 0.1930023729801178\n",
      "epocht 11, batch_num 2400, step 419041, time: 92.05784177780151 s, accu: 0.8629812598228455, loss_yt: 0.14792263507843018\n",
      "epocht 11, batch_num 2600, step 419241, time: 99.80412220954895 s, accu: 0.8629820942878723, loss_yt: 0.22064097225666046\n",
      "epocht 11, batch_num 2800, step 419441, time: 107.53843879699707 s, accu: 0.8629790544509888, loss_yt: 0.21897749602794647\n",
      "epocht 11, batch_num 3000, step 419641, time: 115.20793008804321 s, accu: 0.8629799485206604, loss_yt: 0.4032105505466461\n",
      "epocht 11, batch_num 3200, step 419841, time: 122.76970982551575 s, accu: 0.8629804253578186, loss_yt: 0.2794725000858307\n",
      "epocht 11, batch_num 3400, step 420041, time: 130.17890167236328 s, accu: 0.8629810810089111, loss_yt: 0.3008546233177185\n",
      "epocht 11, batch_num 3600, step 420241, time: 138.132630109787 s, accu: 0.862981379032135, loss_yt: 0.5463071465492249\n",
      "epocht 11, batch_num 3800, step 420441, time: 145.72537422180176 s, accu: 0.8629823327064514, loss_yt: 0.3376176655292511\n",
      "epocht 11, batch_num 4000, step 420641, time: 153.6421570777893 s, accu: 0.8629806041717529, loss_yt: 0.5178658962249756\n",
      "epocht 11, batch_num 4200, step 420841, time: 161.3964490890503 s, accu: 0.8629800081253052, loss_yt: 0.2006026655435562\n",
      "epocht 11, batch_num 4400, step 421041, time: 169.027019739151 s, accu: 0.8629810810089111, loss_yt: 0.1727929711341858\n",
      "epocht 11, batch_num 4600, step 421241, time: 176.61873650550842 s, accu: 0.8629810810089111, loss_yt: 0.12989087402820587\n",
      "epocht 11, batch_num 4800, step 421441, time: 184.49964308738708 s, accu: 0.8629831671714783, loss_yt: 0.3192737102508545\n",
      "epocht 11, batch_num 5000, step 421641, time: 191.94772601127625 s, accu: 0.8629839420318604, loss_yt: 0.25383609533309937\n",
      "epocht 11, batch_num 5200, step 421841, time: 199.54441714286804 s, accu: 0.8629845380783081, loss_yt: 0.42225325107574463\n",
      "epocht 11, batch_num 5400, step 422041, time: 207.24980926513672 s, accu: 0.8629844188690186, loss_yt: 0.32457661628723145\n",
      "epocht 11, batch_num 5600, step 422241, time: 214.72784113883972 s, accu: 0.8629864454269409, loss_yt: 0.4626656174659729\n",
      "epocht 11, batch_num 5800, step 422441, time: 222.21881437301636 s, accu: 0.8629869818687439, loss_yt: 0.2627484202384949\n",
      "epocht 11, batch_num 6000, step 422641, time: 229.62002301216125 s, accu: 0.8629888892173767, loss_yt: 0.24328291416168213\n",
      "epocht 11, batch_num 6200, step 422841, time: 237.22169661521912 s, accu: 0.8629878163337708, loss_yt: 0.30151647329330444\n",
      "epocht 11, batch_num 6400, step 423041, time: 244.65877771377563 s, accu: 0.8629887104034424, loss_yt: 0.3983389735221863\n",
      "epocht 11, batch_num 6600, step 423241, time: 252.24850964546204 s, accu: 0.8629891276359558, loss_yt: 0.1100711077451706\n",
      "epocht 11, batch_num 6800, step 423441, time: 260.01471424102783 s, accu: 0.8629904985427856, loss_yt: 0.2925631105899811\n",
      "epocht 11, batch_num 7000, step 423641, time: 267.62735891342163 s, accu: 0.862991452217102, loss_yt: 0.27836573123931885\n",
      "epocht 11, batch_num 7200, step 423841, time: 275.2729594707489 s, accu: 0.8629899621009827, loss_yt: 0.22826418280601501\n",
      "epocht 11, batch_num 7400, step 424041, time: 282.76990008354187 s, accu: 0.8629906177520752, loss_yt: 0.14474087953567505\n",
      "iter_validnum 1860\n",
      "epochv 11, step 424080, stop_n 0, time: 336.37253308296204 s, accu_va: 0.862991653847438, loss_yv: 0.3029666837505115\n",
      "iter_trainnum 7440\n",
      "epocht 11, batch_num 0, step 424081, time: 0.4059407711029053 s, accu: 0.8629911541938782, loss_yt: 0.45038506388664246\n",
      "epocht 11, batch_num 200, step 424281, time: 8.018592357635498 s, accu: 0.8629915118217468, loss_yt: 0.27598434686660767\n",
      "epocht 11, batch_num 400, step 424481, time: 15.498583555221558 s, accu: 0.8629932403564453, loss_yt: 0.25118133425712585\n",
      "epocht 11, batch_num 600, step 424681, time: 23.31271529197693 s, accu: 0.8629933595657349, loss_yt: 0.29737281799316406\n",
      "epocht 11, batch_num 800, step 424881, time: 30.826595783233643 s, accu: 0.8629938960075378, loss_yt: 0.24110928177833557\n",
      "epocht 11, batch_num 1000, step 425081, time: 38.218857526779175 s, accu: 0.862993597984314, loss_yt: 0.25121524930000305\n",
      "epocht 11, batch_num 1200, step 425281, time: 45.745725870132446 s, accu: 0.8629939556121826, loss_yt: 0.10819103568792343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 11, batch_num 1400, step 425481, time: 53.39524507522583 s, accu: 0.8629942536354065, loss_yt: 0.29914942383766174\n",
      "epocht 11, batch_num 1600, step 425681, time: 61.02983021736145 s, accu: 0.8629968166351318, loss_yt: 0.19282449781894684\n",
      "epocht 11, batch_num 1800, step 425881, time: 68.56867527961731 s, accu: 0.8629942536354065, loss_yt: 0.4178778827190399\n",
      "epocht 11, batch_num 2000, step 426081, time: 76.06163620948792 s, accu: 0.8629939556121826, loss_yt: 0.26935598254203796\n",
      "epocht 11, batch_num 2200, step 426281, time: 83.61646628379822 s, accu: 0.8629971742630005, loss_yt: 0.25774797797203064\n",
      "epocht 11, batch_num 2400, step 426481, time: 90.99173831939697 s, accu: 0.8629989624023438, loss_yt: 0.1357661783695221\n",
      "epocht 11, batch_num 2600, step 426681, time: 98.35106611251831 s, accu: 0.862998366355896, loss_yt: 0.3558475077152252\n",
      "epocht 11, batch_num 2800, step 426881, time: 106.00361371040344 s, accu: 0.8629966974258423, loss_yt: 0.28235694766044617\n",
      "epocht 11, batch_num 3000, step 427081, time: 113.58432412147522 s, accu: 0.8629969358444214, loss_yt: 0.2746277451515198\n",
      "epocht 11, batch_num 3200, step 427281, time: 121.04135990142822 s, accu: 0.8629992604255676, loss_yt: 0.3243280351161957\n",
      "epocht 11, batch_num 3400, step 427481, time: 128.7497477531433 s, accu: 0.8630003929138184, loss_yt: 0.19223932921886444\n",
      "epocht 11, batch_num 3600, step 427681, time: 136.39633297920227 s, accu: 0.8630002737045288, loss_yt: 0.263910710811615\n",
      "epocht 11, batch_num 3800, step 427881, time: 144.12366247177124 s, accu: 0.8630021810531616, loss_yt: 0.3163747489452362\n",
      "epocht 11, batch_num 4000, step 428081, time: 151.67449259757996 s, accu: 0.863002598285675, loss_yt: 0.4602956771850586\n",
      "epocht 11, batch_num 4200, step 428281, time: 159.1883556842804 s, accu: 0.8630028367042542, loss_yt: 0.2795448899269104\n",
      "epocht 11, batch_num 4400, step 428481, time: 166.8738031387329 s, accu: 0.8630027174949646, loss_yt: 0.24184070527553558\n",
      "epocht 11, batch_num 4600, step 428681, time: 174.35183835029602 s, accu: 0.8630036115646362, loss_yt: 0.2467767894268036\n",
      "epocht 11, batch_num 4800, step 428881, time: 181.94450187683105 s, accu: 0.8630037307739258, loss_yt: 0.30349647998809814\n",
      "epocht 11, batch_num 5000, step 429081, time: 189.46140122413635 s, accu: 0.8630021214485168, loss_yt: 0.22723160684108734\n",
      "epocht 11, batch_num 5200, step 429281, time: 196.9314317703247 s, accu: 0.8630039095878601, loss_yt: 0.4457622468471527\n",
      "epocht 11, batch_num 5400, step 429481, time: 204.6807062625885 s, accu: 0.8630053997039795, loss_yt: 0.3066653311252594\n",
      "epocht 11, batch_num 5600, step 429681, time: 212.1926510334015 s, accu: 0.8630061745643616, loss_yt: 0.25171494483947754\n",
      "epocht 11, batch_num 5800, step 429881, time: 219.9937584400177 s, accu: 0.863006055355072, loss_yt: 0.33499741554260254\n",
      "epocht 11, batch_num 6000, step 430081, time: 227.53959345817566 s, accu: 0.8630057573318481, loss_yt: 0.2674451768398285\n",
      "epocht 11, batch_num 6200, step 430281, time: 235.21907758712769 s, accu: 0.8630076050758362, loss_yt: 0.36022618412971497\n",
      "epocht 11, batch_num 6400, step 430481, time: 242.69904255867004 s, accu: 0.8630076050758362, loss_yt: 0.3054404556751251\n",
      "epocht 11, batch_num 6600, step 430681, time: 250.55703043937683 s, accu: 0.8630079627037048, loss_yt: 0.23439517617225647\n",
      "epocht 11, batch_num 6800, step 430881, time: 258.0589804649353 s, accu: 0.8630081415176392, loss_yt: 0.20170201361179352\n",
      "epocht 11, batch_num 7000, step 431081, time: 265.67460560798645 s, accu: 0.8630093932151794, loss_yt: 0.3787156343460083\n",
      "epocht 11, batch_num 7200, step 431281, time: 273.356098651886 s, accu: 0.8630083203315735, loss_yt: 0.4056999087333679\n",
      "epocht 11, batch_num 7400, step 431481, time: 280.94676899909973 s, accu: 0.8630087375640869, loss_yt: 0.3352479040622711\n",
      "iter_validnum 1860\n",
      "epochv 11, step 431520, stop_n 0, time: 334.8366663455963 s, accu_va: 0.8630125806536726, loss_yv: 0.2975085803898432\n",
      "iter_trainnum 7440\n",
      "epocht 11, batch_num 0, step 431521, time: 0.3620734214782715 s, accu: 0.8630162477493286, loss_yt: 0.26555654406547546\n",
      "epocht 11, batch_num 200, step 431721, time: 8.197118759155273 s, accu: 0.8630155920982361, loss_yt: 0.2812647223472595\n",
      "epocht 11, batch_num 400, step 431921, time: 15.839645624160767 s, accu: 0.8630178570747375, loss_yt: 0.34847158193588257\n",
      "epocht 11, batch_num 600, step 432121, time: 23.66973304748535 s, accu: 0.8630166053771973, loss_yt: 0.24478331208229065\n",
      "epocht 11, batch_num 800, step 432321, time: 31.533682823181152 s, accu: 0.8630193471908569, loss_yt: 0.3681432604789734\n",
      "epocht 11, batch_num 1000, step 432521, time: 39.379698514938354 s, accu: 0.8630202412605286, loss_yt: 0.32163965702056885\n",
      "epocht 11, batch_num 1200, step 432721, time: 46.98240089416504 s, accu: 0.8630212545394897, loss_yt: 0.2714523673057556\n",
      "epocht 11, batch_num 1400, step 432921, time: 54.68876504898071 s, accu: 0.8630223870277405, loss_yt: 0.41577503085136414\n",
      "epocht 11, batch_num 1600, step 433121, time: 62.22062587738037 s, accu: 0.8630221486091614, loss_yt: 0.32474440336227417\n",
      "epocht 11, batch_num 1800, step 433321, time: 69.73752093315125 s, accu: 0.863023042678833, loss_yt: 0.32130131125450134\n",
      "epocht 11, batch_num 2000, step 433521, time: 77.40102791786194 s, accu: 0.8630222082138062, loss_yt: 0.3274528980255127\n",
      "epocht 11, batch_num 2200, step 433721, time: 84.87009048461914 s, accu: 0.8630225658416748, loss_yt: 0.3438003361225128\n",
      "epocht 11, batch_num 2400, step 433921, time: 92.27030038833618 s, accu: 0.8630227446556091, loss_yt: 0.2735384404659271\n",
      "epocht 11, batch_num 2600, step 434121, time: 99.7542872428894 s, accu: 0.8630236387252808, loss_yt: 0.3124867379665375\n",
      "epocht 11, batch_num 2800, step 434321, time: 107.2731499671936 s, accu: 0.8630255460739136, loss_yt: 0.44490790367126465\n",
      "epocht 11, batch_num 3000, step 434521, time: 114.65840077400208 s, accu: 0.8630261421203613, loss_yt: 0.6015981435775757\n",
      "epocht 11, batch_num 3200, step 434721, time: 122.28502035140991 s, accu: 0.8630265593528748, loss_yt: 0.26983195543289185\n",
      "epocht 11, batch_num 3400, step 434921, time: 130.00536346435547 s, accu: 0.8630267977714539, loss_yt: 0.21767744421958923\n",
      "epocht 11, batch_num 3600, step 435121, time: 137.78957533836365 s, accu: 0.8630263805389404, loss_yt: 0.3487406075000763\n",
      "epocht 11, batch_num 3800, step 435321, time: 145.3802511692047 s, accu: 0.8630275130271912, loss_yt: 0.32026422023773193\n",
      "epocht 11, batch_num 4000, step 435521, time: 153.11756086349487 s, accu: 0.8630267977714539, loss_yt: 0.3216613829135895\n",
      "epocht 11, batch_num 4200, step 435721, time: 160.73319602012634 s, accu: 0.8630272746086121, loss_yt: 0.31258687376976013\n",
      "epocht 11, batch_num 4400, step 435921, time: 168.29497575759888 s, accu: 0.863029956817627, loss_yt: 0.21355077624320984\n",
      "epocht 11, batch_num 4600, step 436121, time: 176.00635647773743 s, accu: 0.8630302548408508, loss_yt: 0.14970402419567108\n",
      "epocht 11, batch_num 4800, step 436321, time: 183.37069058418274 s, accu: 0.8630295395851135, loss_yt: 0.42824193835258484\n",
      "epocht 11, batch_num 5000, step 436521, time: 190.93646430969238 s, accu: 0.8630297780036926, loss_yt: 0.29589179158210754\n",
      "epocht 11, batch_num 5200, step 436721, time: 198.2748086452484 s, accu: 0.8630313873291016, loss_yt: 0.21968573331832886\n",
      "epocht 11, batch_num 5400, step 436921, time: 205.94633197784424 s, accu: 0.8630335330963135, loss_yt: 0.4869687855243683\n",
      "epocht 11, batch_num 5600, step 437121, time: 213.55798935890198 s, accu: 0.8630348443984985, loss_yt: 0.4311201870441437\n",
      "epocht 11, batch_num 5800, step 437321, time: 221.0868456363678 s, accu: 0.8630321621894836, loss_yt: 0.2601322531700134\n",
      "epocht 11, batch_num 6000, step 437521, time: 228.8211271762848 s, accu: 0.8630335330963135, loss_yt: 0.3890669643878937\n",
      "epocht 11, batch_num 6200, step 437721, time: 236.47067284584045 s, accu: 0.8630307912826538, loss_yt: 0.34003472328186035\n",
      "epocht 11, batch_num 6400, step 437921, time: 244.2239396572113 s, accu: 0.8630289435386658, loss_yt: 0.47843116521835327\n",
      "epocht 11, batch_num 6600, step 438121, time: 251.9881796836853 s, accu: 0.8630309700965881, loss_yt: 0.290367990732193\n",
      "epocht 11, batch_num 6800, step 438321, time: 259.48313903808594 s, accu: 0.8630328178405762, loss_yt: 0.323190838098526\n",
      "epocht 11, batch_num 7000, step 438521, time: 267.01499581336975 s, accu: 0.8630352020263672, loss_yt: 0.35018816590309143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 11, batch_num 7200, step 438721, time: 274.47706842422485 s, accu: 0.8630331754684448, loss_yt: 0.34587663412094116\n",
      "epocht 11, batch_num 7400, step 438921, time: 282.22133350372314 s, accu: 0.8630340695381165, loss_yt: 0.2346843034029007\n",
      "iter_validnum 1860\n",
      "epochv 11, step 438960, stop_n 0, time: 336.1112370491028 s, accu_va: 0.8630393266677856, loss_yv: 0.2981031611641889\n",
      "iter_trainnum 7440\n",
      "epocht 11, batch_num 0, step 438961, time: 0.3450772762298584 s, accu: 0.8630416989326477, loss_yt: 0.2656908333301544\n",
      "epocht 11, batch_num 200, step 439161, time: 7.702403783798218 s, accu: 0.8630436062812805, loss_yt: 0.3097808361053467\n",
      "epocht 11, batch_num 400, step 439361, time: 15.370949745178223 s, accu: 0.8630456924438477, loss_yt: 0.4516310691833496\n",
      "epocht 11, batch_num 600, step 439561, time: 22.969579935073853 s, accu: 0.8630466461181641, loss_yt: 0.232715904712677\n",
      "epocht 11, batch_num 800, step 439761, time: 30.29901909828186 s, accu: 0.8630497455596924, loss_yt: 0.3145536482334137\n",
      "epocht 11, batch_num 1000, step 439961, time: 37.85776948928833 s, accu: 0.8630502223968506, loss_yt: 0.2047426700592041\n",
      "epocht 11, batch_num 1200, step 440161, time: 45.61901640892029 s, accu: 0.863050639629364, loss_yt: 0.26808369159698486\n",
      "epocht 11, batch_num 1400, step 440361, time: 53.07707166671753 s, accu: 0.863052248954773, loss_yt: 0.3066558539867401\n",
      "epocht 11, batch_num 1600, step 440561, time: 60.78047275543213 s, accu: 0.8630538582801819, loss_yt: 0.4615068733692169\n",
      "epocht 11, batch_num 1800, step 440761, time: 68.48686647415161 s, accu: 0.8630525469779968, loss_yt: 0.37617847323417664\n",
      "epocht 11, batch_num 2000, step 440961, time: 75.93396401405334 s, accu: 0.8630542755126953, loss_yt: 0.2963773012161255\n",
      "epocht 11, batch_num 2200, step 441161, time: 83.84978437423706 s, accu: 0.8630549907684326, loss_yt: 0.2451871782541275\n",
      "epocht 11, batch_num 2400, step 441361, time: 91.42655539512634 s, accu: 0.8630531430244446, loss_yt: 0.38015902042388916\n",
      "epocht 11, batch_num 2600, step 441561, time: 99.18976640701294 s, accu: 0.8630502223968506, loss_yt: 0.2559783160686493\n",
      "epocht 11, batch_num 2800, step 441761, time: 106.64583659172058 s, accu: 0.8630498051643372, loss_yt: 0.222556471824646\n",
      "epocht 11, batch_num 3000, step 441961, time: 114.18566727638245 s, accu: 0.8630509376525879, loss_yt: 0.31318557262420654\n",
      "epocht 11, batch_num 3200, step 442161, time: 121.86015295982361 s, accu: 0.8630508780479431, loss_yt: 0.28669312596321106\n",
      "epocht 11, batch_num 3400, step 442361, time: 129.4967257976532 s, accu: 0.8630502820014954, loss_yt: 0.27614617347717285\n",
      "epocht 11, batch_num 3600, step 442561, time: 137.23403406143188 s, accu: 0.8630492091178894, loss_yt: 0.21792998909950256\n",
      "epocht 11, batch_num 3800, step 442761, time: 144.79182386398315 s, accu: 0.8630508780479431, loss_yt: 0.3467600643634796\n",
      "epocht 11, batch_num 4000, step 442961, time: 152.34961485862732 s, accu: 0.8630514740943909, loss_yt: 0.13231682777404785\n",
      "epocht 11, batch_num 4200, step 443161, time: 160.18366694450378 s, accu: 0.8630509972572327, loss_yt: 0.21088771522045135\n",
      "epocht 11, batch_num 4400, step 443361, time: 167.73048758506775 s, accu: 0.8630534410476685, loss_yt: 0.14162996411323547\n",
      "epocht 11, batch_num 4600, step 443561, time: 175.1795678138733 s, accu: 0.863055408000946, loss_yt: 0.37597858905792236\n",
      "epocht 11, batch_num 4800, step 443761, time: 182.6815059185028 s, accu: 0.8630564212799072, loss_yt: 0.2467789649963379\n",
      "epocht 11, batch_num 5000, step 443961, time: 190.10665106773376 s, accu: 0.8630593419075012, loss_yt: 0.4044979214668274\n",
      "epocht 11, batch_num 5200, step 444161, time: 197.7083249092102 s, accu: 0.8630585670471191, loss_yt: 0.5235913395881653\n",
      "epocht 11, batch_num 5400, step 444361, time: 205.19832849502563 s, accu: 0.8630616664886475, loss_yt: 0.24103358387947083\n",
      "epocht 11, batch_num 5600, step 444561, time: 212.86782145500183 s, accu: 0.8630620241165161, loss_yt: 0.2793596088886261\n",
      "epocht 11, batch_num 5800, step 444761, time: 220.53827667236328 s, accu: 0.8630627393722534, loss_yt: 0.2765122950077057\n",
      "epocht 11, batch_num 6000, step 444961, time: 228.05520606040955 s, accu: 0.8630642890930176, loss_yt: 0.262912780046463\n",
      "epocht 11, batch_num 6200, step 445161, time: 235.54218244552612 s, accu: 0.8630648255348206, loss_yt: 0.32712090015411377\n",
      "epocht 11, batch_num 6400, step 445361, time: 243.22860670089722 s, accu: 0.8630635738372803, loss_yt: 0.34273678064346313\n",
      "epocht 11, batch_num 6600, step 445561, time: 250.83426356315613 s, accu: 0.8630645275115967, loss_yt: 0.1792769581079483\n",
      "epocht 11, batch_num 6800, step 445761, time: 258.49178743362427 s, accu: 0.8630650043487549, loss_yt: 0.27868717908859253\n",
      "epocht 11, batch_num 7000, step 445961, time: 266.04957938194275 s, accu: 0.8630642890930176, loss_yt: 0.30356037616729736\n",
      "epocht 11, batch_num 7200, step 446161, time: 273.7669541835785 s, accu: 0.863062858581543, loss_yt: 0.4504866302013397\n",
      "epocht 11, batch_num 7400, step 446361, time: 281.34068989753723 s, accu: 0.8630610704421997, loss_yt: 0.30076488852500916\n",
      "iter_validnum 1860\n",
      "epochv 11, step 446400, stop_n 1, time: 335.0779941082001 s, accu_va: 0.8630629209421015, loss_yv: 0.29807641013094816\n",
      "iter_trainnum 7440\n",
      "epocht 12, batch_num 0, step 446401, time: 0.37100887298583984 s, accu: 0.8630648255348206, loss_yt: 0.2689169943332672\n",
      "epocht 12, batch_num 200, step 446601, time: 7.843027114868164 s, accu: 0.8630661368370056, loss_yt: 0.3782447576522827\n",
      "epocht 12, batch_num 400, step 446801, time: 15.38087511062622 s, accu: 0.8630661368370056, loss_yt: 0.23087133467197418\n",
      "epocht 12, batch_num 600, step 447001, time: 23.145110845565796 s, accu: 0.8630658984184265, loss_yt: 0.17238998413085938\n",
      "epocht 12, batch_num 800, step 447201, time: 30.94924020767212 s, accu: 0.8630639910697937, loss_yt: 0.2974051535129547\n",
      "epocht 12, batch_num 1000, step 447401, time: 38.55689716339111 s, accu: 0.8630667328834534, loss_yt: 0.3575705885887146\n",
      "epocht 12, batch_num 1200, step 447601, time: 45.96212887763977 s, accu: 0.8630692958831787, loss_yt: 0.3285379707813263\n",
      "epocht 12, batch_num 1400, step 447801, time: 53.72932577133179 s, accu: 0.863067090511322, loss_yt: 0.30568671226501465\n",
      "epocht 12, batch_num 1600, step 448001, time: 61.408809423446655 s, accu: 0.8630688786506653, loss_yt: 0.3106837570667267\n",
      "epocht 12, batch_num 1800, step 448201, time: 69.168044090271 s, accu: 0.8630684614181519, loss_yt: 0.4416871666908264\n",
      "epocht 12, batch_num 2000, step 448401, time: 76.63108801841736 s, accu: 0.8630669713020325, loss_yt: 0.23134639859199524\n",
      "epocht 12, batch_num 2200, step 448601, time: 84.21680355072021 s, accu: 0.8630681037902832, loss_yt: 0.17776915431022644\n",
      "epocht 12, batch_num 2400, step 448801, time: 91.56814432144165 s, accu: 0.8630707263946533, loss_yt: 0.2058718055486679\n",
      "epocht 12, batch_num 2600, step 449001, time: 99.14588284492493 s, accu: 0.8630707859992981, loss_yt: 0.3771812319755554\n",
      "epocht 12, batch_num 2800, step 449201, time: 106.77750706672668 s, accu: 0.8630729913711548, loss_yt: 0.31671658158302307\n",
      "epocht 12, batch_num 3000, step 449401, time: 114.32332944869995 s, accu: 0.8630748987197876, loss_yt: 0.4222413897514343\n",
      "epocht 12, batch_num 3200, step 449601, time: 122.00375843048096 s, accu: 0.8630760908126831, loss_yt: 0.3085373342037201\n",
      "epocht 12, batch_num 3400, step 449801, time: 129.40696263313293 s, accu: 0.8630770444869995, loss_yt: 0.2619873583316803\n",
      "epocht 12, batch_num 3600, step 450001, time: 137.09643363952637 s, accu: 0.8630755543708801, loss_yt: 0.29738515615463257\n",
      "epocht 12, batch_num 3800, step 450201, time: 144.57142806053162 s, accu: 0.8630756139755249, loss_yt: 0.23399440944194794\n",
      "epocht 12, batch_num 4000, step 450401, time: 152.1391806602478 s, accu: 0.863076388835907, loss_yt: 0.32724490761756897\n",
      "epocht 12, batch_num 4200, step 450601, time: 159.60321855545044 s, accu: 0.8630797863006592, loss_yt: 0.45123544335365295\n",
      "epocht 12, batch_num 4400, step 450801, time: 167.27473139762878 s, accu: 0.8630787134170532, loss_yt: 0.15654981136322021\n",
      "epocht 12, batch_num 4600, step 451001, time: 174.7148413658142 s, accu: 0.8630784749984741, loss_yt: 0.5471956729888916\n",
      "epocht 12, batch_num 4800, step 451201, time: 182.44915652275085 s, accu: 0.8630766868591309, loss_yt: 0.2313947081565857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 12, batch_num 5000, step 451401, time: 190.04880452156067 s, accu: 0.8630781173706055, loss_yt: 0.2765997648239136\n",
      "epocht 12, batch_num 5200, step 451601, time: 197.4689691066742 s, accu: 0.8630769848823547, loss_yt: 0.257182240486145\n",
      "epocht 12, batch_num 5400, step 451801, time: 205.04769921302795 s, accu: 0.8630774617195129, loss_yt: 0.4855822026729584\n",
      "epocht 12, batch_num 5600, step 452001, time: 212.67930817604065 s, accu: 0.8630788326263428, loss_yt: 0.25609466433525085\n",
      "epocht 12, batch_num 5800, step 452201, time: 220.07850456237793 s, accu: 0.8630799055099487, loss_yt: 0.20466746389865875\n",
      "epocht 12, batch_num 6000, step 452401, time: 227.47373294830322 s, accu: 0.8630827069282532, loss_yt: 0.5245261192321777\n",
      "epocht 12, batch_num 6200, step 452601, time: 235.2170262336731 s, accu: 0.8630832433700562, loss_yt: 0.28466489911079407\n",
      "epocht 12, batch_num 6400, step 452801, time: 242.73792457580566 s, accu: 0.8630841374397278, loss_yt: 0.31908631324768066\n",
      "epocht 12, batch_num 6600, step 453001, time: 250.5081353187561 s, accu: 0.8630840182304382, loss_yt: 0.2471008598804474\n",
      "epocht 12, batch_num 6800, step 453201, time: 258.14671063423157 s, accu: 0.8630831837654114, loss_yt: 0.24058331549167633\n",
      "epocht 12, batch_num 7000, step 453401, time: 265.7444181442261 s, accu: 0.8630853295326233, loss_yt: 0.27288153767585754\n",
      "epocht 12, batch_num 7200, step 453601, time: 273.44480299949646 s, accu: 0.8630862236022949, loss_yt: 0.3809252083301544\n",
      "epocht 12, batch_num 7400, step 453801, time: 281.1900954246521 s, accu: 0.8630864024162292, loss_yt: 0.2789806127548218\n",
      "iter_validnum 1860\n",
      "epochv 12, step 453840, stop_n 0, time: 335.1498019695282 s, accu_va: 0.8630868685501878, loss_yv: 0.3004445925955811\n",
      "iter_trainnum 7440\n",
      "epocht 12, batch_num 0, step 453841, time: 0.25531840324401855 s, accu: 0.86308753490448, loss_yt: 0.11791728436946869\n",
      "epocht 12, batch_num 200, step 454041, time: 7.8370771408081055 s, accu: 0.8630878925323486, loss_yt: 0.4092034697532654\n",
      "epocht 12, batch_num 400, step 454241, time: 15.422796487808228 s, accu: 0.8630908727645874, loss_yt: 0.1971430629491806\n",
      "epocht 12, batch_num 600, step 454441, time: 23.038394689559937 s, accu: 0.8630943894386292, loss_yt: 0.27141073346138\n",
      "epocht 12, batch_num 800, step 454641, time: 30.623114109039307 s, accu: 0.8630929589271545, loss_yt: 0.2559175193309784\n",
      "epocht 12, batch_num 1000, step 454841, time: 38.11411476135254 s, accu: 0.8630926609039307, loss_yt: 0.2527609169483185\n",
      "epocht 12, batch_num 1200, step 455041, time: 45.842453718185425 s, accu: 0.8630925416946411, loss_yt: 0.3171570599079132\n",
      "epocht 12, batch_num 1400, step 455241, time: 53.25563192367554 s, accu: 0.863093376159668, loss_yt: 0.2948073744773865\n",
      "epocht 12, batch_num 1600, step 455441, time: 60.92707967758179 s, accu: 0.8630946278572083, loss_yt: 0.2254226803779602\n",
      "epocht 12, batch_num 1800, step 455641, time: 68.7162516117096 s, accu: 0.8630927801132202, loss_yt: 0.4299967885017395\n",
      "epocht 12, batch_num 2000, step 455841, time: 76.3229124546051 s, accu: 0.8630940914154053, loss_yt: 0.16825249791145325\n",
      "epocht 12, batch_num 2200, step 456041, time: 83.82784414291382 s, accu: 0.8630937933921814, loss_yt: 0.13547715544700623\n",
      "epocht 12, batch_num 2400, step 456241, time: 91.27297830581665 s, accu: 0.8630962371826172, loss_yt: 0.14266420900821686\n",
      "epocht 12, batch_num 2600, step 456441, time: 99.11101937294006 s, accu: 0.863094687461853, loss_yt: 0.2850003242492676\n",
      "epocht 12, batch_num 2800, step 456641, time: 106.54512906074524 s, accu: 0.863095760345459, loss_yt: 0.29480546712875366\n",
      "epocht 12, batch_num 3000, step 456841, time: 114.38313674926758 s, accu: 0.8630967736244202, loss_yt: 0.4703373908996582\n",
      "epocht 12, batch_num 3200, step 457041, time: 122.43560409545898 s, accu: 0.8630965948104858, loss_yt: 0.2817416489124298\n",
      "epocht 12, batch_num 3400, step 457241, time: 130.1839210987091 s, accu: 0.8630951642990112, loss_yt: 0.3045765459537506\n",
      "epocht 12, batch_num 3600, step 457441, time: 137.52027082443237 s, accu: 0.8630961775779724, loss_yt: 0.2212083488702774\n",
      "epocht 12, batch_num 3800, step 457641, time: 145.1398949623108 s, accu: 0.8630953431129456, loss_yt: 0.5014898777008057\n",
      "epocht 12, batch_num 4000, step 457841, time: 152.75353384017944 s, accu: 0.8630967140197754, loss_yt: 0.36514002084732056\n",
      "epocht 12, batch_num 4200, step 458041, time: 160.37120866775513 s, accu: 0.8630984425544739, loss_yt: 0.3902242183685303\n",
      "epocht 12, batch_num 4400, step 458241, time: 167.8960874080658 s, accu: 0.8630997538566589, loss_yt: 0.2285197377204895\n",
      "epocht 12, batch_num 4600, step 458441, time: 175.6712522506714 s, accu: 0.8630991578102112, loss_yt: 0.2492312788963318\n",
      "epocht 12, batch_num 4800, step 458641, time: 183.09041261672974 s, accu: 0.8631012439727783, loss_yt: 0.5219109058380127\n",
      "epocht 12, batch_num 5000, step 458841, time: 190.66515803337097 s, accu: 0.8631040453910828, loss_yt: 0.2779081463813782\n",
      "epocht 12, batch_num 5200, step 459041, time: 198.29875016212463 s, accu: 0.8631041049957275, loss_yt: 0.2795797884464264\n",
      "epocht 12, batch_num 5400, step 459241, time: 205.99918627738953 s, accu: 0.8631030321121216, loss_yt: 0.21133694052696228\n",
      "epocht 12, batch_num 5600, step 459441, time: 213.3834080696106 s, accu: 0.8631043434143066, loss_yt: 0.10583968460559845\n",
      "epocht 12, batch_num 5800, step 459641, time: 221.014004945755 s, accu: 0.8631044030189514, loss_yt: 0.3081793189048767\n",
      "epocht 12, batch_num 6000, step 459841, time: 228.90391063690186 s, accu: 0.8631047010421753, loss_yt: 0.2816067636013031\n",
      "epocht 12, batch_num 6200, step 460041, time: 236.4098677635193 s, accu: 0.8631041646003723, loss_yt: 0.30019253492355347\n",
      "epocht 12, batch_num 6400, step 460241, time: 244.0594129562378 s, accu: 0.8631041049957275, loss_yt: 0.31988754868507385\n",
      "epocht 12, batch_num 6600, step 460441, time: 251.8864781856537 s, accu: 0.8631026148796082, loss_yt: 0.3163831830024719\n",
      "epocht 12, batch_num 6800, step 460641, time: 259.42233419418335 s, accu: 0.8631060719490051, loss_yt: 0.28094103932380676\n",
      "epocht 12, batch_num 7000, step 460841, time: 267.12969160079956 s, accu: 0.8631070256233215, loss_yt: 0.3534393012523651\n",
      "epocht 12, batch_num 7200, step 461041, time: 274.6685311794281 s, accu: 0.8631093502044678, loss_yt: 0.4482945501804352\n",
      "epocht 12, batch_num 7400, step 461241, time: 282.2582359313965 s, accu: 0.8631079196929932, loss_yt: 0.27958428859710693\n",
      "iter_validnum 1860\n",
      "epochv 12, step 461280, stop_n 0, time: 336.2718300819397 s, accu_va: 0.8631064087472936, loss_yv: 0.30276079702000785\n",
      "iter_trainnum 7440\n",
      "epocht 12, batch_num 0, step 461281, time: 0.21439886093139648 s, accu: 0.863106369972229, loss_yt: 0.24310411512851715\n",
      "epocht 12, batch_num 200, step 461481, time: 7.809124946594238 s, accu: 0.863107442855835, loss_yt: 0.3895752429962158\n",
      "epocht 12, batch_num 400, step 461681, time: 15.364896059036255 s, accu: 0.8631066679954529, loss_yt: 0.2535720467567444\n",
      "epocht 12, batch_num 600, step 461881, time: 22.793025970458984 s, accu: 0.8631073832511902, loss_yt: 0.34121987223625183\n",
      "epocht 12, batch_num 800, step 462081, time: 30.469521045684814 s, accu: 0.8631064891815186, loss_yt: 0.18311291933059692\n",
      "epocht 12, batch_num 1000, step 462281, time: 38.40530061721802 s, accu: 0.8631043434143066, loss_yt: 0.43259483575820923\n",
      "epocht 12, batch_num 1200, step 462481, time: 45.974069118499756 s, accu: 0.8631037473678589, loss_yt: 0.24686317145824432\n",
      "epocht 12, batch_num 1400, step 462681, time: 53.508915424346924 s, accu: 0.8631039261817932, loss_yt: 0.32138872146606445\n",
      "epocht 12, batch_num 1600, step 462881, time: 61.595298528671265 s, accu: 0.8631040453910828, loss_yt: 0.37708017230033875\n",
      "epocht 12, batch_num 1800, step 463081, time: 69.19494438171387 s, accu: 0.863105058670044, loss_yt: 0.3877659738063812\n",
      "epocht 12, batch_num 2000, step 463281, time: 76.67793345451355 s, accu: 0.8631071448326111, loss_yt: 0.21687893569469452\n",
      "epocht 12, batch_num 2200, step 463481, time: 84.57282376289368 s, accu: 0.863106906414032, loss_yt: 0.4268418252468109\n",
      "epocht 12, batch_num 2400, step 463681, time: 91.93716311454773 s, accu: 0.8631094098091125, loss_yt: 0.29660269618034363\n",
      "epocht 12, batch_num 2600, step 463881, time: 99.93873429298401 s, accu: 0.8631103038787842, loss_yt: 0.2889275848865509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 12, batch_num 2800, step 464081, time: 107.44366478919983 s, accu: 0.8631106615066528, loss_yt: 0.3681394159793854\n",
      "epocht 12, batch_num 3000, step 464281, time: 115.08623147010803 s, accu: 0.8631125092506409, loss_yt: 0.24470597505569458\n",
      "epocht 12, batch_num 3200, step 464481, time: 122.80462646484375 s, accu: 0.8631132245063782, loss_yt: 0.329246461391449\n",
      "epocht 12, batch_num 3400, step 464681, time: 130.42225003242493 s, accu: 0.8631115555763245, loss_yt: 0.24901923537254333\n",
      "epocht 12, batch_num 3600, step 464881, time: 138.18047547340393 s, accu: 0.8631097674369812, loss_yt: 0.289315789937973\n",
      "epocht 12, batch_num 3800, step 465081, time: 145.69837093353271 s, accu: 0.8631101846694946, loss_yt: 0.22322843968868256\n",
      "epocht 12, batch_num 4000, step 465281, time: 153.49753499031067 s, accu: 0.8631125688552856, loss_yt: 0.37676605582237244\n",
      "epocht 12, batch_num 4200, step 465481, time: 161.14406847953796 s, accu: 0.8631120324134827, loss_yt: 0.3573906123638153\n",
      "epocht 12, batch_num 4400, step 465681, time: 168.78963446617126 s, accu: 0.8631117343902588, loss_yt: 0.264146625995636\n",
      "epocht 12, batch_num 4600, step 465881, time: 176.35339856147766 s, accu: 0.8631126284599304, loss_yt: 0.3438640236854553\n",
      "epocht 12, batch_num 4800, step 466081, time: 183.9969973564148 s, accu: 0.8631126880645752, loss_yt: 0.2800963819026947\n",
      "epocht 12, batch_num 5000, step 466281, time: 191.40714693069458 s, accu: 0.8631132245063782, loss_yt: 0.42722663283348083\n",
      "epocht 12, batch_num 5200, step 466481, time: 199.09462141990662 s, accu: 0.8631125092506409, loss_yt: 0.27817609906196594\n",
      "epocht 12, batch_num 5400, step 466681, time: 206.91966581344604 s, accu: 0.8631125092506409, loss_yt: 0.3304905295372009\n",
      "epocht 12, batch_num 5600, step 466881, time: 214.44556736946106 s, accu: 0.8631144165992737, loss_yt: 0.17302215099334717\n",
      "epocht 12, batch_num 5800, step 467081, time: 221.9963493347168 s, accu: 0.8631148934364319, loss_yt: 0.312180757522583\n",
      "epocht 12, batch_num 6000, step 467281, time: 229.30384135246277 s, accu: 0.8631185293197632, loss_yt: 0.2892754077911377\n",
      "epocht 12, batch_num 6200, step 467481, time: 236.90551161766052 s, accu: 0.8631177544593811, loss_yt: 0.26757383346557617\n",
      "epocht 12, batch_num 6400, step 467681, time: 244.47028613090515 s, accu: 0.8631168603897095, loss_yt: 0.2862839698791504\n",
      "epocht 12, batch_num 6600, step 467881, time: 252.04203534126282 s, accu: 0.8631159067153931, loss_yt: 0.32754480838775635\n",
      "epocht 12, batch_num 6800, step 468081, time: 259.640686750412 s, accu: 0.863116979598999, loss_yt: 0.278532475233078\n",
      "epocht 12, batch_num 7000, step 468281, time: 267.77397775650024 s, accu: 0.863118588924408, loss_yt: 0.2913283705711365\n",
      "epocht 12, batch_num 7200, step 468481, time: 275.1452271938324 s, accu: 0.8631191849708557, loss_yt: 0.1866845190525055\n",
      "epocht 12, batch_num 7400, step 468681, time: 283.05711030960083 s, accu: 0.8631179332733154, loss_yt: 0.3384917676448822\n",
      "iter_validnum 1860\n",
      "epochv 12, step 468720, stop_n 0, time: 336.77143836021423 s, accu_va: 0.8631185039397209, loss_yv: 0.29775749148941166\n",
      "iter_trainnum 7440\n",
      "epocht 12, batch_num 0, step 468721, time: 0.3999629020690918 s, accu: 0.8631231188774109, loss_yt: 0.2854660153388977\n",
      "epocht 12, batch_num 200, step 468921, time: 8.039537191390991 s, accu: 0.8631238341331482, loss_yt: 0.3297770917415619\n",
      "epocht 12, batch_num 400, step 469121, time: 15.484628438949585 s, accu: 0.8631245493888855, loss_yt: 0.12386630475521088\n",
      "epocht 12, batch_num 600, step 469321, time: 23.22389817237854 s, accu: 0.8631244897842407, loss_yt: 0.2625437378883362\n",
      "epocht 12, batch_num 800, step 469521, time: 30.60516047477722 s, accu: 0.8631247878074646, loss_yt: 0.378521203994751\n",
      "epocht 12, batch_num 1000, step 469721, time: 38.260740756988525 s, accu: 0.8631253242492676, loss_yt: 0.3615955114364624\n",
      "epocht 12, batch_num 1200, step 469921, time: 45.73869442939758 s, accu: 0.8631266355514526, loss_yt: 0.3606263995170593\n",
      "epocht 12, batch_num 1400, step 470121, time: 53.248610496520996 s, accu: 0.8631269335746765, loss_yt: 0.29600760340690613\n",
      "epocht 12, batch_num 1600, step 470321, time: 60.759573459625244 s, accu: 0.8631270527839661, loss_yt: 0.37428826093673706\n",
      "epocht 12, batch_num 1800, step 470521, time: 68.20661759376526 s, accu: 0.8631283044815063, loss_yt: 0.32161006331443787\n",
      "epocht 12, batch_num 2000, step 470721, time: 75.65469813346863 s, accu: 0.8631279468536377, loss_yt: 0.4765006899833679\n",
      "epocht 12, batch_num 2200, step 470921, time: 83.35510659217834 s, accu: 0.8631274104118347, loss_yt: 0.25153377652168274\n",
      "epocht 12, batch_num 2400, step 471121, time: 90.84112071990967 s, accu: 0.8631273508071899, loss_yt: 0.13599412143230438\n",
      "epocht 12, batch_num 2600, step 471321, time: 98.48070406913757 s, accu: 0.863128125667572, loss_yt: 0.24883252382278442\n",
      "epocht 12, batch_num 2800, step 471521, time: 105.80311226844788 s, accu: 0.8631293773651123, loss_yt: 0.27727675437927246\n",
      "epocht 12, batch_num 3000, step 471721, time: 113.2790880203247 s, accu: 0.8631297945976257, loss_yt: 0.40494492650032043\n",
      "epocht 12, batch_num 3200, step 471921, time: 120.69230031967163 s, accu: 0.8631319999694824, loss_yt: 0.36530548334121704\n",
      "epocht 12, batch_num 3400, step 472121, time: 128.1633174419403 s, accu: 0.8631342649459839, loss_yt: 0.28094619512557983\n",
      "epocht 12, batch_num 3600, step 472321, time: 135.62536692619324 s, accu: 0.8631357550621033, loss_yt: 0.18255206942558289\n",
      "epocht 12, batch_num 3800, step 472521, time: 143.37660813331604 s, accu: 0.8631362915039062, loss_yt: 0.28489434719085693\n",
      "epocht 12, batch_num 4000, step 472721, time: 150.8825809955597 s, accu: 0.8631359338760376, loss_yt: 0.39922091364860535\n",
      "epocht 12, batch_num 4200, step 472921, time: 158.4543218612671 s, accu: 0.8631356358528137, loss_yt: 0.37620657682418823\n",
      "epocht 12, batch_num 4400, step 473121, time: 165.89941453933716 s, accu: 0.8631368279457092, loss_yt: 0.22701096534729004\n",
      "epocht 12, batch_num 4600, step 473321, time: 173.5399489402771 s, accu: 0.8631380796432495, loss_yt: 0.33090195059776306\n",
      "epocht 12, batch_num 4800, step 473521, time: 181.15359234809875 s, accu: 0.8631386756896973, loss_yt: 0.35056114196777344\n",
      "epocht 12, batch_num 5000, step 473721, time: 188.66151571273804 s, accu: 0.8631367087364197, loss_yt: 0.3230263888835907\n",
      "epocht 12, batch_num 5200, step 473921, time: 196.23529434204102 s, accu: 0.8631341457366943, loss_yt: 0.24541756510734558\n",
      "epocht 12, batch_num 5400, step 474121, time: 203.67140936851501 s, accu: 0.8631329536437988, loss_yt: 0.29873791337013245\n",
      "epocht 12, batch_num 5600, step 474321, time: 211.45558714866638 s, accu: 0.8631337285041809, loss_yt: 0.4007321298122406\n",
      "epocht 12, batch_num 5800, step 474521, time: 218.9714663028717 s, accu: 0.8631337285041809, loss_yt: 0.3433644473552704\n",
      "epocht 12, batch_num 6000, step 474721, time: 226.59109115600586 s, accu: 0.8631342053413391, loss_yt: 0.2921924889087677\n",
      "epocht 12, batch_num 6200, step 474921, time: 234.01624178886414 s, accu: 0.8631358742713928, loss_yt: 0.24529136717319489\n",
      "epocht 12, batch_num 6400, step 475121, time: 241.6418435573578 s, accu: 0.8631359934806824, loss_yt: 0.42090171575546265\n",
      "epocht 12, batch_num 6600, step 475321, time: 249.4030900001526 s, accu: 0.8631362318992615, loss_yt: 0.16333341598510742\n",
      "epocht 12, batch_num 6800, step 475521, time: 256.8192913532257 s, accu: 0.8631356358528137, loss_yt: 0.31716257333755493\n",
      "epocht 12, batch_num 7000, step 475721, time: 264.59446811676025 s, accu: 0.8631349205970764, loss_yt: 0.2705939710140228\n",
      "epocht 12, batch_num 7200, step 475921, time: 272.2211072444916 s, accu: 0.8631357550621033, loss_yt: 0.17633439600467682\n",
      "epocht 12, batch_num 7400, step 476121, time: 279.89754843711853 s, accu: 0.8631353974342346, loss_yt: 0.1887434720993042\n",
      "iter_validnum 1860\n",
      "epochv 12, step 476160, stop_n 0, time: 333.3815550804138 s, accu_va: 0.863139441385064, loss_yv: 0.2980841409535177\n",
      "iter_trainnum 7440\n",
      "epocht 12, batch_num 0, step 476161, time: 0.21240592002868652 s, accu: 0.8631439805030823, loss_yt: 0.17837998270988464\n",
      "epocht 12, batch_num 200, step 476361, time: 7.94971776008606 s, accu: 0.8631446361541748, loss_yt: 0.35080283880233765\n",
      "epocht 12, batch_num 400, step 476561, time: 15.822699069976807 s, accu: 0.8631435036659241, loss_yt: 0.44894710183143616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 12, batch_num 600, step 476761, time: 23.496179342269897 s, accu: 0.8631437420845032, loss_yt: 0.230163112282753\n",
      "epocht 12, batch_num 800, step 476961, time: 31.00506615638733 s, accu: 0.863147497177124, loss_yt: 0.32911163568496704\n",
      "epocht 12, batch_num 1000, step 477161, time: 38.44420623779297 s, accu: 0.8631488084793091, loss_yt: 0.4019491672515869\n",
      "epocht 12, batch_num 1200, step 477361, time: 45.78155303001404 s, accu: 0.8631510138511658, loss_yt: 0.39602354168891907\n",
      "epocht 12, batch_num 1400, step 477561, time: 53.38821458816528 s, accu: 0.8631497621536255, loss_yt: 0.37914034724235535\n",
      "epocht 12, batch_num 1600, step 477761, time: 60.90810441970825 s, accu: 0.8631516695022583, loss_yt: 0.4405662417411804\n",
      "epocht 12, batch_num 1800, step 477961, time: 68.36120772361755 s, accu: 0.8631521463394165, loss_yt: 0.33212122321128845\n",
      "epocht 12, batch_num 2000, step 478161, time: 75.87309241294861 s, accu: 0.8631529808044434, loss_yt: 0.30626964569091797\n",
      "epocht 12, batch_num 2200, step 478361, time: 83.21246290206909 s, accu: 0.8631525635719299, loss_yt: 0.12756696343421936\n",
      "epocht 12, batch_num 2400, step 478561, time: 90.89292621612549 s, accu: 0.8631521463394165, loss_yt: 0.427892804145813\n",
      "epocht 12, batch_num 2600, step 478761, time: 98.44473242759705 s, accu: 0.863152027130127, loss_yt: 0.26057496666908264\n",
      "epocht 12, batch_num 2800, step 478961, time: 105.96362709999084 s, accu: 0.8631515502929688, loss_yt: 0.2274470180273056\n",
      "epocht 12, batch_num 3000, step 479161, time: 113.60618853569031 s, accu: 0.863152265548706, loss_yt: 0.16262303292751312\n",
      "epocht 12, batch_num 3200, step 479361, time: 121.02737784385681 s, accu: 0.8631542325019836, loss_yt: 0.255064457654953\n",
      "epocht 12, batch_num 3400, step 479561, time: 128.60311889648438 s, accu: 0.8631538152694702, loss_yt: 0.3075825572013855\n",
      "epocht 12, batch_num 3600, step 479761, time: 136.1060242652893 s, accu: 0.8631546497344971, loss_yt: 0.1544276922941208\n",
      "epocht 12, batch_num 3800, step 479961, time: 143.76155352592468 s, accu: 0.8631541728973389, loss_yt: 0.4025903642177582\n",
      "epocht 12, batch_num 4000, step 480161, time: 151.43805313110352 s, accu: 0.8631534576416016, loss_yt: 0.16882482171058655\n",
      "epocht 12, batch_num 4200, step 480361, time: 159.05665493011475 s, accu: 0.8631538152694702, loss_yt: 0.32702064514160156\n",
      "epocht 12, batch_num 4400, step 480561, time: 166.49077486991882 s, accu: 0.863154947757721, loss_yt: 0.4212242066860199\n",
      "epocht 12, batch_num 4600, step 480761, time: 174.2091679573059 s, accu: 0.8631552457809448, loss_yt: 0.1699923276901245\n",
      "epocht 12, batch_num 4800, step 480961, time: 181.80685663223267 s, accu: 0.8631563782691956, loss_yt: 0.39968249201774597\n",
      "epocht 12, batch_num 5000, step 481161, time: 189.3147418498993 s, accu: 0.8631585240364075, loss_yt: 0.27048853039741516\n",
      "epocht 12, batch_num 5200, step 481361, time: 197.00817012786865 s, accu: 0.8631594181060791, loss_yt: 0.19401295483112335\n",
      "epocht 12, batch_num 5400, step 481561, time: 204.6078495979309 s, accu: 0.8631589412689209, loss_yt: 0.3479359745979309\n",
      "epocht 12, batch_num 5600, step 481761, time: 212.16164922714233 s, accu: 0.8631598353385925, loss_yt: 0.2364467978477478\n",
      "epocht 12, batch_num 5800, step 481961, time: 219.621728181839 s, accu: 0.8631601333618164, loss_yt: 0.3828582167625427\n",
      "epocht 12, batch_num 6000, step 482161, time: 227.05482578277588 s, accu: 0.8631618022918701, loss_yt: 0.15261982381343842\n",
      "epocht 12, batch_num 6200, step 482361, time: 234.87694692611694 s, accu: 0.8631630539894104, loss_yt: 0.2878475487232208\n",
      "epocht 12, batch_num 6400, step 482561, time: 242.40582084655762 s, accu: 0.8631633520126343, loss_yt: 0.28478217124938965\n",
      "epocht 12, batch_num 6600, step 482761, time: 250.07929611206055 s, accu: 0.8631609082221985, loss_yt: 0.3916487395763397\n",
      "epocht 12, batch_num 6800, step 482961, time: 257.82853722572327 s, accu: 0.8631590008735657, loss_yt: 0.3858712613582611\n",
      "epocht 12, batch_num 7000, step 483161, time: 265.3863251209259 s, accu: 0.8631592988967896, loss_yt: 0.2916940450668335\n",
      "epocht 12, batch_num 7200, step 483361, time: 272.9401261806488 s, accu: 0.8631598353385925, loss_yt: 0.24538695812225342\n",
      "epocht 12, batch_num 7400, step 483561, time: 280.64252948760986 s, accu: 0.8631579279899597, loss_yt: 0.17440472543239594\n",
      "iter_validnum 1860\n",
      "epochv 12, step 483600, stop_n 0, time: 335.2146027088165 s, accu_va: 0.8631590938055387, loss_yv: 0.2984403126142038\n",
      "iter_trainnum 7440\n",
      "epocht 13, batch_num 0, step 483601, time: 0.34208250045776367 s, accu: 0.8631632328033447, loss_yt: 0.2733231484889984\n",
      "epocht 13, batch_num 200, step 483801, time: 8.299836158752441 s, accu: 0.8631635308265686, loss_yt: 0.46428006887435913\n",
      "epocht 13, batch_num 400, step 484001, time: 15.822687864303589 s, accu: 0.8631628751754761, loss_yt: 0.3495316207408905\n",
      "epocht 13, batch_num 600, step 484201, time: 23.519140243530273 s, accu: 0.8631632924079895, loss_yt: 0.2660224735736847\n",
      "epocht 13, batch_num 800, step 484401, time: 31.136747360229492 s, accu: 0.8631606698036194, loss_yt: 0.34717562794685364\n",
      "epocht 13, batch_num 1000, step 484601, time: 38.76537299156189 s, accu: 0.8631613850593567, loss_yt: 0.36660346388816833\n",
      "epocht 13, batch_num 1200, step 484801, time: 46.389949321746826 s, accu: 0.8631600737571716, loss_yt: 0.4483976662158966\n",
      "epocht 13, batch_num 1400, step 485001, time: 54.08640241622925 s, accu: 0.863160252571106, loss_yt: 0.2895154058933258\n",
      "epocht 13, batch_num 1600, step 485201, time: 61.67611885070801 s, accu: 0.8631610870361328, loss_yt: 0.3579074740409851\n",
      "epocht 13, batch_num 1800, step 485401, time: 69.30966210365295 s, accu: 0.8631632328033447, loss_yt: 0.3180939555168152\n",
      "epocht 13, batch_num 2000, step 485601, time: 77.10385203361511 s, accu: 0.8631614446640015, loss_yt: 0.625247597694397\n",
      "epocht 13, batch_num 2200, step 485801, time: 84.857088804245 s, accu: 0.8631603717803955, loss_yt: 0.33517882227897644\n",
      "epocht 13, batch_num 2400, step 486001, time: 92.31917238235474 s, accu: 0.8631625771522522, loss_yt: 0.17638495564460754\n",
      "epocht 13, batch_num 2600, step 486201, time: 99.93576860427856 s, accu: 0.8631640672683716, loss_yt: 0.1469849795103073\n",
      "epocht 13, batch_num 2800, step 486401, time: 107.78981041908264 s, accu: 0.8631637096405029, loss_yt: 0.2839329242706299\n",
      "epocht 13, batch_num 3000, step 486601, time: 115.1550714969635 s, accu: 0.8631646633148193, loss_yt: 0.33050277829170227\n",
      "epocht 13, batch_num 3200, step 486801, time: 122.835533618927 s, accu: 0.8631651401519775, loss_yt: 0.4965894818305969\n",
      "epocht 13, batch_num 3400, step 487001, time: 130.1689510345459 s, accu: 0.863166093826294, loss_yt: 0.2497836798429489\n",
      "epocht 13, batch_num 3600, step 487201, time: 137.55018758773804 s, accu: 0.8631699681282043, loss_yt: 0.41538479924201965\n",
      "epocht 13, batch_num 3800, step 487401, time: 145.0411627292633 s, accu: 0.86316978931427, loss_yt: 0.4681369960308075\n",
      "epocht 13, batch_num 4000, step 487601, time: 152.6188941001892 s, accu: 0.8631711006164551, loss_yt: 0.2517520487308502\n",
      "epocht 13, batch_num 4200, step 487801, time: 160.34523105621338 s, accu: 0.8631714582443237, loss_yt: 0.15625715255737305\n",
      "epocht 13, batch_num 4400, step 488001, time: 167.8202419281006 s, accu: 0.8631712794303894, loss_yt: 0.190370112657547\n",
      "epocht 13, batch_num 4600, step 488201, time: 175.48477244377136 s, accu: 0.8631724119186401, loss_yt: 0.25434932112693787\n",
      "epocht 13, batch_num 4800, step 488401, time: 183.4275085926056 s, accu: 0.8631711602210999, loss_yt: 0.3633621633052826\n",
      "epocht 13, batch_num 5000, step 488601, time: 190.9364562034607 s, accu: 0.8631733655929565, loss_yt: 0.3345050811767578\n",
      "epocht 13, batch_num 5200, step 488801, time: 198.5849814414978 s, accu: 0.8631737232208252, loss_yt: 0.13452783226966858\n",
      "epocht 13, batch_num 5400, step 489001, time: 206.01314401626587 s, accu: 0.8631753921508789, loss_yt: 0.46779918670654297\n",
      "epocht 13, batch_num 5600, step 489201, time: 213.7763545513153 s, accu: 0.863176703453064, loss_yt: 0.1676889806985855\n",
      "epocht 13, batch_num 5800, step 489401, time: 221.11273765563965 s, accu: 0.8631766438484192, loss_yt: 0.4093778431415558\n",
      "epocht 13, batch_num 6000, step 489601, time: 228.87501001358032 s, accu: 0.8631763458251953, loss_yt: 0.2694052457809448\n",
      "epocht 13, batch_num 6200, step 489801, time: 236.23733401298523 s, accu: 0.8631781935691833, loss_yt: 0.13596056401729584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 13, batch_num 6400, step 490001, time: 243.80406045913696 s, accu: 0.8631806969642639, loss_yt: 0.19080138206481934\n",
      "epocht 13, batch_num 6600, step 490201, time: 251.66307663917542 s, accu: 0.8631793856620789, loss_yt: 0.23564413189888\n",
      "epocht 13, batch_num 6800, step 490401, time: 259.2318513393402 s, accu: 0.8631801605224609, loss_yt: 0.29586946964263916\n",
      "epocht 13, batch_num 7000, step 490601, time: 266.851464509964 s, accu: 0.8631799817085266, loss_yt: 0.3796187937259674\n",
      "epocht 13, batch_num 7200, step 490801, time: 274.3902714252472 s, accu: 0.8631796836853027, loss_yt: 0.4404945373535156\n",
      "epocht 13, batch_num 7400, step 491001, time: 282.02688455581665 s, accu: 0.8631820678710938, loss_yt: 0.36462998390197754\n",
      "iter_validnum 1860\n",
      "epochv 13, step 491040, stop_n 0, time: 336.0144872665405 s, accu_va: 0.8631829512696112, loss_yv: 0.30081379017442145\n",
      "iter_trainnum 7440\n",
      "epocht 13, batch_num 0, step 491041, time: 0.3390936851501465 s, accu: 0.8631829023361206, loss_yt: 0.34447258710861206\n",
      "epocht 13, batch_num 200, step 491241, time: 7.798149585723877 s, accu: 0.8631845116615295, loss_yt: 0.11698349565267563\n",
      "epocht 13, batch_num 400, step 491441, time: 15.307070970535278 s, accu: 0.8631840944290161, loss_yt: 0.3102477490901947\n",
      "epocht 13, batch_num 600, step 491641, time: 22.636474132537842 s, accu: 0.8631849884986877, loss_yt: 0.40870150923728943\n",
      "epocht 13, batch_num 800, step 491841, time: 30.268096208572388 s, accu: 0.8631877303123474, loss_yt: 0.3828081786632538\n",
      "epocht 13, batch_num 1000, step 492041, time: 37.87671732902527 s, accu: 0.8631887435913086, loss_yt: 0.17732000350952148\n",
      "epocht 13, batch_num 1200, step 492241, time: 45.35275340080261 s, accu: 0.8631909489631653, loss_yt: 0.2454661875963211\n",
      "epocht 13, batch_num 1400, step 492441, time: 52.76191520690918 s, accu: 0.8631922006607056, loss_yt: 0.2856541872024536\n",
      "epocht 13, batch_num 1600, step 492641, time: 60.34267592430115 s, accu: 0.8631925582885742, loss_yt: 0.14895020425319672\n",
      "epocht 13, batch_num 1800, step 492841, time: 67.86852097511292 s, accu: 0.8631934523582458, loss_yt: 0.1466277837753296\n",
      "epocht 13, batch_num 2000, step 493041, time: 75.27670907974243 s, accu: 0.863194465637207, loss_yt: 0.2970298230648041\n",
      "epocht 13, batch_num 2200, step 493241, time: 82.8684413433075 s, accu: 0.8631959557533264, loss_yt: 0.2848588526248932\n",
      "epocht 13, batch_num 2400, step 493441, time: 90.48206353187561 s, accu: 0.8631967902183533, loss_yt: 0.26303717494010925\n",
      "epocht 13, batch_num 2600, step 493641, time: 97.85932803153992 s, accu: 0.86319899559021, loss_yt: 0.26966461539268494\n",
      "epocht 13, batch_num 2800, step 493841, time: 105.4131691455841 s, accu: 0.8631977438926697, loss_yt: 0.2738279402256012\n",
      "epocht 13, batch_num 3000, step 494041, time: 112.92005205154419 s, accu: 0.8631987571716309, loss_yt: 0.3086495101451874\n",
      "epocht 13, batch_num 3200, step 494241, time: 120.59657692909241 s, accu: 0.8631959557533264, loss_yt: 0.23064807057380676\n",
      "epocht 13, batch_num 3400, step 494441, time: 128.27400517463684 s, accu: 0.8631963133811951, loss_yt: 0.2370532751083374\n",
      "epocht 13, batch_num 3600, step 494641, time: 135.9036295413971 s, accu: 0.8631955981254578, loss_yt: 0.25916287302970886\n",
      "epocht 13, batch_num 3800, step 494841, time: 143.45939779281616 s, accu: 0.8631959557533264, loss_yt: 0.2724292278289795\n",
      "epocht 13, batch_num 4000, step 495041, time: 151.2954456806183 s, accu: 0.8631932735443115, loss_yt: 0.16071709990501404\n",
      "epocht 13, batch_num 4200, step 495241, time: 158.99986839294434 s, accu: 0.8631935119628906, loss_yt: 0.2386500984430313\n",
      "epocht 13, batch_num 4400, step 495441, time: 166.6453981399536 s, accu: 0.8631923198699951, loss_yt: 0.2744314670562744\n",
      "epocht 13, batch_num 4600, step 495641, time: 174.20621037483215 s, accu: 0.8631945252418518, loss_yt: 0.13775058090686798\n",
      "epocht 13, batch_num 4800, step 495841, time: 181.79791235923767 s, accu: 0.863194465637207, loss_yt: 0.18732325732707977\n",
      "epocht 13, batch_num 5000, step 496041, time: 189.43346405029297 s, accu: 0.8631948828697205, loss_yt: 0.30858275294303894\n",
      "epocht 13, batch_num 5200, step 496241, time: 197.029150724411 s, accu: 0.8631942868232727, loss_yt: 0.12249574065208435\n",
      "epocht 13, batch_num 5400, step 496441, time: 204.71360397338867 s, accu: 0.8631957769393921, loss_yt: 0.3037118911743164\n",
      "epocht 13, batch_num 5600, step 496641, time: 212.28934979438782 s, accu: 0.8631970286369324, loss_yt: 0.26673901081085205\n",
      "epocht 13, batch_num 5800, step 496841, time: 219.90203881263733 s, accu: 0.8631983995437622, loss_yt: 0.3117958903312683\n",
      "epocht 13, batch_num 6000, step 497041, time: 227.55656456947327 s, accu: 0.8631991147994995, loss_yt: 0.2291526347398758\n",
      "epocht 13, batch_num 6200, step 497241, time: 235.17818999290466 s, accu: 0.86319899559021, loss_yt: 0.3615640103816986\n",
      "epocht 13, batch_num 6400, step 497441, time: 242.94642901420593 s, accu: 0.863201916217804, loss_yt: 0.11689350008964539\n",
      "epocht 13, batch_num 6600, step 497641, time: 250.39150190353394 s, accu: 0.8632018566131592, loss_yt: 0.3153683543205261\n",
      "epocht 13, batch_num 6800, step 497841, time: 257.92832112312317 s, accu: 0.8632017970085144, loss_yt: 0.28061434626579285\n",
      "epocht 13, batch_num 7000, step 498041, time: 265.443274974823 s, accu: 0.8632032871246338, loss_yt: 0.3047339618206024\n",
      "epocht 13, batch_num 7200, step 498241, time: 273.00101685523987 s, accu: 0.8632034659385681, loss_yt: 0.22002053260803223\n",
      "epocht 13, batch_num 7400, step 498441, time: 280.7702422142029 s, accu: 0.8632022142410278, loss_yt: 0.36281728744506836\n",
      "iter_validnum 1860\n",
      "epochv 13, step 498480, stop_n 0, time: 334.24325346946716 s, accu_va: 0.8631996864593158, loss_yv: 0.30307688855876525\n",
      "iter_trainnum 7440\n",
      "epocht 13, batch_num 0, step 498481, time: 0.6213395595550537 s, accu: 0.8632013201713562, loss_yt: 0.30356141924858093\n",
      "epocht 13, batch_num 200, step 498681, time: 8.192095756530762 s, accu: 0.8632009029388428, loss_yt: 0.4462253153324127\n",
      "epocht 13, batch_num 400, step 498881, time: 15.709996223449707 s, accu: 0.8632007241249084, loss_yt: 0.47821807861328125\n",
      "epocht 13, batch_num 600, step 499081, time: 23.390482187271118 s, accu: 0.8632013201713562, loss_yt: 0.32132136821746826\n",
      "epocht 13, batch_num 800, step 499281, time: 30.929327249526978 s, accu: 0.8632028102874756, loss_yt: 0.30931928753852844\n",
      "epocht 13, batch_num 1000, step 499481, time: 38.62079310417175 s, accu: 0.8632044792175293, loss_yt: 0.26185306906700134\n",
      "epocht 13, batch_num 1200, step 499681, time: 46.18855690956116 s, accu: 0.8632059097290039, loss_yt: 0.33925098180770874\n",
      "epocht 13, batch_num 1400, step 499881, time: 53.79421877861023 s, accu: 0.8632068634033203, loss_yt: 0.11619251221418381\n",
      "epocht 13, batch_num 1600, step 500081, time: 61.24130606651306 s, accu: 0.8632072806358337, loss_yt: 0.27424463629722595\n",
      "epocht 13, batch_num 1800, step 500281, time: 68.89483857154846 s, accu: 0.8632082939147949, loss_yt: 0.3218737542629242\n",
      "epocht 13, batch_num 2000, step 500481, time: 76.68603229522705 s, accu: 0.8632060885429382, loss_yt: 0.3157755434513092\n",
      "epocht 13, batch_num 2200, step 500681, time: 84.1889419555664 s, accu: 0.8632081747055054, loss_yt: 0.4070259630680084\n",
      "epocht 13, batch_num 2400, step 500881, time: 91.86940479278564 s, accu: 0.8632078170776367, loss_yt: 0.33789825439453125\n",
      "epocht 13, batch_num 2600, step 501081, time: 99.49903750419617 s, accu: 0.8632070422172546, loss_yt: 0.3365384042263031\n",
      "epocht 13, batch_num 2800, step 501281, time: 107.16454195976257 s, accu: 0.863207221031189, loss_yt: 0.2946721315383911\n",
      "epocht 13, batch_num 3000, step 501481, time: 114.62854623794556 s, accu: 0.8632069826126099, loss_yt: 0.5948917269706726\n",
      "epocht 13, batch_num 3200, step 501681, time: 121.95296239852905 s, accu: 0.8632099628448486, loss_yt: 0.15408286452293396\n",
      "epocht 13, batch_num 3400, step 501881, time: 129.56859683990479 s, accu: 0.8632097244262695, loss_yt: 0.3230592906475067\n",
      "epocht 13, batch_num 3600, step 502081, time: 137.149352312088 s, accu: 0.863211452960968, loss_yt: 0.3033331036567688\n",
      "epocht 13, batch_num 3800, step 502281, time: 145.15392303466797 s, accu: 0.8632094860076904, loss_yt: 0.5030193328857422\n",
      "epocht 13, batch_num 4000, step 502481, time: 152.73863792419434 s, accu: 0.8632103800773621, loss_yt: 0.30317848920822144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 13, batch_num 4200, step 502681, time: 160.3802375793457 s, accu: 0.8632098436355591, loss_yt: 0.38448235392570496\n",
      "epocht 13, batch_num 4400, step 502881, time: 167.7534990310669 s, accu: 0.8632090091705322, loss_yt: 0.26881474256515503\n",
      "epocht 13, batch_num 4600, step 503081, time: 175.31627321243286 s, accu: 0.8632075190544128, loss_yt: 0.1965678632259369\n",
      "epocht 13, batch_num 4800, step 503281, time: 182.90600275993347 s, accu: 0.8632084131240845, loss_yt: 0.23174957931041718\n",
      "epocht 13, batch_num 5000, step 503481, time: 190.61937165260315 s, accu: 0.8632080554962158, loss_yt: 0.24349254369735718\n",
      "epocht 13, batch_num 5200, step 503681, time: 198.41549944877625 s, accu: 0.8632076382637024, loss_yt: 0.6512648463249207\n",
      "epocht 13, batch_num 5400, step 503881, time: 205.9643120765686 s, accu: 0.8632088303565979, loss_yt: 0.2033175826072693\n",
      "epocht 13, batch_num 5600, step 504081, time: 213.88815689086914 s, accu: 0.8632085919380188, loss_yt: 0.20062319934368134\n",
      "epocht 13, batch_num 5800, step 504281, time: 221.56160378456116 s, accu: 0.8632081151008606, loss_yt: 0.45231032371520996\n",
      "epocht 13, batch_num 6000, step 504481, time: 229.0545675754547 s, accu: 0.8632093667984009, loss_yt: 0.31016382575035095\n",
      "epocht 13, batch_num 6200, step 504681, time: 236.73004341125488 s, accu: 0.863211452960968, loss_yt: 0.17358028888702393\n",
      "epocht 13, batch_num 6400, step 504881, time: 244.3815839290619 s, accu: 0.8632120490074158, loss_yt: 0.27367502450942993\n",
      "epocht 13, batch_num 6600, step 505081, time: 252.04209899902344 s, accu: 0.8632131814956665, loss_yt: 0.3382466733455658\n",
      "epocht 13, batch_num 6800, step 505281, time: 259.52010321617126 s, accu: 0.863213837146759, loss_yt: 0.2828810214996338\n",
      "epocht 13, batch_num 7000, step 505481, time: 267.3033242225647 s, accu: 0.8632130026817322, loss_yt: 0.5988218188285828\n",
      "epocht 13, batch_num 7200, step 505681, time: 274.7842855453491 s, accu: 0.8632140159606934, loss_yt: 0.23201705515384674\n",
      "epocht 13, batch_num 7400, step 505881, time: 282.31415462493896 s, accu: 0.8632146716117859, loss_yt: 0.2984817326068878\n",
      "iter_validnum 1860\n",
      "epochv 13, step 505920, stop_n 0, time: 335.92283391952515 s, accu_va: 0.8632142955257046, loss_yv: 0.29826436244672344\n",
      "iter_trainnum 7440\n",
      "epocht 13, batch_num 0, step 505921, time: 0.37197446823120117 s, accu: 0.8632199764251709, loss_yt: 0.23240309953689575\n",
      "epocht 13, batch_num 200, step 506121, time: 7.789139270782471 s, accu: 0.86322021484375, loss_yt: 0.313480943441391\n",
      "epocht 13, batch_num 400, step 506321, time: 15.444691896438599 s, accu: 0.8632204532623291, loss_yt: 0.33557501435279846\n",
      "epocht 13, batch_num 600, step 506521, time: 22.825962781906128 s, accu: 0.8632227182388306, loss_yt: 0.31417104601860046\n",
      "epocht 13, batch_num 800, step 506721, time: 30.7258038520813 s, accu: 0.8632243275642395, loss_yt: 0.18834790587425232\n",
      "epocht 13, batch_num 1000, step 506921, time: 38.16793727874756 s, accu: 0.863225519657135, loss_yt: 0.42649516463279724\n",
      "epocht 13, batch_num 1200, step 507121, time: 45.83141231536865 s, accu: 0.8632254004478455, loss_yt: 0.4606313109397888\n",
      "epocht 13, batch_num 1400, step 507321, time: 53.51985239982605 s, accu: 0.8632247447967529, loss_yt: 0.26867973804473877\n",
      "epocht 13, batch_num 1600, step 507521, time: 61.101579666137695 s, accu: 0.8632227182388306, loss_yt: 0.369083046913147\n",
      "epocht 13, batch_num 1800, step 507721, time: 68.66136479377747 s, accu: 0.8632246255874634, loss_yt: 0.313785582780838\n",
      "epocht 13, batch_num 2000, step 507921, time: 76.10944747924805 s, accu: 0.8632259964942932, loss_yt: 0.4910777807235718\n",
      "epocht 13, batch_num 2200, step 508121, time: 83.82683897018433 s, accu: 0.8632257580757141, loss_yt: 0.29993778467178345\n",
      "epocht 13, batch_num 2400, step 508321, time: 91.38360381126404 s, accu: 0.8632239103317261, loss_yt: 0.21669766306877136\n",
      "epocht 13, batch_num 2600, step 508521, time: 98.85166788101196 s, accu: 0.8632247447967529, loss_yt: 0.15093594789505005\n",
      "epocht 13, batch_num 2800, step 508721, time: 106.57602977752686 s, accu: 0.8632258176803589, loss_yt: 0.22554618120193481\n",
      "epocht 13, batch_num 3000, step 508921, time: 114.0819103717804 s, accu: 0.8632262945175171, loss_yt: 0.24337732791900635\n",
      "epocht 13, batch_num 3200, step 509121, time: 121.44322490692139 s, accu: 0.863228440284729, loss_yt: 0.2930862009525299\n",
      "epocht 13, batch_num 3400, step 509321, time: 128.95812940597534 s, accu: 0.8632299304008484, loss_yt: 0.2616906464099884\n",
      "epocht 13, batch_num 3600, step 509521, time: 136.49600052833557 s, accu: 0.8632305264472961, loss_yt: 0.24686414003372192\n",
      "epocht 13, batch_num 3800, step 509721, time: 144.08667540550232 s, accu: 0.8632295727729797, loss_yt: 0.30715417861938477\n",
      "epocht 13, batch_num 4000, step 509921, time: 151.61255145072937 s, accu: 0.8632294535636902, loss_yt: 0.5143809914588928\n",
      "epocht 13, batch_num 4200, step 510121, time: 159.18131184577942 s, accu: 0.8632310032844543, loss_yt: 0.22691519558429718\n",
      "epocht 13, batch_num 4400, step 510321, time: 166.99441957473755 s, accu: 0.8632293343544006, loss_yt: 0.258569598197937\n",
      "epocht 13, batch_num 4600, step 510521, time: 174.38169240951538 s, accu: 0.8632283210754395, loss_yt: 0.543010950088501\n",
      "epocht 13, batch_num 4800, step 510721, time: 182.36731433868408 s, accu: 0.8632276058197021, loss_yt: 0.3810414671897888\n",
      "epocht 13, batch_num 5000, step 510921, time: 190.3190815448761 s, accu: 0.8632273077964783, loss_yt: 0.4305844008922577\n",
      "epocht 13, batch_num 5200, step 511121, time: 197.88880729675293 s, accu: 0.8632282018661499, loss_yt: 0.23905020952224731\n",
      "epocht 13, batch_num 5400, step 511321, time: 205.47352695465088 s, accu: 0.863227367401123, loss_yt: 0.31770840287208557\n",
      "epocht 13, batch_num 5600, step 511521, time: 213.1330442428589 s, accu: 0.8632280230522156, loss_yt: 0.4325907230377197\n",
      "epocht 13, batch_num 5800, step 511721, time: 220.69382619857788 s, accu: 0.8632290363311768, loss_yt: 0.12865178287029266\n",
      "epocht 13, batch_num 6000, step 511921, time: 228.22468757629395 s, accu: 0.8632277846336365, loss_yt: 0.1945805847644806\n",
      "epocht 13, batch_num 6200, step 512121, time: 235.89023423194885 s, accu: 0.8632270097732544, loss_yt: 0.24748632311820984\n",
      "epocht 13, batch_num 6400, step 512321, time: 243.24951577186584 s, accu: 0.8632287979125977, loss_yt: 0.2109595537185669\n",
      "epocht 13, batch_num 6600, step 512521, time: 250.80034852027893 s, accu: 0.8632286787033081, loss_yt: 0.49949342012405396\n",
      "epocht 13, batch_num 6800, step 512721, time: 258.3012626171112 s, accu: 0.86323082447052, loss_yt: 0.4978497624397278\n",
      "epocht 13, batch_num 7000, step 512921, time: 265.934956073761 s, accu: 0.8632326126098633, loss_yt: 0.31031063199043274\n",
      "epocht 13, batch_num 7200, step 513121, time: 273.3780105113983 s, accu: 0.863231897354126, loss_yt: 0.28156134486198425\n",
      "epocht 13, batch_num 7400, step 513321, time: 280.8410849571228 s, accu: 0.8632301688194275, loss_yt: 0.2962704002857208\n",
      "iter_validnum 1860\n",
      "epochv 13, step 513360, stop_n 1, time: 334.426766872406 s, accu_va: 0.8632341433596867, loss_yv: 0.29775853457069523\n",
      "iter_trainnum 7440\n",
      "epocht 13, batch_num 0, step 513361, time: 0.4497973918914795 s, accu: 0.8632382154464722, loss_yt: 0.35327842831611633\n",
      "epocht 13, batch_num 200, step 513561, time: 7.873943090438843 s, accu: 0.8632392883300781, loss_yt: 0.29603785276412964\n",
      "epocht 13, batch_num 400, step 513761, time: 15.287149906158447 s, accu: 0.8632392287254333, loss_yt: 0.29893040657043457\n",
      "epocht 13, batch_num 600, step 513961, time: 22.70631170272827 s, accu: 0.8632414937019348, loss_yt: 0.14890223741531372\n",
      "epocht 13, batch_num 800, step 514161, time: 30.265069246292114 s, accu: 0.8632424473762512, loss_yt: 0.14358243346214294\n",
      "epocht 13, batch_num 1000, step 514361, time: 37.55859899520874 s, accu: 0.8632442951202393, loss_yt: 0.1450604945421219\n",
      "epocht 13, batch_num 1200, step 514561, time: 45.22410178184509 s, accu: 0.8632436990737915, loss_yt: 0.3013730049133301\n",
      "epocht 13, batch_num 1400, step 514761, time: 52.89558506011963 s, accu: 0.8632445931434631, loss_yt: 0.26250985264778137\n",
      "epocht 13, batch_num 1600, step 514961, time: 60.43439698219299 s, accu: 0.8632436394691467, loss_yt: 0.22198671102523804\n",
      "epocht 13, batch_num 1800, step 515161, time: 67.93436884880066 s, accu: 0.8632439374923706, loss_yt: 0.29764649271965027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 13, batch_num 2000, step 515361, time: 75.23183751106262 s, accu: 0.8632457256317139, loss_yt: 0.1868962049484253\n",
      "epocht 13, batch_num 2200, step 515561, time: 82.71982979774475 s, accu: 0.8632463812828064, loss_yt: 0.3030758798122406\n",
      "epocht 13, batch_num 2400, step 515761, time: 90.1070511341095 s, accu: 0.8632475137710571, loss_yt: 0.29938268661499023\n",
      "epocht 13, batch_num 2600, step 515961, time: 97.82541227340698 s, accu: 0.8632463216781616, loss_yt: 0.2825394570827484\n",
      "epocht 13, batch_num 2800, step 516161, time: 105.5567398071289 s, accu: 0.8632458448410034, loss_yt: 0.38244298100471497\n",
      "epocht 13, batch_num 3000, step 516361, time: 113.3968014717102 s, accu: 0.8632471561431885, loss_yt: 0.20930735766887665\n",
      "epocht 13, batch_num 3200, step 516561, time: 120.98248934745789 s, accu: 0.8632450699806213, loss_yt: 0.242472305893898\n",
      "epocht 13, batch_num 3400, step 516761, time: 128.51933479309082 s, accu: 0.8632440567016602, loss_yt: 0.34764984250068665\n",
      "epocht 13, batch_num 3600, step 516961, time: 135.96642518043518 s, accu: 0.8632450699806213, loss_yt: 0.23703591525554657\n",
      "epocht 13, batch_num 3800, step 517161, time: 143.62294697761536 s, accu: 0.8632425665855408, loss_yt: 0.305598646402359\n",
      "epocht 13, batch_num 4000, step 517361, time: 151.15483236312866 s, accu: 0.8632421493530273, loss_yt: 0.3468683958053589\n",
      "epocht 13, batch_num 4200, step 517561, time: 158.62486481666565 s, accu: 0.8632422089576721, loss_yt: 0.4233996868133545\n",
      "epocht 13, batch_num 4400, step 517761, time: 166.11680054664612 s, accu: 0.8632426261901855, loss_yt: 0.20541080832481384\n",
      "epocht 13, batch_num 4600, step 517961, time: 173.80823302268982 s, accu: 0.8632426857948303, loss_yt: 0.1262129843235016\n",
      "epocht 13, batch_num 4800, step 518161, time: 181.3171525001526 s, accu: 0.8632434010505676, loss_yt: 0.3986314833164215\n",
      "epocht 13, batch_num 5000, step 518361, time: 188.85499715805054 s, accu: 0.8632438778877258, loss_yt: 0.2539016902446747\n",
      "epocht 13, batch_num 5200, step 518561, time: 196.62026453018188 s, accu: 0.8632460832595825, loss_yt: 0.21794337034225464\n",
      "epocht 13, batch_num 5400, step 518761, time: 204.2797520160675 s, accu: 0.8632474541664124, loss_yt: 0.2710415720939636\n",
      "epocht 13, batch_num 5600, step 518961, time: 211.81768941879272 s, accu: 0.8632490634918213, loss_yt: 0.3358825743198395\n",
      "epocht 13, batch_num 5800, step 519161, time: 219.32857298851013 s, accu: 0.8632513284683228, loss_yt: 0.19188258051872253\n",
      "epocht 13, batch_num 6000, step 519361, time: 226.90331602096558 s, accu: 0.8632510900497437, loss_yt: 0.21447981894016266\n",
      "epocht 13, batch_num 6200, step 519561, time: 234.57081365585327 s, accu: 0.8632508516311646, loss_yt: 0.3826471269130707\n",
      "epocht 13, batch_num 6400, step 519761, time: 242.13957524299622 s, accu: 0.8632495999336243, loss_yt: 0.28560152649879456\n",
      "epocht 13, batch_num 6600, step 519961, time: 249.67143487930298 s, accu: 0.8632482290267944, loss_yt: 0.2694925367832184\n",
      "epocht 13, batch_num 6800, step 520161, time: 257.3359386920929 s, accu: 0.8632495403289795, loss_yt: 0.38444480299949646\n",
      "epocht 13, batch_num 7000, step 520361, time: 264.89672231674194 s, accu: 0.8632500171661377, loss_yt: 0.1626962274312973\n",
      "epocht 13, batch_num 7200, step 520561, time: 272.5572693347931 s, accu: 0.8632509112358093, loss_yt: 0.47540056705474854\n",
      "epocht 13, batch_num 7400, step 520761, time: 280.18188190460205 s, accu: 0.8632497787475586, loss_yt: 0.29369765520095825\n",
      "iter_validnum 1860\n",
      "epochv 13, step 520800, stop_n 0, time: 333.9760024547577 s, accu_va: 0.8632518543991992, loss_yv: 0.29882455591152435\n",
      "iter_trainnum 7440\n",
      "epocht 14, batch_num 0, step 520801, time: 0.2603151798248291 s, accu: 0.863253653049469, loss_yt: 0.27594467997550964\n",
      "epocht 14, batch_num 200, step 521001, time: 7.966727018356323 s, accu: 0.8632515668869019, loss_yt: 0.33234888315200806\n",
      "epocht 14, batch_num 400, step 521201, time: 15.67507004737854 s, accu: 0.8632537722587585, loss_yt: 0.24523316323757172\n",
      "epocht 14, batch_num 600, step 521401, time: 23.454301834106445 s, accu: 0.8632548451423645, loss_yt: 0.23753049969673157\n",
      "epocht 14, batch_num 800, step 521601, time: 30.94324231147766 s, accu: 0.863254189491272, loss_yt: 0.26344966888427734\n",
      "epocht 14, batch_num 1000, step 521801, time: 38.42024898529053 s, accu: 0.8632562160491943, loss_yt: 0.293795645236969\n",
      "epocht 14, batch_num 1200, step 522001, time: 46.00895643234253 s, accu: 0.8632560968399048, loss_yt: 0.31325408816337585\n",
      "epocht 14, batch_num 1400, step 522201, time: 53.491947412490845 s, accu: 0.8632571697235107, loss_yt: 0.34872621297836304\n",
      "epocht 14, batch_num 1600, step 522401, time: 60.89016366004944 s, accu: 0.8632580637931824, loss_yt: 0.22471319139003754\n",
      "epocht 14, batch_num 1800, step 522601, time: 68.53575372695923 s, accu: 0.8632593750953674, loss_yt: 0.3601352274417877\n",
      "epocht 14, batch_num 2000, step 522801, time: 76.22020387649536 s, accu: 0.8632601499557495, loss_yt: 0.2994697093963623\n",
      "epocht 14, batch_num 2200, step 523001, time: 83.71714901924133 s, accu: 0.8632603883743286, loss_yt: 0.3233095705509186\n",
      "epocht 14, batch_num 2400, step 523201, time: 91.2001473903656 s, accu: 0.8632620573043823, loss_yt: 0.35600125789642334\n",
      "epocht 14, batch_num 2600, step 523401, time: 98.68210816383362 s, accu: 0.8632625341415405, loss_yt: 0.3504104018211365\n",
      "epocht 14, batch_num 2800, step 523601, time: 106.10027194023132 s, accu: 0.8632643222808838, loss_yt: 0.36722853779792786\n",
      "epocht 14, batch_num 3000, step 523801, time: 113.67800974845886 s, accu: 0.8632640242576599, loss_yt: 0.20234236121177673\n",
      "epocht 14, batch_num 3200, step 524001, time: 121.57888150215149 s, accu: 0.8632633090019226, loss_yt: 0.3159429728984833\n",
      "epocht 14, batch_num 3400, step 524201, time: 129.435870885849 s, accu: 0.8632631897926331, loss_yt: 0.25695598125457764\n",
      "epocht 14, batch_num 3600, step 524401, time: 136.88495206832886 s, accu: 0.8632638454437256, loss_yt: 0.23173104226589203\n",
      "epocht 14, batch_num 3800, step 524601, time: 144.54646515846252 s, accu: 0.8632665276527405, loss_yt: 0.397795170545578\n",
      "epocht 14, batch_num 4000, step 524801, time: 152.3725390434265 s, accu: 0.8632674813270569, loss_yt: 0.297330379486084\n",
      "epocht 14, batch_num 4200, step 525001, time: 159.87149286270142 s, accu: 0.8632681369781494, loss_yt: 0.22927865386009216\n",
      "epocht 14, batch_num 4400, step 525201, time: 167.50110268592834 s, accu: 0.8632686138153076, loss_yt: 0.26497164368629456\n",
      "epocht 14, batch_num 4600, step 525401, time: 174.99205255508423 s, accu: 0.8632686734199524, loss_yt: 0.13137218356132507\n",
      "epocht 14, batch_num 4800, step 525601, time: 182.70844721794128 s, accu: 0.8632697463035583, loss_yt: 0.2844606935977936\n",
      "epocht 14, batch_num 5000, step 525801, time: 190.1884195804596 s, accu: 0.8632700443267822, loss_yt: 0.31312882900238037\n",
      "epocht 14, batch_num 5200, step 526001, time: 197.67041063308716 s, accu: 0.8632710576057434, loss_yt: 0.24240118265151978\n",
      "epocht 14, batch_num 5400, step 526201, time: 205.22620558738708 s, accu: 0.8632717132568359, loss_yt: 0.3085625469684601\n",
      "epocht 14, batch_num 5600, step 526401, time: 212.83585810661316 s, accu: 0.8632705211639404, loss_yt: 0.10082884132862091\n",
      "epocht 14, batch_num 5800, step 526601, time: 220.57533431053162 s, accu: 0.8632693290710449, loss_yt: 0.431130588054657\n",
      "epocht 14, batch_num 6000, step 526801, time: 227.97059226036072 s, accu: 0.8632723093032837, loss_yt: 0.22175155580043793\n",
      "epocht 14, batch_num 6200, step 527001, time: 236.01205682754517 s, accu: 0.8632723093032837, loss_yt: 0.4013058841228485\n",
      "epocht 14, batch_num 6400, step 527201, time: 243.6905460357666 s, accu: 0.8632728457450867, loss_yt: 0.23717132210731506\n",
      "epocht 14, batch_num 6600, step 527401, time: 251.1366183757782 s, accu: 0.863274097442627, loss_yt: 0.40656620264053345\n",
      "epocht 14, batch_num 6800, step 527601, time: 258.69340538978577 s, accu: 0.8632727861404419, loss_yt: 0.19230857491493225\n",
      "epocht 14, batch_num 7000, step 527801, time: 266.196341753006 s, accu: 0.8632714152336121, loss_yt: 0.44246959686279297\n",
      "epocht 14, batch_num 7200, step 528001, time: 273.7731144428253 s, accu: 0.8632717728614807, loss_yt: 0.3624130189418793\n",
      "epocht 14, batch_num 7400, step 528201, time: 281.27502155303955 s, accu: 0.8632702827453613, loss_yt: 0.2837759256362915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_validnum 1860\n",
      "epochv 14, step 528240, stop_n 0, time: 335.2577042579651 s, accu_va: 0.8632695107370294, loss_yv: 0.3010094310647698\n",
      "iter_trainnum 7440\n",
      "epocht 14, batch_num 0, step 528241, time: 0.42383408546447754 s, accu: 0.8632711172103882, loss_yt: 0.21183006465435028\n",
      "epocht 14, batch_num 200, step 528441, time: 8.03149151802063 s, accu: 0.863270103931427, loss_yt: 0.5418604612350464\n",
      "epocht 14, batch_num 400, step 528641, time: 15.459634065628052 s, accu: 0.8632693886756897, loss_yt: 0.30504944920539856\n",
      "epocht 14, batch_num 600, step 528841, time: 23.040355920791626 s, accu: 0.8632687926292419, loss_yt: 0.12315180897712708\n",
      "epocht 14, batch_num 800, step 529041, time: 30.5462863445282 s, accu: 0.8632684350013733, loss_yt: 0.2764555811882019\n",
      "epocht 14, batch_num 1000, step 529241, time: 38.03828477859497 s, accu: 0.8632680177688599, loss_yt: 0.46588748693466187\n",
      "epocht 14, batch_num 1200, step 529441, time: 45.45841145515442 s, accu: 0.8632684350013733, loss_yt: 0.13029001653194427\n",
      "epocht 14, batch_num 1400, step 529641, time: 53.171809673309326 s, accu: 0.8632698655128479, loss_yt: 0.3220309913158417\n",
      "epocht 14, batch_num 1600, step 529841, time: 60.56601810455322 s, accu: 0.8632712960243225, loss_yt: 0.208907812833786\n",
      "epocht 14, batch_num 1800, step 530041, time: 68.38711452484131 s, accu: 0.8632705211639404, loss_yt: 0.344669371843338\n",
      "epocht 14, batch_num 2000, step 530241, time: 75.92095303535461 s, accu: 0.8632696866989136, loss_yt: 0.4467791020870209\n",
      "epocht 14, batch_num 2200, step 530441, time: 83.4079315662384 s, accu: 0.8632707595825195, loss_yt: 0.6105960011482239\n",
      "epocht 14, batch_num 2400, step 530641, time: 91.20807433128357 s, accu: 0.8632704019546509, loss_yt: 0.3781368136405945\n",
      "epocht 14, batch_num 2600, step 530841, time: 98.74591732025146 s, accu: 0.863271951675415, loss_yt: 0.3499895930290222\n",
      "epocht 14, batch_num 2800, step 531041, time: 106.31667351722717 s, accu: 0.863273024559021, loss_yt: 0.3150913119316101\n",
      "epocht 14, batch_num 3000, step 531241, time: 113.80764436721802 s, accu: 0.8632733821868896, loss_yt: 0.25215139985084534\n",
      "epocht 14, batch_num 3200, step 531441, time: 121.46527576446533 s, accu: 0.8632736802101135, loss_yt: 0.4356038272380829\n",
      "epocht 14, batch_num 3400, step 531641, time: 129.03901171684265 s, accu: 0.8632742166519165, loss_yt: 0.29327401518821716\n",
      "epocht 14, batch_num 3600, step 531841, time: 136.55886793136597 s, accu: 0.8632749915122986, loss_yt: 0.13969963788986206\n",
      "epocht 14, batch_num 3800, step 532041, time: 144.4018976688385 s, accu: 0.8632742166519165, loss_yt: 0.4057016968727112\n",
      "epocht 14, batch_num 4000, step 532241, time: 151.95470190048218 s, accu: 0.8632731437683105, loss_yt: 0.4335589110851288\n",
      "epocht 14, batch_num 4200, step 532441, time: 159.68802094459534 s, accu: 0.8632738590240479, loss_yt: 0.2121884524822235\n",
      "epocht 14, batch_num 4400, step 532641, time: 167.25977420806885 s, accu: 0.8632761240005493, loss_yt: 0.300569623708725\n",
      "epocht 14, batch_num 4600, step 532841, time: 174.78468942642212 s, accu: 0.8632776141166687, loss_yt: 0.17715537548065186\n",
      "epocht 14, batch_num 4800, step 533041, time: 182.3773808479309 s, accu: 0.8632778525352478, loss_yt: 0.1442946493625641\n",
      "epocht 14, batch_num 5000, step 533241, time: 190.4248559474945 s, accu: 0.8632770776748657, loss_yt: 0.127660870552063\n",
      "epocht 14, batch_num 5200, step 533441, time: 197.97165203094482 s, accu: 0.8632788062095642, loss_yt: 0.29453766345977783\n",
      "epocht 14, batch_num 5400, step 533641, time: 205.29508662223816 s, accu: 0.8632818460464478, loss_yt: 0.36854031682014465\n",
      "epocht 14, batch_num 5600, step 533841, time: 213.23982405662537 s, accu: 0.8632824420928955, loss_yt: 0.3051881194114685\n",
      "epocht 14, batch_num 5800, step 534041, time: 220.79461932182312 s, accu: 0.8632846474647522, loss_yt: 0.11739157885313034\n",
      "epocht 14, batch_num 6000, step 534241, time: 228.33246850967407 s, accu: 0.8632869720458984, loss_yt: 0.3184564709663391\n",
      "epocht 14, batch_num 6200, step 534441, time: 236.02193474769592 s, accu: 0.8632872104644775, loss_yt: 0.28971022367477417\n",
      "epocht 14, batch_num 6400, step 534641, time: 243.58770418167114 s, accu: 0.8632879257202148, loss_yt: 0.4554809629917145\n",
      "epocht 14, batch_num 6600, step 534841, time: 251.20231008529663 s, accu: 0.8632870316505432, loss_yt: 0.12750913202762604\n",
      "epocht 14, batch_num 6800, step 535041, time: 258.73018169403076 s, accu: 0.8632877469062805, loss_yt: 0.12530618906021118\n",
      "epocht 14, batch_num 7000, step 535241, time: 266.3139271736145 s, accu: 0.8632879257202148, loss_yt: 0.5981482267379761\n",
      "epocht 14, batch_num 7200, step 535441, time: 273.92357873916626 s, accu: 0.8632868528366089, loss_yt: 0.42282918095588684\n",
      "epocht 14, batch_num 7400, step 535641, time: 281.2180480957031 s, accu: 0.8632867336273193, loss_yt: 0.1773184984922409\n",
      "iter_validnum 1860\n",
      "epochv 14, step 535680, stop_n 0, time: 335.2745306491852 s, accu_va: 0.8632859566519338, loss_yv: 0.30332629579289627\n",
      "iter_trainnum 7440\n",
      "epocht 14, batch_num 0, step 535681, time: 0.32315993309020996 s, accu: 0.8632872104644775, loss_yt: 0.10700194537639618\n",
      "epocht 14, batch_num 200, step 535881, time: 7.790146589279175 s, accu: 0.863288402557373, loss_yt: 0.23904168605804443\n",
      "epocht 14, batch_num 400, step 536081, time: 15.289084911346436 s, accu: 0.8632895350456238, loss_yt: 0.26031002402305603\n",
      "epocht 14, batch_num 600, step 536281, time: 22.737168788909912 s, accu: 0.8632880449295044, loss_yt: 0.2683663070201874\n",
      "epocht 14, batch_num 800, step 536481, time: 30.443562269210815 s, accu: 0.863286554813385, loss_yt: 0.30530425906181335\n",
      "epocht 14, batch_num 1000, step 536681, time: 38.53895115852356 s, accu: 0.8632868528366089, loss_yt: 0.43477049469947815\n",
      "epocht 14, batch_num 1200, step 536881, time: 46.31711721420288 s, accu: 0.8632864356040955, loss_yt: 0.2911153733730316\n",
      "epocht 14, batch_num 1400, step 537081, time: 53.71833038330078 s, accu: 0.8632861375808716, loss_yt: 0.1103631779551506\n",
      "epocht 14, batch_num 1600, step 537281, time: 61.30607724189758 s, accu: 0.8632863163948059, loss_yt: 0.16347460448741913\n",
      "epocht 14, batch_num 1800, step 537481, time: 68.84192204475403 s, accu: 0.8632869124412537, loss_yt: 0.1590421199798584\n",
      "epocht 14, batch_num 2000, step 537681, time: 76.81758832931519 s, accu: 0.8632859587669373, loss_yt: 0.30504119396209717\n",
      "epocht 14, batch_num 2200, step 537881, time: 84.47408318519592 s, accu: 0.8632869124412537, loss_yt: 0.23558031022548676\n",
      "epocht 14, batch_num 2400, step 538081, time: 92.12163376808167 s, accu: 0.8632879257202148, loss_yt: 0.28133392333984375\n",
      "epocht 14, batch_num 2600, step 538281, time: 99.85595035552979 s, accu: 0.8632862567901611, loss_yt: 0.5054190754890442\n",
      "epocht 14, batch_num 2800, step 538481, time: 107.29109048843384 s, accu: 0.8632877469062805, loss_yt: 0.4856271743774414\n",
      "epocht 14, batch_num 3000, step 538681, time: 114.871830701828 s, accu: 0.8632882237434387, loss_yt: 0.285350501537323\n",
      "epocht 14, batch_num 3200, step 538881, time: 122.39072918891907 s, accu: 0.8632882237434387, loss_yt: 0.2713101804256439\n",
      "epocht 14, batch_num 3400, step 539081, time: 129.9883770942688 s, accu: 0.8632872104644775, loss_yt: 0.3245300352573395\n",
      "epocht 14, batch_num 3600, step 539281, time: 137.68778705596924 s, accu: 0.8632866144180298, loss_yt: 0.36394059658050537\n",
      "epocht 14, batch_num 3800, step 539481, time: 145.42809009552002 s, accu: 0.8632869720458984, loss_yt: 0.3773929476737976\n",
      "epocht 14, batch_num 4000, step 539681, time: 152.98488855361938 s, accu: 0.8632869720458984, loss_yt: 0.30356094241142273\n",
      "epocht 14, batch_num 4200, step 539881, time: 160.41102647781372 s, accu: 0.8632877469062805, loss_yt: 0.29897060990333557\n",
      "epocht 14, batch_num 4400, step 540081, time: 168.07056975364685 s, accu: 0.8632881045341492, loss_yt: 0.23494812846183777\n",
      "epocht 14, batch_num 4600, step 540281, time: 175.50270628929138 s, accu: 0.8632901906967163, loss_yt: 0.2912046015262604\n",
      "epocht 14, batch_num 4800, step 540481, time: 183.0146200656891 s, accu: 0.8632904887199402, loss_yt: 0.32040074467658997\n",
      "epocht 14, batch_num 5000, step 540681, time: 190.73294305801392 s, accu: 0.8632894158363342, loss_yt: 0.3229011297225952\n",
      "epocht 14, batch_num 5200, step 540881, time: 198.34359669685364 s, accu: 0.8632912635803223, loss_yt: 0.30226802825927734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 14, batch_num 5400, step 541081, time: 205.9742214679718 s, accu: 0.8632930517196655, loss_yt: 0.31911420822143555\n",
      "epocht 14, batch_num 5600, step 541281, time: 213.80426025390625 s, accu: 0.8632959127426147, loss_yt: 0.24825483560562134\n",
      "epocht 14, batch_num 5800, step 541481, time: 221.23039388656616 s, accu: 0.8632975816726685, loss_yt: 0.3083970844745636\n",
      "epocht 14, batch_num 6000, step 541681, time: 228.97771310806274 s, accu: 0.863296389579773, loss_yt: 0.28879988193511963\n",
      "epocht 14, batch_num 6200, step 541881, time: 236.58837366104126 s, accu: 0.8632951378822327, loss_yt: 0.2586694657802582\n",
      "epocht 14, batch_num 6400, step 542081, time: 244.35865950584412 s, accu: 0.8632941842079163, loss_yt: 0.4128219485282898\n",
      "epocht 14, batch_num 6600, step 542281, time: 251.88254022598267 s, accu: 0.8632941842079163, loss_yt: 0.3396381139755249\n",
      "epocht 14, batch_num 6800, step 542481, time: 259.5041596889496 s, accu: 0.8632948398590088, loss_yt: 0.263528436422348\n",
      "epocht 14, batch_num 7000, step 542681, time: 267.0170753002167 s, accu: 0.86329585313797, loss_yt: 0.26442575454711914\n",
      "epocht 14, batch_num 7200, step 542881, time: 274.37938356399536 s, accu: 0.8632969260215759, loss_yt: 0.31570693850517273\n",
      "epocht 14, batch_num 7400, step 543081, time: 281.9561240673065 s, accu: 0.8632973432540894, loss_yt: 0.2781476080417633\n",
      "iter_validnum 1860\n",
      "epochv 14, step 543120, stop_n 0, time: 335.69442534446716 s, accu_va: 0.8632999674927804, loss_yv: 0.2975670666263629\n",
      "iter_trainnum 7440\n",
      "epocht 14, batch_num 0, step 543121, time: 0.45478391647338867 s, accu: 0.8633023500442505, loss_yt: 0.27217262983322144\n",
      "epocht 14, batch_num 200, step 543321, time: 8.020555019378662 s, accu: 0.863304078578949, loss_yt: 0.1243763342499733\n",
      "epocht 14, batch_num 400, step 543521, time: 15.59330415725708 s, accu: 0.863305926322937, loss_yt: 0.19590942561626434\n",
      "epocht 14, batch_num 600, step 543721, time: 23.269823789596558 s, accu: 0.8633052110671997, loss_yt: 0.39738330245018005\n",
      "epocht 14, batch_num 800, step 543921, time: 30.831555604934692 s, accu: 0.8633028864860535, loss_yt: 0.34334129095077515\n",
      "epocht 14, batch_num 1000, step 544121, time: 38.32052993774414 s, accu: 0.8633013963699341, loss_yt: 0.2792629599571228\n",
      "epocht 14, batch_num 1200, step 544321, time: 45.83147835731506 s, accu: 0.863301694393158, loss_yt: 0.3340051770210266\n",
      "epocht 14, batch_num 1400, step 544521, time: 53.3274028301239 s, accu: 0.863303005695343, loss_yt: 0.3991113603115082\n",
      "epocht 14, batch_num 1600, step 544721, time: 61.1674370765686 s, accu: 0.8633025288581848, loss_yt: 0.16325406730175018\n",
      "epocht 14, batch_num 1800, step 544921, time: 68.74218249320984 s, accu: 0.8633010983467102, loss_yt: 0.22281453013420105\n",
      "epocht 14, batch_num 2000, step 545121, time: 76.48148918151855 s, accu: 0.8633024096488953, loss_yt: 0.40267062187194824\n",
      "epocht 14, batch_num 2200, step 545321, time: 84.05224275588989 s, accu: 0.8633006811141968, loss_yt: 0.21248698234558105\n",
      "epocht 14, batch_num 2400, step 545521, time: 91.39363646507263 s, accu: 0.8632994294166565, loss_yt: 0.16971896588802338\n",
      "epocht 14, batch_num 2600, step 545721, time: 99.27254366874695 s, accu: 0.8633005619049072, loss_yt: 0.1402939260005951\n",
      "epocht 14, batch_num 2800, step 545921, time: 106.80643057823181 s, accu: 0.8633020520210266, loss_yt: 0.2493218183517456\n",
      "epocht 14, batch_num 3000, step 546121, time: 114.45195245742798 s, accu: 0.86330246925354, loss_yt: 0.14028875529766083\n",
      "epocht 14, batch_num 3200, step 546321, time: 121.99183511734009 s, accu: 0.8633014559745789, loss_yt: 0.12382734566926956\n",
      "epocht 14, batch_num 3400, step 546521, time: 129.84080982208252 s, accu: 0.8633002638816833, loss_yt: 0.5027766823768616\n",
      "epocht 14, batch_num 3600, step 546721, time: 137.17918181419373 s, accu: 0.8633023500442505, loss_yt: 0.17641285061836243\n",
      "epocht 14, batch_num 3800, step 546921, time: 144.66516399383545 s, accu: 0.8633041381835938, loss_yt: 0.508027195930481\n",
      "epocht 14, batch_num 4000, step 547121, time: 152.22996735572815 s, accu: 0.8633064031600952, loss_yt: 0.5183243751525879\n",
      "epocht 14, batch_num 4200, step 547321, time: 159.7468400001526 s, accu: 0.863308310508728, loss_yt: 0.22566576302051544\n",
      "epocht 14, batch_num 4400, step 547521, time: 167.17596769332886 s, accu: 0.8633078932762146, loss_yt: 0.35057222843170166\n",
      "epocht 14, batch_num 4600, step 547721, time: 174.69685769081116 s, accu: 0.8633069396018982, loss_yt: 0.16765189170837402\n",
      "epocht 14, batch_num 4800, step 547921, time: 182.45311617851257 s, accu: 0.8633078932762146, loss_yt: 0.3123624920845032\n",
      "epocht 14, batch_num 5000, step 548121, time: 190.04784274101257 s, accu: 0.8633078336715698, loss_yt: 0.25302574038505554\n",
      "epocht 14, batch_num 5200, step 548321, time: 197.49095916748047 s, accu: 0.8633076548576355, loss_yt: 0.21134160459041595\n",
      "epocht 14, batch_num 5400, step 548521, time: 204.86322021484375 s, accu: 0.8633097410202026, loss_yt: 0.21159417927265167\n",
      "epocht 14, batch_num 5600, step 548721, time: 212.71718978881836 s, accu: 0.8633095026016235, loss_yt: 0.4995938539505005\n",
      "epocht 14, batch_num 5800, step 548921, time: 220.3647494316101 s, accu: 0.8633100986480713, loss_yt: 0.27988582849502563\n",
      "epocht 14, batch_num 6000, step 549121, time: 227.9704351425171 s, accu: 0.8633092045783997, loss_yt: 0.38057637214660645\n",
      "epocht 14, batch_num 6200, step 549321, time: 236.00592160224915 s, accu: 0.8633091449737549, loss_yt: 0.24697677791118622\n",
      "epocht 14, batch_num 6400, step 549521, time: 243.4679617881775 s, accu: 0.8633099794387817, loss_yt: 0.2471468597650528\n",
      "epocht 14, batch_num 6600, step 549721, time: 251.10952925682068 s, accu: 0.8633096814155579, loss_yt: 0.2697538137435913\n",
      "epocht 14, batch_num 6800, step 549921, time: 258.8189129829407 s, accu: 0.8633100986480713, loss_yt: 0.14881034195423126\n",
      "epocht 14, batch_num 7000, step 550121, time: 266.3537640571594 s, accu: 0.8633108139038086, loss_yt: 0.16551481187343597\n",
      "epocht 14, batch_num 7200, step 550321, time: 274.2596244812012 s, accu: 0.8633109331130981, loss_yt: 0.29954561591148376\n",
      "epocht 14, batch_num 7400, step 550521, time: 282.0049395561218 s, accu: 0.8633114099502563, loss_yt: 0.21247509121894836\n",
      "iter_validnum 1860\n",
      "epochv 14, step 550560, stop_n 0, time: 335.6863956451416 s, accu_va: 0.863314750598323, loss_yv: 0.298192843598544\n",
      "iter_trainnum 7440\n",
      "epocht 14, batch_num 0, step 550561, time: 0.34604620933532715 s, accu: 0.8633174300193787, loss_yt: 0.32222822308540344\n",
      "epocht 14, batch_num 200, step 550761, time: 7.812119722366333 s, accu: 0.8633171916007996, loss_yt: 0.5703802704811096\n",
      "epocht 14, batch_num 400, step 550961, time: 15.37286639213562 s, accu: 0.8633193969726562, loss_yt: 0.26483187079429626\n",
      "epocht 14, batch_num 600, step 551161, time: 23.14707612991333 s, accu: 0.8633183240890503, loss_yt: 0.24777443706989288\n",
      "epocht 14, batch_num 800, step 551361, time: 31.134718894958496 s, accu: 0.8633190393447876, loss_yt: 0.5841803550720215\n",
      "epocht 14, batch_num 1000, step 551561, time: 38.57282829284668 s, accu: 0.8633213043212891, loss_yt: 0.3160432279109955\n",
      "epocht 14, batch_num 1200, step 551761, time: 46.05485415458679 s, accu: 0.8633216619491577, loss_yt: 0.21610353887081146\n",
      "epocht 14, batch_num 1400, step 551961, time: 53.663498878479004 s, accu: 0.8633215427398682, loss_yt: 0.2365746647119522\n",
      "epocht 14, batch_num 1600, step 552161, time: 61.37684917449951 s, accu: 0.8633215427398682, loss_yt: 0.25453823804855347\n",
      "epocht 14, batch_num 1800, step 552361, time: 69.16003799438477 s, accu: 0.8633213639259338, loss_yt: 0.31854209303855896\n",
      "epocht 14, batch_num 2000, step 552561, time: 76.86047792434692 s, accu: 0.8633204698562622, loss_yt: 0.24860820174217224\n",
      "epocht 14, batch_num 2200, step 552761, time: 84.56787323951721 s, accu: 0.8633226156234741, loss_yt: 0.47671622037887573\n",
      "epocht 14, batch_num 2400, step 552961, time: 92.38396859169006 s, accu: 0.863323450088501, loss_yt: 0.3256615102291107\n",
      "epocht 14, batch_num 2600, step 553161, time: 99.76918745040894 s, accu: 0.863325297832489, loss_yt: 0.3243148922920227\n",
      "epocht 14, batch_num 2800, step 553361, time: 107.46763110160828 s, accu: 0.8633253574371338, loss_yt: 0.24402853846549988\n",
      "epocht 14, batch_num 3000, step 553561, time: 115.0513219833374 s, accu: 0.8633260726928711, loss_yt: 0.2188555747270584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 14, batch_num 3200, step 553761, time: 122.44953894615173 s, accu: 0.8633272051811218, loss_yt: 0.38790473341941833\n",
      "epocht 14, batch_num 3400, step 553961, time: 130.0192973613739 s, accu: 0.8633255958557129, loss_yt: 0.3947885036468506\n",
      "epocht 14, batch_num 3600, step 554161, time: 137.70576906204224 s, accu: 0.8633266091346741, loss_yt: 0.42786917090415955\n",
      "epocht 14, batch_num 3800, step 554361, time: 145.73826456069946 s, accu: 0.8633222579956055, loss_yt: 0.2983536720275879\n",
      "epocht 14, batch_num 4000, step 554561, time: 153.40476393699646 s, accu: 0.8633217811584473, loss_yt: 0.25652363896369934\n",
      "epocht 14, batch_num 4200, step 554761, time: 160.9585678577423 s, accu: 0.8633233308792114, loss_yt: 0.3927278220653534\n",
      "epocht 14, batch_num 4400, step 554961, time: 168.4964096546173 s, accu: 0.8633244633674622, loss_yt: 0.2748730778694153\n",
      "epocht 14, batch_num 4600, step 555161, time: 175.9166042804718 s, accu: 0.8633240461349487, loss_yt: 0.343003511428833\n",
      "epocht 14, batch_num 4800, step 555361, time: 183.79652166366577 s, accu: 0.8633251190185547, loss_yt: 0.33237266540527344\n",
      "epocht 14, batch_num 5000, step 555561, time: 191.45501708984375 s, accu: 0.8633260726928711, loss_yt: 0.29752612113952637\n",
      "epocht 14, batch_num 5200, step 555761, time: 198.9380078315735 s, accu: 0.8633272051811218, loss_yt: 0.23948794603347778\n",
      "epocht 14, batch_num 5400, step 555961, time: 206.45693397521973 s, accu: 0.8633266687393188, loss_yt: 0.141879603266716\n",
      "epocht 14, batch_num 5600, step 556161, time: 214.2660219669342 s, accu: 0.8633279800415039, loss_yt: 0.28493404388427734\n",
      "epocht 14, batch_num 5800, step 556361, time: 221.84076523780823 s, accu: 0.8633285760879517, loss_yt: 0.15069809556007385\n",
      "epocht 14, batch_num 6000, step 556561, time: 229.44443345069885 s, accu: 0.8633266091346741, loss_yt: 0.775431752204895\n",
      "epocht 14, batch_num 6200, step 556761, time: 237.11791491508484 s, accu: 0.8633247017860413, loss_yt: 0.1356729418039322\n",
      "epocht 14, batch_num 6400, step 556961, time: 244.8632366657257 s, accu: 0.8633253574371338, loss_yt: 0.3533828854560852\n",
      "epocht 14, batch_num 6600, step 557161, time: 252.18263292312622 s, accu: 0.8633249998092651, loss_yt: 0.28428447246551514\n",
      "epocht 14, batch_num 6800, step 557361, time: 260.07951307296753 s, accu: 0.8633251190185547, loss_yt: 0.301830917596817\n",
      "epocht 14, batch_num 7000, step 557561, time: 267.77294087409973 s, accu: 0.8633266687393188, loss_yt: 0.22406943142414093\n",
      "epocht 14, batch_num 7200, step 557761, time: 275.31278109550476 s, accu: 0.8633256554603577, loss_yt: 0.2762693762779236\n",
      "epocht 14, batch_num 7400, step 557961, time: 283.0042374134064 s, accu: 0.8633263111114502, loss_yt: 0.27526310086250305\n",
      "iter_validnum 1860\n",
      "epochv 14, step 558000, stop_n 0, time: 336.76246094703674 s, accu_va: 0.8633281023912532, loss_yv: 0.2989016575398304\n",
      "iter_trainnum 7440\n",
      "epocht 15, batch_num 0, step 558001, time: 0.44879889488220215 s, accu: 0.8633313179016113, loss_yt: 0.27365875244140625\n",
      "epocht 15, batch_num 200, step 558201, time: 7.874974012374878 s, accu: 0.8633324503898621, loss_yt: 0.31956106424331665\n",
      "epocht 15, batch_num 400, step 558401, time: 15.536486625671387 s, accu: 0.8633340001106262, loss_yt: 0.21751995384693146\n",
      "epocht 15, batch_num 600, step 558601, time: 23.131178617477417 s, accu: 0.8633352518081665, loss_yt: 0.25833576917648315\n",
      "epocht 15, batch_num 800, step 558801, time: 30.59319758415222 s, accu: 0.8633379936218262, loss_yt: 0.43023061752319336\n",
      "epocht 15, batch_num 1000, step 559001, time: 38.029335737228394 s, accu: 0.8633385896682739, loss_yt: 0.23356494307518005\n",
      "epocht 15, batch_num 1200, step 559201, time: 45.664891958236694 s, accu: 0.8633394837379456, loss_yt: 0.36110377311706543\n",
      "epocht 15, batch_num 1400, step 559401, time: 53.18976974487305 s, accu: 0.8633416891098022, loss_yt: 0.3095816373825073\n",
      "epocht 15, batch_num 1600, step 559601, time: 60.51717472076416 s, accu: 0.8633430600166321, loss_yt: 0.3169279992580414\n",
      "epocht 15, batch_num 1800, step 559801, time: 68.25349354743958 s, accu: 0.863342821598053, loss_yt: 0.25065961480140686\n",
      "epocht 15, batch_num 2000, step 560001, time: 75.97384309768677 s, accu: 0.8633438348770142, loss_yt: 0.70868319272995\n",
      "epocht 15, batch_num 2200, step 560201, time: 83.55158042907715 s, accu: 0.8633437156677246, loss_yt: 0.41875120997428894\n",
      "epocht 15, batch_num 2400, step 560401, time: 91.0545175075531 s, accu: 0.8633434176445007, loss_yt: 0.5038262605667114\n",
      "epocht 15, batch_num 2600, step 560601, time: 98.64821434020996 s, accu: 0.8633434176445007, loss_yt: 0.21800225973129272\n",
      "epocht 15, batch_num 2800, step 560801, time: 105.98359751701355 s, accu: 0.8633446097373962, loss_yt: 0.16537413001060486\n",
      "epocht 15, batch_num 3000, step 561001, time: 113.57729172706604 s, accu: 0.8633437156677246, loss_yt: 0.2682700753211975\n",
      "epocht 15, batch_num 3200, step 561201, time: 121.33754110336304 s, accu: 0.8633435964584351, loss_yt: 0.25545090436935425\n",
      "epocht 15, batch_num 3400, step 561401, time: 129.2463927268982 s, accu: 0.8633432388305664, loss_yt: 0.2754717171192169\n",
      "epocht 15, batch_num 3600, step 561601, time: 136.83509945869446 s, accu: 0.863343358039856, loss_yt: 0.2575341761112213\n",
      "epocht 15, batch_num 3800, step 561801, time: 144.26323819160461 s, accu: 0.8633450865745544, loss_yt: 0.35141605138778687\n",
      "epocht 15, batch_num 4000, step 562001, time: 151.71933221817017 s, accu: 0.8633458614349365, loss_yt: 0.3827058970928192\n",
      "epocht 15, batch_num 4200, step 562201, time: 159.15342044830322 s, accu: 0.8633472919464111, loss_yt: 0.32431328296661377\n",
      "epocht 15, batch_num 4400, step 562401, time: 167.00941276550293 s, accu: 0.8633467555046082, loss_yt: 0.26447421312332153\n",
      "epocht 15, batch_num 4600, step 562601, time: 174.49738907814026 s, accu: 0.86334627866745, loss_yt: 0.31525182723999023\n",
      "epocht 15, batch_num 4800, step 562801, time: 181.99633836746216 s, accu: 0.8633475303649902, loss_yt: 0.32058969140052795\n",
      "epocht 15, batch_num 5000, step 563001, time: 189.3805911540985 s, accu: 0.8633491396903992, loss_yt: 0.25078916549682617\n",
      "epocht 15, batch_num 5200, step 563201, time: 196.83266592025757 s, accu: 0.8633502125740051, loss_yt: 0.27790066599845886\n",
      "epocht 15, batch_num 5400, step 563401, time: 204.3934826850891 s, accu: 0.8633497357368469, loss_yt: 0.2706792950630188\n",
      "epocht 15, batch_num 5600, step 563601, time: 211.9033648967743 s, accu: 0.8633490800857544, loss_yt: 0.28070899844169617\n",
      "epocht 15, batch_num 5800, step 563801, time: 219.52601504325867 s, accu: 0.8633508086204529, loss_yt: 0.26084965467453003\n",
      "epocht 15, batch_num 6000, step 564001, time: 227.70910048484802 s, accu: 0.8633498549461365, loss_yt: 0.46480610966682434\n",
      "epocht 15, batch_num 6200, step 564201, time: 235.42646408081055 s, accu: 0.8633502125740051, loss_yt: 0.2661053240299225\n",
      "epocht 15, batch_num 6400, step 564401, time: 243.21365904808044 s, accu: 0.8633487820625305, loss_yt: 0.3218206465244293\n",
      "epocht 15, batch_num 6600, step 564601, time: 250.8871247768402 s, accu: 0.8633469343185425, loss_yt: 0.29193437099456787\n",
      "epocht 15, batch_num 6800, step 564801, time: 258.43494057655334 s, accu: 0.8633471727371216, loss_yt: 0.4472983479499817\n",
      "epocht 15, batch_num 7000, step 565001, time: 266.16827034950256 s, accu: 0.8633456230163574, loss_yt: 0.23920020461082458\n",
      "epocht 15, batch_num 7200, step 565201, time: 273.77392172813416 s, accu: 0.863345205783844, loss_yt: 0.2873418629169464\n",
      "epocht 15, batch_num 7400, step 565401, time: 281.63893008232117 s, accu: 0.863345742225647, loss_yt: 0.2442387491464615\n",
      "iter_validnum 1860\n",
      "epochv 15, step 565440, stop_n 0, time: 335.5886344909668 s, accu_va: 0.8633422976219526, loss_yv: 0.3013410545565108\n",
      "iter_trainnum 7440\n",
      "epocht 15, batch_num 0, step 565441, time: 0.3440864086151123 s, accu: 0.8633452653884888, loss_yt: 0.12509483098983765\n",
      "epocht 15, batch_num 200, step 565641, time: 8.045491695404053 s, accu: 0.8633446097373962, loss_yt: 0.14023981988430023\n",
      "epocht 15, batch_num 400, step 565841, time: 15.77481746673584 s, accu: 0.8633440732955933, loss_yt: 0.25079789757728577\n",
      "epocht 15, batch_num 600, step 566041, time: 23.292745113372803 s, accu: 0.8633440732955933, loss_yt: 0.51027512550354\n",
      "epocht 15, batch_num 800, step 566241, time: 30.82261347770691 s, accu: 0.8633441925048828, loss_yt: 0.26613542437553406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 15, batch_num 1000, step 566441, time: 38.39236497879028 s, accu: 0.8633439540863037, loss_yt: 0.17818228900432587\n",
      "epocht 15, batch_num 1200, step 566641, time: 45.941152572631836 s, accu: 0.8633438944816589, loss_yt: 0.2990649938583374\n",
      "epocht 15, batch_num 1400, step 566841, time: 53.409183740615845 s, accu: 0.8633453249931335, loss_yt: 0.2547962963581085\n",
      "epocht 15, batch_num 1600, step 567041, time: 61.10264444351196 s, accu: 0.863345205783844, loss_yt: 0.2918175458908081\n",
      "epocht 15, batch_num 1800, step 567241, time: 69.0174789428711 s, accu: 0.8633468151092529, loss_yt: 0.49383270740509033\n",
      "epocht 15, batch_num 2000, step 567441, time: 76.66798973083496 s, accu: 0.8633474111557007, loss_yt: 0.4281158745288849\n",
      "epocht 15, batch_num 2200, step 567641, time: 84.35842370986938 s, accu: 0.8633466362953186, loss_yt: 0.17640900611877441\n",
      "epocht 15, batch_num 2400, step 567841, time: 92.03190732002258 s, accu: 0.8633456230163574, loss_yt: 0.2576967775821686\n",
      "epocht 15, batch_num 2600, step 568041, time: 99.75824427604675 s, accu: 0.8633447885513306, loss_yt: 0.3119851052761078\n",
      "epocht 15, batch_num 2800, step 568241, time: 107.34897971153259 s, accu: 0.863347053527832, loss_yt: 0.25271502137184143\n",
      "epocht 15, batch_num 3000, step 568441, time: 114.92967867851257 s, accu: 0.8633488416671753, loss_yt: 0.3495136499404907\n",
      "epocht 15, batch_num 3200, step 568641, time: 122.50644826889038 s, accu: 0.863348126411438, loss_yt: 0.2738828957080841\n",
      "epocht 15, batch_num 3400, step 568841, time: 130.224778175354 s, accu: 0.8633465766906738, loss_yt: 0.38560548424720764\n",
      "epocht 15, batch_num 3600, step 569041, time: 137.72671556472778 s, accu: 0.8633490800857544, loss_yt: 0.3129858672618866\n",
      "epocht 15, batch_num 3800, step 569241, time: 145.19175481796265 s, accu: 0.8633500337600708, loss_yt: 0.3088437616825104\n",
      "epocht 15, batch_num 4000, step 569441, time: 152.97793579101562 s, accu: 0.8633489608764648, loss_yt: 0.18120495975017548\n",
      "epocht 15, batch_num 4200, step 569641, time: 160.54669570922852 s, accu: 0.8633497953414917, loss_yt: 0.2925397753715515\n",
      "epocht 15, batch_num 4400, step 569841, time: 168.0965392589569 s, accu: 0.863349199295044, loss_yt: 0.18526019155979156\n",
      "epocht 15, batch_num 4600, step 570041, time: 175.71616458892822 s, accu: 0.8633508682250977, loss_yt: 0.24030296504497528\n",
      "epocht 15, batch_num 4800, step 570241, time: 183.46944761276245 s, accu: 0.8633506894111633, loss_yt: 0.2487594187259674\n",
      "epocht 15, batch_num 5000, step 570441, time: 191.02023458480835 s, accu: 0.8633512854576111, loss_yt: 0.4872896075248718\n",
      "epocht 15, batch_num 5200, step 570641, time: 198.495219707489 s, accu: 0.8633519411087036, loss_yt: 0.32547998428344727\n",
      "epocht 15, batch_num 5400, step 570841, time: 206.2066044807434 s, accu: 0.863350510597229, loss_yt: 0.29863792657852173\n",
      "epocht 15, batch_num 5600, step 571041, time: 213.66669487953186 s, accu: 0.8633511066436768, loss_yt: 0.34798258543014526\n",
      "epocht 15, batch_num 5800, step 571241, time: 221.2024998664856 s, accu: 0.8633514046669006, loss_yt: 0.14853240549564362\n",
      "epocht 15, batch_num 6000, step 571441, time: 228.61467909812927 s, accu: 0.8633542656898499, loss_yt: 0.2543359100818634\n",
      "epocht 15, batch_num 6200, step 571641, time: 236.04384922981262 s, accu: 0.8633560538291931, loss_yt: 0.2973566949367523\n",
      "epocht 15, batch_num 6400, step 571841, time: 243.6085922718048 s, accu: 0.8633546233177185, loss_yt: 0.28861796855926514\n",
      "epocht 15, batch_num 6600, step 572041, time: 251.15341019630432 s, accu: 0.8633526563644409, loss_yt: 0.20326966047286987\n",
      "epocht 15, batch_num 6800, step 572241, time: 258.98048639297485 s, accu: 0.8633562326431274, loss_yt: 0.1666513979434967\n",
      "epocht 15, batch_num 7000, step 572441, time: 266.5661962032318 s, accu: 0.8633572459220886, loss_yt: 0.18176725506782532\n",
      "epocht 15, batch_num 7200, step 572641, time: 274.18781566619873 s, accu: 0.863358199596405, loss_yt: 0.3206779658794403\n",
      "epocht 15, batch_num 7400, step 572841, time: 281.64786767959595 s, accu: 0.8633594512939453, loss_yt: 0.11999955028295517\n",
      "iter_validnum 1860\n",
      "epochv 15, step 572880, stop_n 0, time: 335.20864820480347 s, accu_va: 0.8633589140189591, loss_yv: 0.3027434881816628\n",
      "iter_trainnum 7440\n",
      "epocht 15, batch_num 0, step 572881, time: 0.23836064338684082 s, accu: 0.8633590936660767, loss_yt: 0.3311198949813843\n",
      "epocht 15, batch_num 200, step 573081, time: 7.839034795761108 s, accu: 0.8633605241775513, loss_yt: 0.5675219893455505\n",
      "epocht 15, batch_num 400, step 573281, time: 15.361951112747192 s, accu: 0.8633596301078796, loss_yt: 0.40724244713783264\n",
      "epocht 15, batch_num 600, step 573481, time: 22.804019927978516 s, accu: 0.8633598685264587, loss_yt: 0.2685737609863281\n",
      "epocht 15, batch_num 800, step 573681, time: 30.459579467773438 s, accu: 0.8633600473403931, loss_yt: 0.33196955919265747\n",
      "epocht 15, batch_num 1000, step 573881, time: 37.86279559135437 s, accu: 0.8633598685264587, loss_yt: 0.21075046062469482\n",
      "epocht 15, batch_num 1200, step 574081, time: 45.644967555999756 s, accu: 0.8633589744567871, loss_yt: 0.2796592116355896\n",
      "epocht 15, batch_num 1400, step 574281, time: 52.99827790260315 s, accu: 0.8633602261543274, loss_yt: 0.32745927572250366\n",
      "epocht 15, batch_num 1600, step 574481, time: 60.74356746673584 s, accu: 0.8633613586425781, loss_yt: 0.3152388036251068\n",
      "epocht 15, batch_num 1800, step 574681, time: 68.15677642822266 s, accu: 0.8633617758750916, loss_yt: 0.3015722632408142\n",
      "epocht 15, batch_num 2000, step 574881, time: 75.88906812667847 s, accu: 0.863364577293396, loss_yt: 0.40019360184669495\n",
      "epocht 15, batch_num 2200, step 575081, time: 83.65234184265137 s, accu: 0.8633631467819214, loss_yt: 0.27234816551208496\n",
      "epocht 15, batch_num 2400, step 575281, time: 91.27099108695984 s, accu: 0.8633643388748169, loss_yt: 0.14102290570735931\n",
      "epocht 15, batch_num 2600, step 575481, time: 99.07806015014648 s, accu: 0.8633646965026855, loss_yt: 0.40007737278938293\n",
      "epocht 15, batch_num 2800, step 575681, time: 106.53614926338196 s, accu: 0.8633663654327393, loss_yt: 0.29722753167152405\n",
      "epocht 15, batch_num 3000, step 575881, time: 114.1228621006012 s, accu: 0.8633666634559631, loss_yt: 0.4433453679084778\n",
      "epocht 15, batch_num 3200, step 576081, time: 121.45824718475342 s, accu: 0.8633682727813721, loss_yt: 0.40206703543663025\n",
      "epocht 15, batch_num 3400, step 576281, time: 129.14270424842834 s, accu: 0.8633674383163452, loss_yt: 0.25397542119026184\n",
      "epocht 15, batch_num 3600, step 576481, time: 136.9657485485077 s, accu: 0.8633666634559631, loss_yt: 0.3393023908138275\n",
      "epocht 15, batch_num 3800, step 576681, time: 144.4038577079773 s, accu: 0.863366961479187, loss_yt: 0.2822374105453491\n",
      "epocht 15, batch_num 4000, step 576881, time: 152.17108845710754 s, accu: 0.8633670806884766, loss_yt: 0.32790327072143555\n",
      "epocht 15, batch_num 4200, step 577081, time: 159.49849462509155 s, accu: 0.8633683919906616, loss_yt: 0.38508522510528564\n",
      "epocht 15, batch_num 4400, step 577281, time: 167.2248661518097 s, accu: 0.8633694052696228, loss_yt: 0.20144394040107727\n",
      "epocht 15, batch_num 4600, step 577481, time: 174.6689314842224 s, accu: 0.8633708357810974, loss_yt: 0.23217175900936127\n",
      "epocht 15, batch_num 4800, step 577681, time: 182.33246779441833 s, accu: 0.8633719086647034, loss_yt: 0.3066290616989136\n",
      "epocht 15, batch_num 5000, step 577881, time: 190.01589179039001 s, accu: 0.8633708357810974, loss_yt: 0.1544465571641922\n",
      "epocht 15, batch_num 5200, step 578081, time: 197.76317429542542 s, accu: 0.8633711338043213, loss_yt: 0.21817369759082794\n",
      "epocht 15, batch_num 5400, step 578281, time: 205.41870307922363 s, accu: 0.8633702397346497, loss_yt: 0.26036348938941956\n",
      "epocht 15, batch_num 5600, step 578481, time: 213.14106225967407 s, accu: 0.8633682727813721, loss_yt: 0.5813755989074707\n",
      "epocht 15, batch_num 5800, step 578681, time: 220.82849621772766 s, accu: 0.8633661270141602, loss_yt: 0.1672833114862442\n",
      "epocht 15, batch_num 6000, step 578881, time: 228.304505109787 s, accu: 0.8633672595024109, loss_yt: 0.1451520472764969\n",
      "epocht 15, batch_num 6200, step 579081, time: 236.11860990524292 s, accu: 0.8633676171302795, loss_yt: 0.3623232841491699\n",
      "epocht 15, batch_num 6400, step 579281, time: 243.74721217155457 s, accu: 0.8633686304092407, loss_yt: 0.4030507802963257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 15, batch_num 6600, step 579481, time: 251.33297109603882 s, accu: 0.8633691072463989, loss_yt: 0.40099507570266724\n",
      "epocht 15, batch_num 6800, step 579681, time: 258.92467188835144 s, accu: 0.863369882106781, loss_yt: 0.14308559894561768\n",
      "epocht 15, batch_num 7000, step 579881, time: 266.61905241012573 s, accu: 0.8633713722229004, loss_yt: 0.2616595923900604\n",
      "epocht 15, batch_num 7200, step 580081, time: 274.34838247299194 s, accu: 0.8633710145950317, loss_yt: 0.39450889825820923\n",
      "epocht 15, batch_num 7400, step 580281, time: 281.8613214492798 s, accu: 0.8633696436882019, loss_yt: 0.2806045114994049\n",
      "iter_validnum 1860\n",
      "epochv 15, step 580320, stop_n 1, time: 336.1491265296936 s, accu_va: 0.8633715860946204, loss_yv: 0.2976035030538677\n",
      "iter_trainnum 7440\n",
      "epocht 15, batch_num 0, step 580321, time: 0.44085264205932617 s, accu: 0.8633741140365601, loss_yt: 0.2711307108402252\n",
      "epocht 15, batch_num 200, step 580521, time: 8.262903213500977 s, accu: 0.8633748292922974, loss_yt: 0.2945939302444458\n",
      "epocht 15, batch_num 400, step 580721, time: 15.768831729888916 s, accu: 0.8633765578269958, loss_yt: 0.3766464293003082\n",
      "epocht 15, batch_num 600, step 580921, time: 23.424386978149414 s, accu: 0.8633776903152466, loss_yt: 0.10167641192674637\n",
      "epocht 15, batch_num 800, step 581121, time: 30.837539196014404 s, accu: 0.8633780479431152, loss_yt: 0.2684924900531769\n",
      "epocht 15, batch_num 1000, step 581321, time: 38.251715898513794 s, accu: 0.8633790016174316, loss_yt: 0.373390793800354\n",
      "epocht 15, batch_num 1200, step 581521, time: 45.89427709579468 s, accu: 0.8633792400360107, loss_yt: 0.4828985333442688\n",
      "epocht 15, batch_num 1400, step 581721, time: 53.46805691719055 s, accu: 0.8633794188499451, loss_yt: 0.4878208637237549\n",
      "epocht 15, batch_num 1600, step 581921, time: 61.208669662475586 s, accu: 0.8633801937103271, loss_yt: 0.17504529654979706\n",
      "epocht 15, batch_num 1800, step 582121, time: 68.9658944606781 s, accu: 0.8633813261985779, loss_yt: 0.2192077934741974\n",
      "epocht 15, batch_num 2000, step 582321, time: 76.53665113449097 s, accu: 0.8633782267570496, loss_yt: 0.3776966631412506\n",
      "epocht 15, batch_num 2200, step 582521, time: 84.09045004844666 s, accu: 0.8633801341056824, loss_yt: 0.30031436681747437\n",
      "epocht 15, batch_num 2400, step 582721, time: 91.63228392601013 s, accu: 0.8633791208267212, loss_yt: 0.1382632702589035\n",
      "epocht 15, batch_num 2600, step 582921, time: 99.32272005081177 s, accu: 0.8633777499198914, loss_yt: 0.45600807666778564\n",
      "epocht 15, batch_num 2800, step 583121, time: 107.0410795211792 s, accu: 0.8633790612220764, loss_yt: 0.2973712980747223\n",
      "epocht 15, batch_num 3000, step 583321, time: 114.8122992515564 s, accu: 0.8633789420127869, loss_yt: 0.38630354404449463\n",
      "epocht 15, batch_num 3200, step 583521, time: 122.79894351959229 s, accu: 0.8633782267570496, loss_yt: 0.36929935216903687\n",
      "epocht 15, batch_num 3400, step 583721, time: 130.55923438072205 s, accu: 0.8633785843849182, loss_yt: 0.3000539243221283\n",
      "epocht 15, batch_num 3600, step 583921, time: 137.98134684562683 s, accu: 0.8633784651756287, loss_yt: 0.25585097074508667\n",
      "epocht 15, batch_num 3800, step 584121, time: 145.23494935035706 s, accu: 0.8633805513381958, loss_yt: 0.3249634802341461\n",
      "epocht 15, batch_num 4000, step 584321, time: 152.75384497642517 s, accu: 0.8633823990821838, loss_yt: 0.26367610692977905\n",
      "epocht 15, batch_num 4200, step 584521, time: 160.41140508651733 s, accu: 0.8633822798728943, loss_yt: 0.42791301012039185\n",
      "epocht 15, batch_num 4400, step 584721, time: 168.0878415107727 s, accu: 0.8633817434310913, loss_yt: 0.25500091910362244\n",
      "epocht 15, batch_num 4600, step 584921, time: 175.74240851402283 s, accu: 0.8633820414543152, loss_yt: 0.21220368146896362\n",
      "epocht 15, batch_num 4800, step 585121, time: 183.563462972641 s, accu: 0.8633828163146973, loss_yt: 0.375249445438385\n",
      "epocht 15, batch_num 5000, step 585321, time: 191.01557445526123 s, accu: 0.863379716873169, loss_yt: 0.3055155575275421\n",
      "epocht 15, batch_num 5200, step 585521, time: 198.5992512702942 s, accu: 0.8633803129196167, loss_yt: 0.14567162096500397\n",
      "epocht 15, batch_num 5400, step 585721, time: 206.25181579589844 s, accu: 0.8633795380592346, loss_yt: 0.6300104260444641\n",
      "epocht 15, batch_num 5600, step 585921, time: 214.0928213596344 s, accu: 0.8633775115013123, loss_yt: 0.3320735692977905\n",
      "epocht 15, batch_num 5800, step 586121, time: 221.68551874160767 s, accu: 0.8633784055709839, loss_yt: 0.31267279386520386\n",
      "epocht 15, batch_num 6000, step 586321, time: 229.29018354415894 s, accu: 0.8633792400360107, loss_yt: 0.26569631695747375\n",
      "epocht 15, batch_num 6200, step 586521, time: 236.91180324554443 s, accu: 0.8633807897567749, loss_yt: 0.4055534899234772\n",
      "epocht 15, batch_num 6400, step 586721, time: 244.455632686615 s, accu: 0.8633804321289062, loss_yt: 0.3069729208946228\n",
      "epocht 15, batch_num 6600, step 586921, time: 252.0373570919037 s, accu: 0.8633816242218018, loss_yt: 0.4228878617286682\n",
      "epocht 15, batch_num 6800, step 587121, time: 259.604124546051 s, accu: 0.8633816242218018, loss_yt: 0.16492082178592682\n",
      "epocht 15, batch_num 7000, step 587321, time: 267.27764105796814 s, accu: 0.8633812665939331, loss_yt: 0.28035494685173035\n",
      "epocht 15, batch_num 7200, step 587521, time: 274.73369884490967 s, accu: 0.8633818626403809, loss_yt: 0.413819819688797\n",
      "epocht 15, batch_num 7400, step 587721, time: 282.2834777832031 s, accu: 0.86338210105896, loss_yt: 0.268941730260849\n",
      "iter_validnum 1860\n",
      "epochv 15, step 587760, stop_n 2, time: 335.97291254997253 s, accu_va: 0.8633848924790659, loss_yv: 0.2975107668668673\n",
      "iter_trainnum 7440\n",
      "epocht 15, batch_num 0, step 587761, time: 0.33310937881469727 s, accu: 0.863387942314148, loss_yt: 0.18632523715496063\n",
      "epocht 15, batch_num 200, step 587961, time: 8.128265142440796 s, accu: 0.8633885383605957, loss_yt: 0.46374523639678955\n",
      "epocht 15, batch_num 400, step 588161, time: 15.70201325416565 s, accu: 0.8633896112442017, loss_yt: 0.268984317779541\n",
      "epocht 15, batch_num 600, step 588361, time: 23.553019285202026 s, accu: 0.8633886575698853, loss_yt: 0.2939833402633667\n",
      "epocht 15, batch_num 800, step 588561, time: 31.327231407165527 s, accu: 0.8633888959884644, loss_yt: 0.3111405372619629\n",
      "epocht 15, batch_num 1000, step 588761, time: 38.96082043647766 s, accu: 0.863389790058136, loss_yt: 0.14587455987930298\n",
      "epocht 15, batch_num 1200, step 588961, time: 46.64427328109741 s, accu: 0.8633899092674255, loss_yt: 0.24687394499778748\n",
      "epocht 15, batch_num 1400, step 589161, time: 54.15119934082031 s, accu: 0.8633915781974792, loss_yt: 0.276448518037796\n",
      "epocht 15, batch_num 1600, step 589361, time: 62.064072370529175 s, accu: 0.8633907437324524, loss_yt: 0.20879331231117249\n",
      "epocht 15, batch_num 1800, step 589561, time: 69.71159076690674 s, accu: 0.8633894920349121, loss_yt: 0.30552083253860474\n",
      "epocht 15, batch_num 2000, step 589761, time: 77.57257103919983 s, accu: 0.8633906245231628, loss_yt: 0.44973519444465637\n",
      "epocht 15, batch_num 2200, step 589961, time: 85.0126748085022 s, accu: 0.8633905053138733, loss_yt: 0.25071313977241516\n",
      "epocht 15, batch_num 2400, step 590161, time: 92.53655529022217 s, accu: 0.8633896112442017, loss_yt: 0.37345775961875916\n",
      "epocht 15, batch_num 2600, step 590361, time: 100.11129999160767 s, accu: 0.8633901476860046, loss_yt: 0.4035286009311676\n",
      "epocht 15, batch_num 2800, step 590561, time: 107.64519739151001 s, accu: 0.8633912801742554, loss_yt: 0.271584153175354\n",
      "epocht 15, batch_num 3000, step 590761, time: 115.44131016731262 s, accu: 0.8633925318717957, loss_yt: 0.4310532212257385\n",
      "epocht 15, batch_num 3200, step 590961, time: 123.01106786727905 s, accu: 0.8633919358253479, loss_yt: 0.47333383560180664\n",
      "epocht 15, batch_num 3400, step 591161, time: 130.5599172115326 s, accu: 0.8633929491043091, loss_yt: 0.4325180947780609\n",
      "epocht 15, batch_num 3600, step 591361, time: 138.51463508605957 s, accu: 0.8633947372436523, loss_yt: 0.23451365530490875\n",
      "epocht 15, batch_num 3800, step 591561, time: 146.07339692115784 s, accu: 0.863394021987915, loss_yt: 0.2914111912250519\n",
      "epocht 15, batch_num 4000, step 591761, time: 153.9782612323761 s, accu: 0.8633938431739807, loss_yt: 0.3128219544887543\n",
      "epocht 15, batch_num 4200, step 591961, time: 161.54602456092834 s, accu: 0.8633950352668762, loss_yt: 0.32648223638534546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 15, batch_num 4400, step 592161, time: 169.081871509552 s, accu: 0.8633947372436523, loss_yt: 0.30941975116729736\n",
      "epocht 15, batch_num 4600, step 592361, time: 176.65362453460693 s, accu: 0.8633957505226135, loss_yt: 0.24044017493724823\n",
      "epocht 15, batch_num 4800, step 592561, time: 184.39093661308289 s, accu: 0.8633939623832703, loss_yt: 0.45867279171943665\n",
      "epocht 15, batch_num 5000, step 592761, time: 192.1731255054474 s, accu: 0.8633931875228882, loss_yt: 0.2714821994304657\n",
      "epocht 15, batch_num 5200, step 592961, time: 199.90345454216003 s, accu: 0.8633934855461121, loss_yt: 0.4071679413318634\n",
      "epocht 15, batch_num 5400, step 593161, time: 207.70260310173035 s, accu: 0.8633959889411926, loss_yt: 0.2821810245513916\n",
      "epocht 15, batch_num 5600, step 593361, time: 215.32225465774536 s, accu: 0.8633962869644165, loss_yt: 0.3391161859035492\n",
      "epocht 15, batch_num 5800, step 593561, time: 223.09643530845642 s, accu: 0.8633965849876404, loss_yt: 0.32387372851371765\n",
      "epocht 15, batch_num 6000, step 593761, time: 230.78387904167175 s, accu: 0.8633965253829956, loss_yt: 0.5939954519271851\n",
      "epocht 15, batch_num 6200, step 593961, time: 238.5012423992157 s, accu: 0.863394021987915, loss_yt: 0.4640806019306183\n",
      "epocht 15, batch_num 6400, step 594161, time: 246.29340648651123 s, accu: 0.8633943796157837, loss_yt: 0.36535370349884033\n",
      "epocht 15, batch_num 6600, step 594361, time: 253.87214016914368 s, accu: 0.8633970618247986, loss_yt: 0.25400954484939575\n",
      "epocht 15, batch_num 6800, step 594561, time: 261.44991636276245 s, accu: 0.8633973598480225, loss_yt: 0.2794956862926483\n",
      "epocht 15, batch_num 7000, step 594761, time: 269.0236246585846 s, accu: 0.8633981347084045, loss_yt: 0.20661920309066772\n",
      "epocht 15, batch_num 7200, step 594961, time: 276.725031375885 s, accu: 0.8633967638015747, loss_yt: 0.31989485025405884\n",
      "epocht 15, batch_num 7400, step 595161, time: 284.4344651699066 s, accu: 0.8633975386619568, loss_yt: 0.18535184860229492\n",
      "iter_validnum 1860\n",
      "epochv 15, step 595200, stop_n 0, time: 338.13582468032837 s, accu_va: 0.8634000248485996, loss_yv: 0.2989735462292228\n",
      "iter_trainnum 7440\n",
      "epocht 16, batch_num 0, step 595201, time: 0.4507942199707031 s, accu: 0.8634017705917358, loss_yt: 0.28284594416618347\n",
      "epocht 16, batch_num 200, step 595401, time: 7.73830771446228 s, accu: 0.8634026646614075, loss_yt: 0.31334200501441956\n",
      "epocht 16, batch_num 400, step 595601, time: 15.380870819091797 s, accu: 0.8634042143821716, loss_yt: 0.12115023285150528\n",
      "epocht 16, batch_num 600, step 595801, time: 22.843914270401 s, accu: 0.8634054064750671, loss_yt: 0.36765003204345703\n",
      "epocht 16, batch_num 800, step 596001, time: 30.54535460472107 s, accu: 0.8634065389633179, loss_yt: 0.33260378241539\n",
      "epocht 16, batch_num 1000, step 596201, time: 38.27465224266052 s, accu: 0.8634081482887268, loss_yt: 0.1300181895494461\n",
      "epocht 16, batch_num 1200, step 596401, time: 45.82450795173645 s, accu: 0.8634079098701477, loss_yt: 0.2963716685771942\n",
      "epocht 16, batch_num 1400, step 596601, time: 53.53985905647278 s, accu: 0.8634082078933716, loss_yt: 0.32502132654190063\n",
      "epocht 16, batch_num 1600, step 596801, time: 61.043800592422485 s, accu: 0.8634083271026611, loss_yt: 0.3781058192253113\n",
      "epocht 16, batch_num 1800, step 597001, time: 68.66040110588074 s, accu: 0.863409698009491, loss_yt: 0.21656173467636108\n",
      "epocht 16, batch_num 2000, step 597201, time: 76.17834210395813 s, accu: 0.8634098172187805, loss_yt: 0.3410690724849701\n",
      "epocht 16, batch_num 2200, step 597401, time: 83.95553803443909 s, accu: 0.8634091019630432, loss_yt: 0.47786858677864075\n",
      "epocht 16, batch_num 2400, step 597601, time: 91.69483828544617 s, accu: 0.8634090423583984, loss_yt: 0.25673213601112366\n",
      "epocht 16, batch_num 2600, step 597801, time: 99.34538292884827 s, accu: 0.8634082674980164, loss_yt: 0.1473320871591568\n",
      "epocht 16, batch_num 2800, step 598001, time: 106.87421607971191 s, accu: 0.8634078502655029, loss_yt: 0.3367357850074768\n",
      "epocht 16, batch_num 3000, step 598201, time: 114.23154163360596 s, accu: 0.8634088039398193, loss_yt: 0.28281664848327637\n",
      "epocht 16, batch_num 3200, step 598401, time: 121.85618138313293 s, accu: 0.8634105324745178, loss_yt: 0.3368144929409027\n",
      "epocht 16, batch_num 3400, step 598601, time: 129.306232213974 s, accu: 0.8634103536605835, loss_yt: 0.23551560938358307\n",
      "epocht 16, batch_num 3600, step 598801, time: 137.31980419158936 s, accu: 0.863412082195282, loss_yt: 0.44974952936172485\n",
      "epocht 16, batch_num 3800, step 599001, time: 144.94346570968628 s, accu: 0.8634113073348999, loss_yt: 0.5360698103904724\n",
      "epocht 16, batch_num 4000, step 599201, time: 152.65679216384888 s, accu: 0.8634101152420044, loss_yt: 0.0983169749379158\n",
      "epocht 16, batch_num 4200, step 599401, time: 160.34924864768982 s, accu: 0.8634129762649536, loss_yt: 0.3254649043083191\n",
      "epocht 16, batch_num 4400, step 599601, time: 167.71352982521057 s, accu: 0.863412082195282, loss_yt: 0.261705607175827\n",
      "epocht 16, batch_num 4600, step 599801, time: 175.42291617393494 s, accu: 0.8634111285209656, loss_yt: 0.46241453289985657\n",
      "epocht 16, batch_num 4800, step 600001, time: 182.97771334648132 s, accu: 0.8634103536605835, loss_yt: 0.38833582401275635\n",
      "epocht 16, batch_num 5000, step 600201, time: 190.589359998703 s, accu: 0.8634089231491089, loss_yt: 0.26052162051200867\n",
      "epocht 16, batch_num 5200, step 600401, time: 198.07039189338684 s, accu: 0.8634092807769775, loss_yt: 0.16264671087265015\n",
      "epocht 16, batch_num 5400, step 600601, time: 205.53140544891357 s, accu: 0.8634114265441895, loss_yt: 0.15271568298339844\n",
      "epocht 16, batch_num 5600, step 600801, time: 213.12812185287476 s, accu: 0.8634113073348999, loss_yt: 0.4404810667037964\n",
      "epocht 16, batch_num 5800, step 601001, time: 220.72377920150757 s, accu: 0.863412082195282, loss_yt: 0.22602540254592896\n",
      "epocht 16, batch_num 6000, step 601201, time: 228.44218850135803 s, accu: 0.8634140491485596, loss_yt: 0.3051842451095581\n",
      "epocht 16, batch_num 6200, step 601401, time: 235.96206521987915 s, accu: 0.8634145259857178, loss_yt: 0.23634842038154602\n",
      "epocht 16, batch_num 6400, step 601601, time: 243.7272686958313 s, accu: 0.8634154200553894, loss_yt: 0.22173579037189484\n",
      "epocht 16, batch_num 6600, step 601801, time: 251.2112557888031 s, accu: 0.8634173274040222, loss_yt: 0.24350854754447937\n",
      "epocht 16, batch_num 6800, step 602001, time: 258.8717713356018 s, accu: 0.8634164929389954, loss_yt: 0.41228169202804565\n",
      "epocht 16, batch_num 7000, step 602201, time: 266.8414843082428 s, accu: 0.8634157776832581, loss_yt: 0.3206900656223297\n",
      "epocht 16, batch_num 7200, step 602401, time: 274.6675434112549 s, accu: 0.8634147047996521, loss_yt: 0.42700710892677307\n",
      "epocht 16, batch_num 7400, step 602601, time: 282.57240319252014 s, accu: 0.8634153604507446, loss_yt: 0.3032279312610626\n",
      "iter_validnum 1860\n",
      "epochv 16, step 602640, stop_n 0, time: 336.5370919704437 s, accu_va: 0.8634143493829235, loss_yv: 0.30104025477763785\n",
      "iter_trainnum 7440\n",
      "epocht 16, batch_num 0, step 602641, time: 0.46575427055358887 s, accu: 0.8634148836135864, loss_yt: 0.3012090027332306\n",
      "epocht 16, batch_num 200, step 602841, time: 7.846032381057739 s, accu: 0.8634154796600342, loss_yt: 0.13581505417823792\n",
      "epocht 16, batch_num 400, step 603041, time: 15.51750636100769 s, accu: 0.8634159564971924, loss_yt: 0.25445231795310974\n",
      "epocht 16, batch_num 600, step 603241, time: 22.968581199645996 s, accu: 0.8634171485900879, loss_yt: 0.46016252040863037\n",
      "epocht 16, batch_num 800, step 603441, time: 30.46157169342041 s, accu: 0.8634178638458252, loss_yt: 0.27325567603111267\n",
      "epocht 16, batch_num 1000, step 603641, time: 38.0432710647583 s, accu: 0.8634184002876282, loss_yt: 0.4480611979961395\n",
      "epocht 16, batch_num 1200, step 603841, time: 46.07182288169861 s, accu: 0.8634178638458252, loss_yt: 0.3481071889400482\n",
      "epocht 16, batch_num 1400, step 604041, time: 53.71037769317627 s, accu: 0.8634183406829834, loss_yt: 0.16399447619915009\n",
      "epocht 16, batch_num 1600, step 604241, time: 61.21633338928223 s, accu: 0.8634187579154968, loss_yt: 0.34621623158454895\n",
      "epocht 16, batch_num 1800, step 604441, time: 68.96259307861328 s, accu: 0.8634189367294312, loss_yt: 0.373975932598114\n",
      "epocht 16, batch_num 2000, step 604641, time: 76.54535460472107 s, accu: 0.8634202480316162, loss_yt: 0.10915292799472809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 16, batch_num 2200, step 604841, time: 84.16793394088745 s, accu: 0.8634186387062073, loss_yt: 0.43878480792045593\n",
      "epocht 16, batch_num 2400, step 605041, time: 91.74071741104126 s, accu: 0.8634187579154968, loss_yt: 0.33332115411758423\n",
      "epocht 16, batch_num 2600, step 605241, time: 99.1847791671753 s, accu: 0.8634188175201416, loss_yt: 0.095528744161129\n",
      "epocht 16, batch_num 2800, step 605441, time: 107.0068941116333 s, accu: 0.8634191751480103, loss_yt: 0.19277526438236237\n",
      "epocht 16, batch_num 3000, step 605641, time: 114.63912081718445 s, accu: 0.8634212017059326, loss_yt: 0.24693550169467926\n",
      "epocht 16, batch_num 3200, step 605841, time: 122.37041687965393 s, accu: 0.8634227514266968, loss_yt: 0.257210910320282\n",
      "epocht 16, batch_num 3400, step 606041, time: 130.0618326663971 s, accu: 0.8634229898452759, loss_yt: 0.33757105469703674\n",
      "epocht 16, batch_num 3600, step 606241, time: 137.4999418258667 s, accu: 0.8634231090545654, loss_yt: 0.18440832197666168\n",
      "epocht 16, batch_num 3800, step 606441, time: 145.14848923683167 s, accu: 0.8634219765663147, loss_yt: 0.2862836420536041\n",
      "epocht 16, batch_num 4000, step 606641, time: 152.80501532554626 s, accu: 0.8634228706359863, loss_yt: 0.33254677057266235\n",
      "epocht 16, batch_num 4200, step 606841, time: 160.57823085784912 s, accu: 0.8634229898452759, loss_yt: 0.2433784008026123\n",
      "epocht 16, batch_num 4400, step 607041, time: 168.60077738761902 s, accu: 0.8634231090545654, loss_yt: 0.31534886360168457\n",
      "epocht 16, batch_num 4600, step 607241, time: 176.04490399360657 s, accu: 0.8634239435195923, loss_yt: 0.5051982998847961\n",
      "epocht 16, batch_num 4800, step 607441, time: 183.7532925605774 s, accu: 0.8634253740310669, loss_yt: 0.27563419938087463\n",
      "epocht 16, batch_num 5000, step 607641, time: 191.32303619384766 s, accu: 0.8634247779846191, loss_yt: 0.2343917191028595\n",
      "epocht 16, batch_num 5200, step 607841, time: 198.9506483078003 s, accu: 0.8634258508682251, loss_yt: 0.2137991189956665\n",
      "epocht 16, batch_num 5400, step 608041, time: 206.64505648612976 s, accu: 0.8634254932403564, loss_yt: 0.3628135621547699\n",
      "epocht 16, batch_num 5600, step 608241, time: 214.38135838508606 s, accu: 0.8634247779846191, loss_yt: 0.3509818911552429\n",
      "epocht 16, batch_num 5800, step 608441, time: 222.22139477729797 s, accu: 0.8634236454963684, loss_yt: 0.32403355836868286\n",
      "epocht 16, batch_num 6000, step 608641, time: 229.98463582992554 s, accu: 0.8634238839149475, loss_yt: 0.2430238425731659\n",
      "epocht 16, batch_num 6200, step 608841, time: 237.750901222229 s, accu: 0.8634239435195923, loss_yt: 0.24339084327220917\n",
      "epocht 16, batch_num 6400, step 609041, time: 245.6238510608673 s, accu: 0.8634240627288818, loss_yt: 0.22298043966293335\n",
      "epocht 16, batch_num 6600, step 609241, time: 253.2145562171936 s, accu: 0.8634252548217773, loss_yt: 0.2702855169773102\n",
      "epocht 16, batch_num 6800, step 609441, time: 260.67856097221375 s, accu: 0.8634265065193176, loss_yt: 0.29154878854751587\n",
      "epocht 16, batch_num 7000, step 609641, time: 268.3251132965088 s, accu: 0.8634273409843445, loss_yt: 0.17138391733169556\n",
      "epocht 16, batch_num 7200, step 609841, time: 275.84004974365234 s, accu: 0.86342853307724, loss_yt: 0.31977784633636475\n",
      "epocht 16, batch_num 7400, step 610041, time: 283.6411633491516 s, accu: 0.8634279370307922, loss_yt: 0.12509113550186157\n",
      "iter_validnum 1860\n",
      "epochv 16, step 610080, stop_n 0, time: 337.77443647384644 s, accu_va: 0.8634272753551442, loss_yv: 0.30307629899352145\n",
      "iter_trainnum 7440\n",
      "epocht 16, batch_num 0, step 610081, time: 0.3351552486419678 s, accu: 0.8634271621704102, loss_yt: 0.29753461480140686\n",
      "epocht 16, batch_num 200, step 610281, time: 8.163204431533813 s, accu: 0.8634284734725952, loss_yt: 0.4603140354156494\n",
      "epocht 16, batch_num 400, step 610481, time: 15.624220371246338 s, accu: 0.863429069519043, loss_yt: 0.3118860423564911\n",
      "epocht 16, batch_num 600, step 610681, time: 23.081314086914062 s, accu: 0.8634297251701355, loss_yt: 0.3315604031085968\n",
      "epocht 16, batch_num 800, step 610881, time: 30.731855869293213 s, accu: 0.8634280562400818, loss_yt: 0.2573035955429077\n",
      "epocht 16, batch_num 1000, step 611081, time: 38.18090605735779 s, accu: 0.8634288907051086, loss_yt: 0.1912820041179657\n",
      "epocht 16, batch_num 1200, step 611281, time: 45.79953050613403 s, accu: 0.8634290099143982, loss_yt: 0.34756267070770264\n",
      "epocht 16, batch_num 1400, step 611481, time: 53.26756238937378 s, accu: 0.8634291887283325, loss_yt: 0.2046172022819519\n",
      "epocht 16, batch_num 1600, step 611681, time: 61.19738960266113 s, accu: 0.8634291291236877, loss_yt: 0.319484144449234\n",
      "epocht 16, batch_num 1800, step 611881, time: 68.78108024597168 s, accu: 0.8634303212165833, loss_yt: 0.5731401443481445\n",
      "epocht 16, batch_num 2000, step 612081, time: 76.31496214866638 s, accu: 0.8634296655654907, loss_yt: 0.3311808705329895\n",
      "epocht 16, batch_num 2200, step 612281, time: 83.90563774108887 s, accu: 0.8634294867515564, loss_yt: 0.16349786520004272\n",
      "epocht 16, batch_num 2400, step 612481, time: 91.5232982635498 s, accu: 0.8634282946586609, loss_yt: 0.3418642282485962\n",
      "epocht 16, batch_num 2600, step 612681, time: 99.3593111038208 s, accu: 0.8634259700775146, loss_yt: 0.29364943504333496\n",
      "epocht 16, batch_num 2800, step 612881, time: 107.03578400611877 s, accu: 0.8634259104728699, loss_yt: 0.3430909812450409\n",
      "epocht 16, batch_num 3000, step 613081, time: 114.50783705711365 s, accu: 0.8634248971939087, loss_yt: 0.38120025396347046\n",
      "epocht 16, batch_num 3200, step 613281, time: 122.01074171066284 s, accu: 0.8634260892868042, loss_yt: 0.23139989376068115\n",
      "epocht 16, batch_num 3400, step 613481, time: 129.3910071849823 s, accu: 0.8634286522865295, loss_yt: 0.5336244106292725\n",
      "epocht 16, batch_num 3600, step 613681, time: 137.0675230026245 s, accu: 0.8634272217750549, loss_yt: 0.29561489820480347\n",
      "epocht 16, batch_num 3800, step 613881, time: 144.64524865150452 s, accu: 0.8634271025657654, loss_yt: 0.3941832482814789\n",
      "epocht 16, batch_num 4000, step 614081, time: 152.36956214904785 s, accu: 0.8634277582168579, loss_yt: 0.2903149724006653\n",
      "epocht 16, batch_num 4200, step 614281, time: 160.22359204292297 s, accu: 0.8634287714958191, loss_yt: 0.294455349445343\n",
      "epocht 16, batch_num 4400, step 614481, time: 167.62778759002686 s, accu: 0.8634296655654907, loss_yt: 0.34335121512413025\n",
      "epocht 16, batch_num 4600, step 614681, time: 175.04692888259888 s, accu: 0.8634294271469116, loss_yt: 0.41025254130363464\n",
      "epocht 16, batch_num 4800, step 614881, time: 182.53390216827393 s, accu: 0.8634321689605713, loss_yt: 0.29996076226234436\n",
      "epocht 16, batch_num 5000, step 615081, time: 190.10370707511902 s, accu: 0.8634326457977295, loss_yt: 0.3546188771724701\n",
      "epocht 16, batch_num 5200, step 615281, time: 197.62654328346252 s, accu: 0.863431990146637, loss_yt: 0.1460319310426712\n",
      "epocht 16, batch_num 5400, step 615481, time: 205.6441295146942 s, accu: 0.8634315729141235, loss_yt: 0.28309276700019836\n",
      "epocht 16, batch_num 5600, step 615681, time: 213.2816824913025 s, accu: 0.8634330630302429, loss_yt: 0.51346755027771\n",
      "epocht 16, batch_num 5800, step 615881, time: 220.91030144691467 s, accu: 0.8634332418441772, loss_yt: 0.2908538579940796\n",
      "epocht 16, batch_num 6000, step 616081, time: 228.62565088272095 s, accu: 0.8634341359138489, loss_yt: 0.20438244938850403\n",
      "epocht 16, batch_num 6200, step 616281, time: 236.1595482826233 s, accu: 0.8634355068206787, loss_yt: 0.27468279004096985\n",
      "epocht 16, batch_num 6400, step 616481, time: 244.24591207504272 s, accu: 0.8634340167045593, loss_yt: 0.26755860447883606\n",
      "epocht 16, batch_num 6600, step 616681, time: 251.95327234268188 s, accu: 0.8634352684020996, loss_yt: 0.31961190700531006\n",
      "epocht 16, batch_num 6800, step 616881, time: 259.53100848197937 s, accu: 0.8634343147277832, loss_yt: 0.4000145196914673\n",
      "epocht 16, batch_num 7000, step 617081, time: 267.31619238853455 s, accu: 0.8634341955184937, loss_yt: 0.15317587554454803\n",
      "epocht 16, batch_num 7200, step 617281, time: 275.2031033039093 s, accu: 0.863433301448822, loss_yt: 0.2635556161403656\n",
      "epocht 16, batch_num 7400, step 617481, time: 282.78981852531433 s, accu: 0.8634343147277832, loss_yt: 0.24013613164424896\n",
      "iter_validnum 1860\n",
      "epochv 16, step 617520, stop_n 0, time: 336.58795976638794 s, accu_va: 0.8634382346304514, loss_yv: 0.2982555728085259\n",
      "iter_trainnum 7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 16, batch_num 0, step 617521, time: 0.3560473918914795 s, accu: 0.8634392619132996, loss_yt: 0.24792525172233582\n",
      "epocht 16, batch_num 200, step 617721, time: 7.977667570114136 s, accu: 0.8634390830993652, loss_yt: 0.1636296659708023\n",
      "epocht 16, batch_num 400, step 617921, time: 15.630207061767578 s, accu: 0.8634389638900757, loss_yt: 0.19454124569892883\n",
      "epocht 16, batch_num 600, step 618121, time: 23.32363224029541 s, accu: 0.8634404540061951, loss_yt: 0.17383833229541779\n",
      "epocht 16, batch_num 800, step 618321, time: 30.990159034729004 s, accu: 0.8634400367736816, loss_yt: 0.25247275829315186\n",
      "epocht 16, batch_num 1000, step 618521, time: 38.69353246688843 s, accu: 0.8634402751922607, loss_yt: 0.34523805975914\n",
      "epocht 16, batch_num 1200, step 618721, time: 46.31918025016785 s, accu: 0.8634399175643921, loss_yt: 0.34946149587631226\n",
      "epocht 16, batch_num 1400, step 618921, time: 54.03650450706482 s, accu: 0.8634403944015503, loss_yt: 0.3834991753101349\n",
      "epocht 16, batch_num 1600, step 619121, time: 61.688077449798584 s, accu: 0.8634401559829712, loss_yt: 0.3289605677127838\n",
      "epocht 16, batch_num 1800, step 619321, time: 69.49217653274536 s, accu: 0.8634411692619324, loss_yt: 0.12563234567642212\n",
      "epocht 16, batch_num 2000, step 619521, time: 77.1656904220581 s, accu: 0.8634404540061951, loss_yt: 0.36756595969200134\n",
      "epocht 16, batch_num 2200, step 619721, time: 84.59778308868408 s, accu: 0.8634433746337891, loss_yt: 0.4744022786617279\n",
      "epocht 16, batch_num 2400, step 619921, time: 92.43785238265991 s, accu: 0.8634430170059204, loss_yt: 0.3708861172199249\n",
      "epocht 16, batch_num 2600, step 620121, time: 99.97370314598083 s, accu: 0.8634424805641174, loss_yt: 0.21256212890148163\n",
      "epocht 16, batch_num 2800, step 620321, time: 107.66310667991638 s, accu: 0.8634416460990906, loss_yt: 0.217312753200531\n",
      "epocht 16, batch_num 3000, step 620521, time: 115.28771734237671 s, accu: 0.8634432554244995, loss_yt: 0.34270715713500977\n",
      "epocht 16, batch_num 3200, step 620721, time: 122.70292234420776 s, accu: 0.8634442090988159, loss_yt: 0.2615979313850403\n",
      "epocht 16, batch_num 3400, step 620921, time: 130.2656660079956 s, accu: 0.8634443879127502, loss_yt: 0.31241708993911743\n",
      "epocht 16, batch_num 3600, step 621121, time: 137.87132859230042 s, accu: 0.8634434938430786, loss_yt: 0.2599574029445648\n",
      "epocht 16, batch_num 3800, step 621321, time: 145.81309485435486 s, accu: 0.8634439706802368, loss_yt: 0.2748165428638458\n",
      "epocht 16, batch_num 4000, step 621521, time: 153.291095495224 s, accu: 0.8634440898895264, loss_yt: 0.5326877236366272\n",
      "epocht 16, batch_num 4200, step 621721, time: 160.9167377948761 s, accu: 0.8634439706802368, loss_yt: 0.43515586853027344\n",
      "epocht 16, batch_num 4400, step 621921, time: 168.64308857917786 s, accu: 0.8634451627731323, loss_yt: 0.5175794959068298\n",
      "epocht 16, batch_num 4600, step 622121, time: 176.20083951950073 s, accu: 0.8634449243545532, loss_yt: 0.4719075560569763\n",
      "epocht 16, batch_num 4800, step 622321, time: 183.9052586555481 s, accu: 0.8634440898895264, loss_yt: 0.33783644437789917\n",
      "epocht 16, batch_num 5000, step 622521, time: 191.4231312274933 s, accu: 0.8634448647499084, loss_yt: 0.12355096638202667\n",
      "epocht 16, batch_num 5200, step 622721, time: 199.15149235725403 s, accu: 0.8634452223777771, loss_yt: 0.2038651555776596\n",
      "epocht 16, batch_num 5400, step 622921, time: 206.79602217674255 s, accu: 0.8634447455406189, loss_yt: 0.24045199155807495\n",
      "epocht 16, batch_num 5600, step 623121, time: 214.66700839996338 s, accu: 0.8634428977966309, loss_yt: 0.39047080278396606\n",
      "epocht 16, batch_num 5800, step 623321, time: 222.4082772731781 s, accu: 0.8634432554244995, loss_yt: 0.3165181279182434\n",
      "epocht 16, batch_num 6000, step 623521, time: 230.16453909873962 s, accu: 0.8634427785873413, loss_yt: 0.1893254816532135\n",
      "epocht 16, batch_num 6200, step 623721, time: 237.608628988266 s, accu: 0.8634440898895264, loss_yt: 0.25295618176460266\n",
      "epocht 16, batch_num 6400, step 623921, time: 245.35893726348877 s, accu: 0.8634423613548279, loss_yt: 0.40085071325302124\n",
      "epocht 16, batch_num 6600, step 624121, time: 253.0882363319397 s, accu: 0.8634429574012756, loss_yt: 0.5346375107765198\n",
      "epocht 16, batch_num 6800, step 624321, time: 260.7368154525757 s, accu: 0.8634448051452637, loss_yt: 0.21016138792037964\n",
      "epocht 16, batch_num 7000, step 624521, time: 268.5160093307495 s, accu: 0.863445520401001, loss_yt: 0.30708929896354675\n",
      "epocht 16, batch_num 7200, step 624721, time: 276.2423231601715 s, accu: 0.8634456396102905, loss_yt: 0.3155331313610077\n",
      "epocht 16, batch_num 7400, step 624921, time: 283.7761754989624 s, accu: 0.8634467124938965, loss_yt: 0.11771238595247269\n",
      "iter_validnum 1860\n",
      "epochv 16, step 624960, stop_n 1, time: 337.5075013637543 s, accu_va: 0.8634488003869211, loss_yv: 0.2974238193283478\n",
      "iter_trainnum 7440\n",
      "epocht 16, batch_num 0, step 624961, time: 0.33607983589172363 s, accu: 0.8634519577026367, loss_yt: 0.30988478660583496\n",
      "epocht 16, batch_num 200, step 625161, time: 8.206038475036621 s, accu: 0.8634515404701233, loss_yt: 0.2551197409629822\n",
      "epocht 16, batch_num 400, step 625361, time: 15.900455713272095 s, accu: 0.8634529709815979, loss_yt: 0.29624006152153015\n",
      "epocht 16, batch_num 600, step 625561, time: 23.56795024871826 s, accu: 0.8634522557258606, loss_yt: 0.2569315731525421\n",
      "epocht 16, batch_num 800, step 625761, time: 31.29632019996643 s, accu: 0.863453209400177, loss_yt: 0.1574697196483612\n",
      "epocht 16, batch_num 1000, step 625961, time: 38.840112924575806 s, accu: 0.8634535670280457, loss_yt: 0.18015411496162415\n",
      "epocht 16, batch_num 1200, step 626161, time: 46.311134338378906 s, accu: 0.8634545803070068, loss_yt: 0.1399499624967575\n",
      "epocht 16, batch_num 1400, step 626361, time: 53.856974840164185 s, accu: 0.8634535670280457, loss_yt: 0.2852468192577362\n",
      "epocht 16, batch_num 1600, step 626561, time: 61.615214586257935 s, accu: 0.8634551763534546, loss_yt: 0.30245471000671387\n",
      "epocht 16, batch_num 1800, step 626761, time: 69.26176428794861 s, accu: 0.8634547591209412, loss_yt: 0.3024923801422119\n",
      "epocht 16, batch_num 2000, step 626961, time: 76.87444567680359 s, accu: 0.8634547591209412, loss_yt: 0.38785338401794434\n",
      "epocht 16, batch_num 2200, step 627161, time: 84.51199245452881 s, accu: 0.8634556531906128, loss_yt: 0.2726764380931854\n",
      "epocht 16, batch_num 2400, step 627361, time: 92.12465524673462 s, accu: 0.8634563088417053, loss_yt: 0.314775288105011\n",
      "epocht 16, batch_num 2600, step 627561, time: 99.5507709980011 s, accu: 0.863457202911377, loss_yt: 0.16340021789073944\n",
      "epocht 16, batch_num 2800, step 627761, time: 107.00384163856506 s, accu: 0.863457202911377, loss_yt: 0.37212687730789185\n",
      "epocht 16, batch_num 3000, step 627961, time: 114.64443635940552 s, accu: 0.8634565472602844, loss_yt: 0.32060059905052185\n",
      "epocht 16, batch_num 3200, step 628161, time: 122.25705480575562 s, accu: 0.8634576201438904, loss_yt: 0.28153106570243835\n",
      "epocht 16, batch_num 3400, step 628361, time: 130.00433683395386 s, accu: 0.8634576797485352, loss_yt: 0.30604836344718933\n",
      "epocht 16, batch_num 3600, step 628561, time: 137.73070454597473 s, accu: 0.8634570837020874, loss_yt: 0.34536293148994446\n",
      "epocht 16, batch_num 3800, step 628761, time: 145.13288259506226 s, accu: 0.8634567260742188, loss_yt: 0.21655718982219696\n",
      "epocht 16, batch_num 4000, step 628961, time: 152.70267415046692 s, accu: 0.8634567260742188, loss_yt: 0.2885317802429199\n",
      "epocht 16, batch_num 4200, step 629161, time: 160.18662881851196 s, accu: 0.8634562492370605, loss_yt: 0.32363083958625793\n",
      "epocht 16, batch_num 4400, step 629361, time: 168.1613414287567 s, accu: 0.8634557723999023, loss_yt: 0.31903424859046936\n",
      "epocht 16, batch_num 4600, step 629561, time: 175.74303770065308 s, accu: 0.8634555339813232, loss_yt: 0.2707327604293823\n",
      "epocht 16, batch_num 4800, step 629761, time: 183.42252659797668 s, accu: 0.8634551167488098, loss_yt: 0.21246013045310974\n",
      "epocht 16, batch_num 5000, step 629961, time: 191.20568323135376 s, accu: 0.8634549975395203, loss_yt: 0.20172269642353058\n",
      "epocht 16, batch_num 5200, step 630161, time: 198.752503156662 s, accu: 0.863456666469574, loss_yt: 0.2639475464820862\n",
      "epocht 16, batch_num 5400, step 630361, time: 206.32026839256287 s, accu: 0.8634576201438904, loss_yt: 0.22633270919322968\n",
      "epocht 16, batch_num 5600, step 630561, time: 213.696542263031 s, accu: 0.8634583950042725, loss_yt: 0.24609892070293427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 16, batch_num 5800, step 630761, time: 221.4657928943634 s, accu: 0.8634595274925232, loss_yt: 0.3557818531990051\n",
      "epocht 16, batch_num 6000, step 630961, time: 229.3606562614441 s, accu: 0.8634583950042725, loss_yt: 0.2266581654548645\n",
      "epocht 16, batch_num 6200, step 631161, time: 237.1508605480194 s, accu: 0.8634599447250366, loss_yt: 0.35280323028564453\n",
      "epocht 16, batch_num 6400, step 631361, time: 244.934020280838 s, accu: 0.8634598255157471, loss_yt: 0.5434961915016174\n",
      "epocht 16, batch_num 6600, step 631561, time: 253.07926511764526 s, accu: 0.8634596467018127, loss_yt: 0.40093138813972473\n",
      "epocht 16, batch_num 6800, step 631761, time: 260.7158453464508 s, accu: 0.86346036195755, loss_yt: 0.33896347880363464\n",
      "epocht 16, batch_num 7000, step 631961, time: 268.1120412349701 s, accu: 0.8634612560272217, loss_yt: 0.21286462247371674\n",
      "epocht 16, batch_num 7200, step 632161, time: 275.9112117290497 s, accu: 0.8634611368179321, loss_yt: 0.3635147511959076\n",
      "epocht 16, batch_num 7400, step 632361, time: 283.71532011032104 s, accu: 0.8634607791900635, loss_yt: 0.3790380358695984\n",
      "iter_validnum 1860\n",
      "epochv 16, step 632400, stop_n 0, time: 337.50351071357727 s, accu_va: 0.8634626561916002, loss_yv: 0.2988987530110985\n",
      "iter_trainnum 7440\n",
      "epocht 17, batch_num 0, step 632401, time: 0.5116403102874756 s, accu: 0.8634644150733948, loss_yt: 0.30970802903175354\n",
      "epocht 17, batch_num 200, step 632601, time: 8.129295110702515 s, accu: 0.8634653091430664, loss_yt: 0.15432296693325043\n",
      "epocht 17, batch_num 400, step 632801, time: 15.871559143066406 s, accu: 0.8634647727012634, loss_yt: 0.2844693660736084\n",
      "epocht 17, batch_num 600, step 633001, time: 23.399428606033325 s, accu: 0.863464891910553, loss_yt: 0.3216628134250641\n",
      "epocht 17, batch_num 800, step 633201, time: 31.03102445602417 s, accu: 0.8634673953056335, loss_yt: 0.3112014830112457\n",
      "epocht 17, batch_num 1000, step 633401, time: 38.59782147407532 s, accu: 0.8634666800498962, loss_yt: 0.27374738454818726\n",
      "epocht 17, batch_num 1200, step 633601, time: 46.289222240448 s, accu: 0.8634671568870544, loss_yt: 0.29557353258132935\n",
      "epocht 17, batch_num 1400, step 633801, time: 53.98268151283264 s, accu: 0.8634681105613708, loss_yt: 0.20013222098350525\n",
      "epocht 17, batch_num 1600, step 634001, time: 61.7519428730011 s, accu: 0.8634678721427917, loss_yt: 0.29480627179145813\n",
      "epocht 17, batch_num 1800, step 634201, time: 69.36556720733643 s, accu: 0.8634687662124634, loss_yt: 0.36985066533088684\n",
      "epocht 17, batch_num 2000, step 634401, time: 77.03402781486511 s, accu: 0.8634697794914246, loss_yt: 0.3097420930862427\n",
      "epocht 17, batch_num 2200, step 634601, time: 84.53599405288696 s, accu: 0.8634706139564514, loss_yt: 0.3289482891559601\n",
      "epocht 17, batch_num 2400, step 634801, time: 91.97511959075928 s, accu: 0.8634700179100037, loss_yt: 0.3335031270980835\n",
      "epocht 17, batch_num 2600, step 635001, time: 99.81015253067017 s, accu: 0.8634686470031738, loss_yt: 0.2220350205898285\n",
      "epocht 17, batch_num 2800, step 635201, time: 107.61525750160217 s, accu: 0.8634698390960693, loss_yt: 0.4481062591075897\n",
      "epocht 17, batch_num 3000, step 635401, time: 115.53610634803772 s, accu: 0.8634710907936096, loss_yt: 0.29832059144973755\n",
      "epocht 17, batch_num 3200, step 635601, time: 123.29336881637573 s, accu: 0.8634708523750305, loss_yt: 0.26412972807884216\n",
      "epocht 17, batch_num 3400, step 635801, time: 130.95487570762634 s, accu: 0.8634719848632812, loss_yt: 0.362481027841568\n",
      "epocht 17, batch_num 3600, step 636001, time: 139.04720520973206 s, accu: 0.863471269607544, loss_yt: 0.2589166760444641\n",
      "epocht 17, batch_num 3800, step 636201, time: 147.02786779403687 s, accu: 0.8634714484214783, loss_yt: 0.3526464104652405\n",
      "epocht 17, batch_num 4000, step 636401, time: 155.33369064331055 s, accu: 0.8634730577468872, loss_yt: 0.35529589653015137\n",
      "epocht 17, batch_num 4200, step 636601, time: 163.17967438697815 s, accu: 0.8634738326072693, loss_yt: 0.29252663254737854\n",
      "epocht 17, batch_num 4400, step 636801, time: 171.03068089485168 s, accu: 0.8634735345840454, loss_yt: 0.2681027352809906\n",
      "epocht 17, batch_num 4600, step 637001, time: 179.04225826263428 s, accu: 0.8634733557701111, loss_yt: 0.23884382843971252\n",
      "epocht 17, batch_num 4800, step 637201, time: 186.99898052215576 s, accu: 0.8634729385375977, loss_yt: 0.23655052483081818\n",
      "epocht 17, batch_num 5000, step 637401, time: 194.74526834487915 s, accu: 0.8634732961654663, loss_yt: 0.3239603340625763\n",
      "epocht 17, batch_num 5200, step 637601, time: 202.24723863601685 s, accu: 0.8634747266769409, loss_yt: 0.3823727071285248\n",
      "epocht 17, batch_num 5400, step 637801, time: 209.928692817688 s, accu: 0.8634747862815857, loss_yt: 0.18065427243709564\n",
      "epocht 17, batch_num 5600, step 638001, time: 217.71783804893494 s, accu: 0.8634752631187439, loss_yt: 0.16126583516597748\n",
      "epocht 17, batch_num 5800, step 638201, time: 225.27861833572388 s, accu: 0.8634762167930603, loss_yt: 0.24271160364151\n",
      "epocht 17, batch_num 6000, step 638401, time: 232.9042558670044 s, accu: 0.8634747862815857, loss_yt: 0.27767154574394226\n",
      "epocht 17, batch_num 6200, step 638601, time: 240.61760210990906 s, accu: 0.8634751439094543, loss_yt: 0.20097286999225616\n",
      "epocht 17, batch_num 6400, step 638801, time: 248.30807089805603 s, accu: 0.8634745478630066, loss_yt: 0.3447805345058441\n",
      "epocht 17, batch_num 6600, step 639001, time: 256.29966950416565 s, accu: 0.8634763956069946, loss_yt: 0.3264353573322296\n",
      "epocht 17, batch_num 6800, step 639201, time: 264.04894757270813 s, accu: 0.8634755611419678, loss_yt: 0.2028968185186386\n",
      "epocht 17, batch_num 7000, step 639401, time: 271.85108280181885 s, accu: 0.8634744882583618, loss_yt: 0.2622624635696411\n",
      "epocht 17, batch_num 7200, step 639601, time: 279.5076422691345 s, accu: 0.86347496509552, loss_yt: 0.48987218737602234\n",
      "epocht 17, batch_num 7400, step 639801, time: 287.0664293766022 s, accu: 0.8634747862815857, loss_yt: 0.48891571164131165\n",
      "iter_validnum 1860\n",
      "epochv 17, step 639840, stop_n 0, time: 341.0789682865143 s, accu_va: 0.86347631424345, loss_yv: 0.3009493463422342\n",
      "iter_trainnum 7440\n",
      "epocht 17, batch_num 0, step 639841, time: 0.4468402862548828 s, accu: 0.8634752035140991, loss_yt: 0.4934625029563904\n",
      "epocht 17, batch_num 200, step 640041, time: 8.204061269760132 s, accu: 0.8634752035140991, loss_yt: 0.28827840089797974\n",
      "epocht 17, batch_num 400, step 640241, time: 15.943370819091797 s, accu: 0.8634754419326782, loss_yt: 0.7097304463386536\n",
      "epocht 17, batch_num 600, step 640441, time: 23.746501445770264 s, accu: 0.8634748458862305, loss_yt: 0.5973844528198242\n",
      "epocht 17, batch_num 800, step 640641, time: 31.1696515083313 s, accu: 0.8634746074676514, loss_yt: 0.4214293360710144\n",
      "epocht 17, batch_num 1000, step 640841, time: 38.762351274490356 s, accu: 0.8634754419326782, loss_yt: 0.31441453099250793\n",
      "epocht 17, batch_num 1200, step 641041, time: 46.38496661186218 s, accu: 0.8634752631187439, loss_yt: 0.2188107967376709\n",
      "epocht 17, batch_num 1400, step 641241, time: 54.39956736564636 s, accu: 0.8634748458862305, loss_yt: 0.28462669253349304\n",
      "epocht 17, batch_num 1600, step 641441, time: 61.91942644119263 s, accu: 0.8634762763977051, loss_yt: 0.2579724192619324\n",
      "epocht 17, batch_num 1800, step 641641, time: 69.69363713264465 s, accu: 0.86347895860672, loss_yt: 0.3767854869365692\n",
      "epocht 17, batch_num 2000, step 641841, time: 77.49679780006409 s, accu: 0.8634783029556274, loss_yt: 0.27266809344291687\n",
      "epocht 17, batch_num 2200, step 642041, time: 84.82520818710327 s, accu: 0.8634793758392334, loss_yt: 0.17997856438159943\n",
      "epocht 17, batch_num 2400, step 642241, time: 92.38894963264465 s, accu: 0.8634806871414185, loss_yt: 0.30693572759628296\n",
      "epocht 17, batch_num 2600, step 642441, time: 100.00358772277832 s, accu: 0.8634811043739319, loss_yt: 0.1500590443611145\n",
      "epocht 17, batch_num 2800, step 642641, time: 107.53046011924744 s, accu: 0.8634818196296692, loss_yt: 0.3213382959365845\n",
      "epocht 17, batch_num 3000, step 642841, time: 115.28971457481384 s, accu: 0.8634825944900513, loss_yt: 0.3303180932998657\n",
      "epocht 17, batch_num 3200, step 643041, time: 123.12675642967224 s, accu: 0.8634838461875916, loss_yt: 0.28714510798454285\n",
      "epocht 17, batch_num 3400, step 643241, time: 130.7753038406372 s, accu: 0.8634840846061707, loss_yt: 0.14016060531139374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 17, batch_num 3600, step 643441, time: 138.51962733268738 s, accu: 0.8634845614433289, loss_yt: 0.3469860255718231\n",
      "epocht 17, batch_num 3800, step 643641, time: 146.07141709327698 s, accu: 0.8634840250015259, loss_yt: 0.2702072262763977\n",
      "epocht 17, batch_num 4000, step 643841, time: 153.7319188117981 s, accu: 0.8634823560714722, loss_yt: 0.3034464716911316\n",
      "epocht 17, batch_num 4200, step 644041, time: 161.21395349502563 s, accu: 0.8634828925132751, loss_yt: 0.46499747037887573\n",
      "epocht 17, batch_num 4400, step 644241, time: 168.95421314239502 s, accu: 0.8634838461875916, loss_yt: 0.11841616034507751\n",
      "epocht 17, batch_num 4600, step 644441, time: 176.69152331352234 s, accu: 0.8634849786758423, loss_yt: 0.26865869760513306\n",
      "epocht 17, batch_num 4800, step 644641, time: 184.51061391830444 s, accu: 0.8634840846061707, loss_yt: 0.16832289099693298\n",
      "epocht 17, batch_num 5000, step 644841, time: 191.9667043685913 s, accu: 0.8634838461875916, loss_yt: 0.3561689555644989\n",
      "epocht 17, batch_num 5200, step 645041, time: 199.41575813293457 s, accu: 0.8634842038154602, loss_yt: 0.34979644417762756\n",
      "epocht 17, batch_num 5400, step 645241, time: 206.8379602432251 s, accu: 0.8634850382804871, loss_yt: 0.27857279777526855\n",
      "epocht 17, batch_num 5600, step 645441, time: 214.3607940673828 s, accu: 0.8634860515594482, loss_yt: 0.40327736735343933\n",
      "epocht 17, batch_num 5800, step 645641, time: 222.0722086429596 s, accu: 0.8634869456291199, loss_yt: 0.33442360162734985\n",
      "epocht 17, batch_num 6000, step 645841, time: 230.1166651248932 s, accu: 0.8634859323501587, loss_yt: 0.2869231402873993\n",
      "epocht 17, batch_num 6200, step 646041, time: 237.718337059021 s, accu: 0.86348557472229, loss_yt: 0.3610958456993103\n",
      "epocht 17, batch_num 6400, step 646241, time: 245.20135378837585 s, accu: 0.8634856343269348, loss_yt: 0.12382558733224869\n",
      "epocht 17, batch_num 6600, step 646441, time: 252.90971302986145 s, accu: 0.8634862303733826, loss_yt: 0.19877316057682037\n",
      "epocht 17, batch_num 6800, step 646641, time: 260.5563154220581 s, accu: 0.8634856939315796, loss_yt: 0.3322674334049225\n",
      "epocht 17, batch_num 7000, step 646841, time: 267.8856678009033 s, accu: 0.8634862899780273, loss_yt: 0.4043962061405182\n",
      "epocht 17, batch_num 7200, step 647041, time: 275.695782661438 s, accu: 0.8634874224662781, loss_yt: 0.570554256439209\n",
      "epocht 17, batch_num 7400, step 647241, time: 283.2206618785858 s, accu: 0.8634876608848572, loss_yt: 0.2535320222377777\n",
      "iter_validnum 1860\n",
      "epochv 17, step 647280, stop_n 0, time: 336.9061059951782 s, accu_va: 0.8634878164017072, loss_yv: 0.3028766354846378\n",
      "iter_trainnum 7440\n",
      "epocht 17, batch_num 0, step 647281, time: 0.4298555850982666 s, accu: 0.8634872436523438, loss_yt: 0.12674182653427124\n",
      "epocht 17, batch_num 200, step 647481, time: 8.200105428695679 s, accu: 0.8634867668151855, loss_yt: 0.3169527053833008\n",
      "epocht 17, batch_num 400, step 647681, time: 15.660125255584717 s, accu: 0.8634880185127258, loss_yt: 0.27336347103118896\n",
      "epocht 17, batch_num 600, step 647881, time: 23.413403272628784 s, accu: 0.863488495349884, loss_yt: 0.3250489830970764\n",
      "epocht 17, batch_num 800, step 648081, time: 30.90436053276062 s, accu: 0.8634887337684631, loss_yt: 0.36794131994247437\n",
      "epocht 17, batch_num 1000, step 648281, time: 38.620736837387085 s, accu: 0.8634870648384094, loss_yt: 0.27592673897743225\n",
      "epocht 17, batch_num 1200, step 648481, time: 46.20145583152771 s, accu: 0.8634881973266602, loss_yt: 0.40857994556427\n",
      "epocht 17, batch_num 1400, step 648681, time: 53.47500658035278 s, accu: 0.8634903430938721, loss_yt: 0.2199483960866928\n",
      "epocht 17, batch_num 1600, step 648881, time: 61.21829962730408 s, accu: 0.863490104675293, loss_yt: 0.2885134816169739\n",
      "epocht 17, batch_num 1800, step 649081, time: 68.83991956710815 s, accu: 0.86348956823349, loss_yt: 0.2687307298183441\n",
      "epocht 17, batch_num 2000, step 649281, time: 76.63208746910095 s, accu: 0.8634896278381348, loss_yt: 0.3712792694568634\n",
      "epocht 17, batch_num 2200, step 649481, time: 83.96550679206848 s, accu: 0.8634905815124512, loss_yt: 0.23178699612617493\n",
      "epocht 17, batch_num 2400, step 649681, time: 91.82246398925781 s, accu: 0.8634876608848572, loss_yt: 0.262861043214798\n",
      "epocht 17, batch_num 2600, step 649881, time: 99.54880475997925 s, accu: 0.8634886145591736, loss_yt: 0.3197573721408844\n",
      "epocht 17, batch_num 2800, step 650081, time: 107.16546297073364 s, accu: 0.8634880781173706, loss_yt: 0.3002978563308716\n",
      "epocht 17, batch_num 3000, step 650281, time: 114.86684226989746 s, accu: 0.863487184047699, loss_yt: 0.5525785088539124\n",
      "epocht 17, batch_num 3200, step 650481, time: 122.5024254322052 s, accu: 0.8634867072105408, loss_yt: 0.3406135141849518\n",
      "epocht 17, batch_num 3400, step 650681, time: 130.2267711162567 s, accu: 0.863487184047699, loss_yt: 0.11254512518644333\n",
      "epocht 17, batch_num 3600, step 650881, time: 137.63595843315125 s, accu: 0.8634893894195557, loss_yt: 0.18214450776576996\n",
      "epocht 17, batch_num 3800, step 651081, time: 145.33939480781555 s, accu: 0.8634878396987915, loss_yt: 0.24960434436798096\n",
      "epocht 17, batch_num 4000, step 651281, time: 153.1654326915741 s, accu: 0.863487720489502, loss_yt: 0.10562951117753983\n",
      "epocht 17, batch_num 4200, step 651481, time: 160.94961857795715 s, accu: 0.8634878993034363, loss_yt: 0.3026491701602936\n",
      "epocht 17, batch_num 4400, step 651681, time: 168.51538586616516 s, accu: 0.8634880781173706, loss_yt: 0.3389317989349365\n",
      "epocht 17, batch_num 4600, step 651881, time: 176.04026341438293 s, accu: 0.8634896278381348, loss_yt: 0.22326648235321045\n",
      "epocht 17, batch_num 4800, step 652081, time: 183.64297795295715 s, accu: 0.8634892702102661, loss_yt: 0.3162369728088379\n",
      "epocht 17, batch_num 5000, step 652281, time: 191.2535834312439 s, accu: 0.8634902238845825, loss_yt: 0.2126089483499527\n",
      "epocht 17, batch_num 5200, step 652481, time: 198.93005681037903 s, accu: 0.8634902238845825, loss_yt: 0.3300907611846924\n",
      "epocht 17, batch_num 5400, step 652681, time: 206.5955605506897 s, accu: 0.8634912371635437, loss_yt: 0.12537099421024323\n",
      "epocht 17, batch_num 5600, step 652881, time: 214.16332149505615 s, accu: 0.8634916543960571, loss_yt: 0.15372973680496216\n",
      "epocht 17, batch_num 5800, step 653081, time: 222.07915496826172 s, accu: 0.8634920716285706, loss_yt: 0.5397258996963501\n",
      "epocht 17, batch_num 6000, step 653281, time: 229.72670578956604 s, accu: 0.8634921312332153, loss_yt: 0.30413323640823364\n",
      "epocht 17, batch_num 6200, step 653481, time: 237.45803046226501 s, accu: 0.8634922504425049, loss_yt: 0.30584797263145447\n",
      "epocht 17, batch_num 6400, step 653681, time: 244.9580090045929 s, accu: 0.8634920120239258, loss_yt: 0.27463045716285706\n",
      "epocht 17, batch_num 6600, step 653881, time: 252.5087857246399 s, accu: 0.8634946346282959, loss_yt: 0.3424433171749115\n",
      "epocht 17, batch_num 6800, step 654081, time: 260.0327048301697 s, accu: 0.8634940385818481, loss_yt: 0.3376559317111969\n",
      "epocht 17, batch_num 7000, step 654281, time: 267.85574889183044 s, accu: 0.8634926080703735, loss_yt: 0.23863737285137177\n",
      "epocht 17, batch_num 7200, step 654481, time: 275.6110415458679 s, accu: 0.8634937405586243, loss_yt: 0.3033888638019562\n",
      "epocht 17, batch_num 7400, step 654681, time: 283.19772267341614 s, accu: 0.8634930849075317, loss_yt: 0.34359854459762573\n",
      "iter_validnum 1860\n",
      "epochv 17, step 654720, stop_n 1, time: 337.0856568813324 s, accu_va: 0.8634938393869708, loss_yv: 0.2976528055485218\n",
      "iter_trainnum 7440\n",
      "epocht 17, batch_num 0, step 654721, time: 0.4328422546386719 s, accu: 0.863496720790863, loss_yt: 0.17798647284507751\n",
      "epocht 17, batch_num 200, step 654921, time: 8.424472570419312 s, accu: 0.8634955883026123, loss_yt: 0.3690096437931061\n",
      "epocht 17, batch_num 400, step 655121, time: 16.025147438049316 s, accu: 0.8634957075119019, loss_yt: 0.328546404838562\n",
      "epocht 17, batch_num 600, step 655321, time: 23.595936059951782 s, accu: 0.8634964823722839, loss_yt: 0.34113913774490356\n",
      "epocht 17, batch_num 800, step 655521, time: 31.588531970977783 s, accu: 0.8634951710700989, loss_yt: 0.32556384801864624\n",
      "epocht 17, batch_num 1000, step 655721, time: 39.494420289993286 s, accu: 0.8634932041168213, loss_yt: 0.31103652715682983\n",
      "epocht 17, batch_num 1200, step 655921, time: 47.012288093566895 s, accu: 0.8634918928146362, loss_yt: 0.4432569146156311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 17, batch_num 1400, step 656121, time: 54.571101903915405 s, accu: 0.8634929656982422, loss_yt: 0.2338535487651825\n",
      "epocht 17, batch_num 1600, step 656321, time: 62.50186729431152 s, accu: 0.8634929656982422, loss_yt: 0.35367369651794434\n",
      "epocht 17, batch_num 1800, step 656521, time: 70.14842057228088 s, accu: 0.8634927272796631, loss_yt: 0.35580721497535706\n",
      "epocht 17, batch_num 2000, step 656721, time: 77.70723724365234 s, accu: 0.8634927868843079, loss_yt: 0.2063572108745575\n",
      "epocht 17, batch_num 2200, step 656921, time: 85.18326330184937 s, accu: 0.8634934425354004, loss_yt: 0.22555488348007202\n",
      "epocht 17, batch_num 2400, step 657121, time: 92.98937106132507 s, accu: 0.8634952306747437, loss_yt: 0.25569239258766174\n",
      "epocht 17, batch_num 2600, step 657321, time: 101.26820659637451 s, accu: 0.8634949922561646, loss_yt: 0.3682571351528168\n",
      "epocht 17, batch_num 2800, step 657521, time: 108.72330379486084 s, accu: 0.8634958863258362, loss_yt: 0.3020014762878418\n",
      "epocht 17, batch_num 3000, step 657721, time: 116.39575386047363 s, accu: 0.863494873046875, loss_yt: 0.2730173170566559\n",
      "epocht 17, batch_num 3200, step 657921, time: 123.88672518730164 s, accu: 0.8634967803955078, loss_yt: 0.3414377272129059\n",
      "epocht 17, batch_num 3400, step 658121, time: 131.44251918792725 s, accu: 0.863498330116272, loss_yt: 0.2808792293071747\n",
      "epocht 17, batch_num 3600, step 658321, time: 139.2975137233734 s, accu: 0.8634995222091675, loss_yt: 0.38204076886177063\n",
      "epocht 17, batch_num 3800, step 658521, time: 147.1445324420929 s, accu: 0.863500714302063, loss_yt: 0.46152105927467346\n",
      "epocht 17, batch_num 4000, step 658721, time: 154.89680409431458 s, accu: 0.8635003566741943, loss_yt: 0.26851820945739746\n",
      "epocht 17, batch_num 4200, step 658921, time: 162.39977073669434 s, accu: 0.8635011911392212, loss_yt: 0.4300803542137146\n",
      "epocht 17, batch_num 4400, step 659121, time: 170.05826330184937 s, accu: 0.8635027408599854, loss_yt: 0.28966790437698364\n",
      "epocht 17, batch_num 4600, step 659321, time: 177.7537145614624 s, accu: 0.8635035157203674, loss_yt: 0.3776756227016449\n",
      "epocht 17, batch_num 4800, step 659521, time: 185.39225602149963 s, accu: 0.8635041117668152, loss_yt: 0.19108140468597412\n",
      "epocht 17, batch_num 5000, step 659721, time: 192.9371156692505 s, accu: 0.8635044693946838, loss_yt: 0.3540746867656708\n",
      "epocht 17, batch_num 5200, step 659921, time: 200.73323488235474 s, accu: 0.8635042309761047, loss_yt: 0.40849044919013977\n",
      "epocht 17, batch_num 5400, step 660121, time: 208.34687447547913 s, accu: 0.8635050058364868, loss_yt: 0.5208077430725098\n",
      "epocht 17, batch_num 5600, step 660321, time: 216.27866744995117 s, accu: 0.8635037541389465, loss_yt: 0.28210899233818054\n",
      "epocht 17, batch_num 5800, step 660521, time: 223.77262663841248 s, accu: 0.8635050058364868, loss_yt: 0.31089285016059875\n",
      "epocht 17, batch_num 6000, step 660721, time: 231.43015575408936 s, accu: 0.8635052442550659, loss_yt: 0.5258551836013794\n",
      "epocht 17, batch_num 6200, step 660921, time: 238.93212723731995 s, accu: 0.8635045289993286, loss_yt: 0.23794753849506378\n",
      "epocht 17, batch_num 6400, step 661121, time: 246.51481413841248 s, accu: 0.8635045886039734, loss_yt: 0.23722845315933228\n",
      "epocht 17, batch_num 6600, step 661321, time: 254.19730520248413 s, accu: 0.8635045289993286, loss_yt: 0.46287915110588074\n",
      "epocht 17, batch_num 6800, step 661521, time: 262.131055355072 s, accu: 0.8635038733482361, loss_yt: 0.29893749952316284\n",
      "epocht 17, batch_num 7000, step 661721, time: 269.9591226577759 s, accu: 0.8635024428367615, loss_yt: 0.3028883635997772\n",
      "epocht 17, batch_num 7200, step 661921, time: 277.56179308891296 s, accu: 0.8635035753250122, loss_yt: 0.36988627910614014\n",
      "epocht 17, batch_num 7400, step 662121, time: 285.3070819377899 s, accu: 0.8635028004646301, loss_yt: 0.5154569149017334\n",
      "iter_validnum 1860\n",
      "epochv 17, step 662160, stop_n 0, time: 338.97756576538086 s, accu_va: 0.8635061791507147, loss_yv: 0.29797998034265094\n",
      "iter_trainnum 7440\n",
      "epocht 17, batch_num 0, step 662161, time: 0.3381037712097168 s, accu: 0.8635075092315674, loss_yt: 0.2929806709289551\n",
      "epocht 17, batch_num 200, step 662361, time: 8.026537656784058 s, accu: 0.8635070323944092, loss_yt: 0.27039945125579834\n",
      "epocht 17, batch_num 400, step 662561, time: 15.822683095932007 s, accu: 0.8635081648826599, loss_yt: 0.47143441438674927\n",
      "epocht 17, batch_num 600, step 662761, time: 23.33758783340454 s, accu: 0.8635081052780151, loss_yt: 0.2210184931755066\n",
      "epocht 17, batch_num 800, step 662961, time: 30.80063509941101 s, accu: 0.8635082244873047, loss_yt: 0.29235056042671204\n",
      "epocht 17, batch_num 1000, step 663161, time: 38.36445236206055 s, accu: 0.8635095953941345, loss_yt: 0.348082959651947\n",
      "epocht 17, batch_num 1200, step 663361, time: 45.71180772781372 s, accu: 0.8635104298591614, loss_yt: 0.2969410717487335\n",
      "epocht 17, batch_num 1400, step 663561, time: 53.14588022232056 s, accu: 0.8635123372077942, loss_yt: 0.3492904603481293\n",
      "epocht 17, batch_num 1600, step 663761, time: 60.9420325756073 s, accu: 0.8635109066963196, loss_yt: 0.39853158593177795\n",
      "epocht 17, batch_num 1800, step 663961, time: 68.82694792747498 s, accu: 0.8635118007659912, loss_yt: 0.3389381766319275\n",
      "epocht 17, batch_num 2000, step 664161, time: 76.3179178237915 s, accu: 0.8635116815567017, loss_yt: 0.25585830211639404\n",
      "epocht 17, batch_num 2200, step 664361, time: 83.92258214950562 s, accu: 0.8635113835334778, loss_yt: 0.321001261472702\n",
      "epocht 17, batch_num 2400, step 664561, time: 91.44945573806763 s, accu: 0.8635112047195435, loss_yt: 0.24537979066371918\n",
      "epocht 17, batch_num 2600, step 664761, time: 99.10398697853088 s, accu: 0.8635109663009644, loss_yt: 0.20796450972557068\n",
      "epocht 17, batch_num 2800, step 664961, time: 106.82334685325623 s, accu: 0.8635103702545166, loss_yt: 0.30155429244041443\n",
      "epocht 17, batch_num 3000, step 665161, time: 114.31032967567444 s, accu: 0.8635106086730957, loss_yt: 0.29717564582824707\n",
      "epocht 17, batch_num 3200, step 665361, time: 121.89604043960571 s, accu: 0.8635121583938599, loss_yt: 0.2565869092941284\n",
      "epocht 17, batch_num 3400, step 665561, time: 129.4309241771698 s, accu: 0.8635134696960449, loss_yt: 0.2345494031906128\n",
      "epocht 17, batch_num 3600, step 665761, time: 137.29486393928528 s, accu: 0.8635145425796509, loss_yt: 0.31886494159698486\n",
      "epocht 17, batch_num 3800, step 665961, time: 144.87762188911438 s, accu: 0.8635155558586121, loss_yt: 0.27253156900405884\n",
      "epocht 17, batch_num 4000, step 666161, time: 152.40246629714966 s, accu: 0.863516092300415, loss_yt: 0.298897385597229\n",
      "epocht 17, batch_num 4200, step 666361, time: 160.1078999042511 s, accu: 0.8635150194168091, loss_yt: 0.35153618454933167\n",
      "epocht 17, batch_num 4400, step 666561, time: 167.53004717826843 s, accu: 0.8635161519050598, loss_yt: 0.30824804306030273\n",
      "epocht 17, batch_num 4600, step 666761, time: 175.09581589698792 s, accu: 0.8635163307189941, loss_yt: 0.2376430183649063\n",
      "epocht 17, batch_num 4800, step 666961, time: 182.79120469093323 s, accu: 0.8635162711143494, loss_yt: 0.31673699617385864\n",
      "epocht 17, batch_num 5000, step 667161, time: 190.34403443336487 s, accu: 0.8635158538818359, loss_yt: 0.2580815255641937\n",
      "epocht 17, batch_num 5200, step 667361, time: 197.99156045913696 s, accu: 0.8635152578353882, loss_yt: 0.24902425706386566\n",
      "epocht 17, batch_num 5400, step 667561, time: 205.7348861694336 s, accu: 0.8635149002075195, loss_yt: 0.3276383876800537\n",
      "epocht 17, batch_num 5600, step 667761, time: 213.15604186058044 s, accu: 0.863513708114624, loss_yt: 0.3010217249393463\n",
      "epocht 17, batch_num 5800, step 667961, time: 220.60509133338928 s, accu: 0.8635151386260986, loss_yt: 0.17650647461414337\n",
      "epocht 17, batch_num 6000, step 668161, time: 227.95546793937683 s, accu: 0.8635159134864807, loss_yt: 0.1658381223678589\n",
      "epocht 17, batch_num 6200, step 668361, time: 235.6080002784729 s, accu: 0.8635162115097046, loss_yt: 0.28065162897109985\n",
      "epocht 17, batch_num 6400, step 668561, time: 243.10093545913696 s, accu: 0.8635175824165344, loss_yt: 0.19321145117282867\n",
      "epocht 17, batch_num 6600, step 668761, time: 250.94695568084717 s, accu: 0.8635154962539673, loss_yt: 0.2761971950531006\n",
      "epocht 17, batch_num 6800, step 668961, time: 258.5865547657013 s, accu: 0.8635141253471375, loss_yt: 0.3707978427410126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 17, batch_num 7000, step 669161, time: 266.3278286457062 s, accu: 0.863513171672821, loss_yt: 0.26531273126602173\n",
      "epocht 17, batch_num 7200, step 669361, time: 273.8716604709625 s, accu: 0.8635141849517822, loss_yt: 0.24102218449115753\n",
      "epocht 17, batch_num 7400, step 669561, time: 281.3287148475647 s, accu: 0.8635151982307434, loss_yt: 0.25855615735054016\n",
      "iter_validnum 1860\n",
      "epochv 17, step 669600, stop_n 0, time: 334.8955078125 s, accu_va: 0.8635157040049953, loss_yv: 0.29839535982057613\n",
      "iter_trainnum 7440\n",
      "epocht 18, batch_num 0, step 669601, time: 0.5904543399810791 s, accu: 0.8635184168815613, loss_yt: 0.4658547043800354\n",
      "epocht 18, batch_num 200, step 669801, time: 8.188105821609497 s, accu: 0.8635191917419434, loss_yt: 0.16841986775398254\n",
      "epocht 18, batch_num 400, step 670001, time: 15.658163070678711 s, accu: 0.863518476486206, loss_yt: 0.24174617230892181\n",
      "epocht 18, batch_num 600, step 670201, time: 23.201958179473877 s, accu: 0.8635186553001404, loss_yt: 0.3553318679332733\n",
      "epocht 18, batch_num 800, step 670401, time: 30.74977469444275 s, accu: 0.8635176420211792, loss_yt: 0.3815779983997345\n",
      "epocht 18, batch_num 1000, step 670601, time: 38.20284581184387 s, accu: 0.8635176420211792, loss_yt: 0.32205674052238464\n",
      "epocht 18, batch_num 1200, step 670801, time: 45.73171401023865 s, accu: 0.8635180592536926, loss_yt: 0.2979319989681244\n",
      "epocht 18, batch_num 1400, step 671001, time: 53.49694800376892 s, accu: 0.8635185956954956, loss_yt: 0.33424219489097595\n",
      "epocht 18, batch_num 1600, step 671201, time: 61.03280448913574 s, accu: 0.863519012928009, loss_yt: 0.30400270223617554\n",
      "epocht 18, batch_num 1800, step 671401, time: 68.72123956680298 s, accu: 0.8635188341140747, loss_yt: 0.27872687578201294\n",
      "epocht 18, batch_num 2000, step 671601, time: 76.19027280807495 s, accu: 0.8635208010673523, loss_yt: 0.3808773159980774\n",
      "epocht 18, batch_num 2200, step 671801, time: 83.80602526664734 s, accu: 0.8635197877883911, loss_yt: 0.17698590457439423\n",
      "epocht 18, batch_num 2400, step 672001, time: 91.28902816772461 s, accu: 0.8635212182998657, loss_yt: 0.1546189785003662\n",
      "epocht 18, batch_num 2600, step 672201, time: 98.7072103023529 s, accu: 0.8635205030441284, loss_yt: 0.281581848859787\n",
      "epocht 18, batch_num 2800, step 672401, time: 106.20512771606445 s, accu: 0.8635215759277344, loss_yt: 0.3538302779197693\n",
      "epocht 18, batch_num 3000, step 672601, time: 113.58243370056152 s, accu: 0.8635234832763672, loss_yt: 0.24418793618679047\n",
      "epocht 18, batch_num 3200, step 672801, time: 121.50524353981018 s, accu: 0.8635224103927612, loss_yt: 0.3519470989704132\n",
      "epocht 18, batch_num 3400, step 673001, time: 129.18970346450806 s, accu: 0.8635229468345642, loss_yt: 0.40180009603500366\n",
      "epocht 18, batch_num 3600, step 673201, time: 136.74549460411072 s, accu: 0.8635228276252747, loss_yt: 0.4117971658706665\n",
      "epocht 18, batch_num 3800, step 673401, time: 144.2603678703308 s, accu: 0.8635226488113403, loss_yt: 0.28840401768684387\n",
      "epocht 18, batch_num 4000, step 673601, time: 151.7603521347046 s, accu: 0.8635233044624329, loss_yt: 0.24383966624736786\n",
      "epocht 18, batch_num 4200, step 673801, time: 159.20141625404358 s, accu: 0.8635250926017761, loss_yt: 0.1322363018989563\n",
      "epocht 18, batch_num 4400, step 674001, time: 166.55480694770813 s, accu: 0.8635273575782776, loss_yt: 0.16480128467082977\n",
      "epocht 18, batch_num 4600, step 674201, time: 174.316997051239 s, accu: 0.8635280132293701, loss_yt: 0.09859269857406616\n",
      "epocht 18, batch_num 4800, step 674401, time: 182.27175188064575 s, accu: 0.863527774810791, loss_yt: 0.15603898465633392\n",
      "epocht 18, batch_num 5000, step 674601, time: 189.87040638923645 s, accu: 0.8635285496711731, loss_yt: 0.21994373202323914\n",
      "epocht 18, batch_num 5200, step 674801, time: 197.40824913978577 s, accu: 0.8635281920433044, loss_yt: 0.5725788474082947\n",
      "epocht 18, batch_num 5400, step 675001, time: 205.0807328224182 s, accu: 0.8635291457176208, loss_yt: 0.27141714096069336\n",
      "epocht 18, batch_num 5600, step 675201, time: 212.57868242263794 s, accu: 0.8635295629501343, loss_yt: 0.2796265482902527\n",
      "epocht 18, batch_num 5800, step 675401, time: 220.0507037639618 s, accu: 0.8635299801826477, loss_yt: 0.3870397210121155\n",
      "epocht 18, batch_num 6000, step 675601, time: 227.71321368217468 s, accu: 0.8635289669036865, loss_yt: 0.29831287264823914\n",
      "epocht 18, batch_num 6200, step 675801, time: 235.62505555152893 s, accu: 0.8635271191596985, loss_yt: 0.265365332365036\n",
      "epocht 18, batch_num 6400, step 676001, time: 243.66954565048218 s, accu: 0.8635259866714478, loss_yt: 0.24887783825397491\n",
      "epocht 18, batch_num 6600, step 676201, time: 251.19146347045898 s, accu: 0.8635274171829224, loss_yt: 0.2609117031097412\n",
      "epocht 18, batch_num 6800, step 676401, time: 258.63156819343567 s, accu: 0.863528311252594, loss_yt: 0.35655462741851807\n",
      "epocht 18, batch_num 7000, step 676601, time: 266.48753094673157 s, accu: 0.8635292649269104, loss_yt: 0.14651577174663544\n",
      "epocht 18, batch_num 7200, step 676801, time: 274.3635015487671 s, accu: 0.8635281920433044, loss_yt: 0.30567970871925354\n",
      "epocht 18, batch_num 7400, step 677001, time: 281.9900748729706 s, accu: 0.8635286092758179, loss_yt: 0.3072274625301361\n",
      "iter_validnum 1860\n",
      "epochv 18, step 677040, stop_n 0, time: 335.77126908302307 s, accu_va: 0.863527746418471, loss_yv: 0.3005942743752272\n",
      "iter_trainnum 7440\n",
      "epocht 18, batch_num 0, step 677041, time: 0.7260518074035645 s, accu: 0.8635286688804626, loss_yt: 0.38235288858413696\n",
      "epocht 18, batch_num 200, step 677241, time: 8.232977867126465 s, accu: 0.8635296821594238, loss_yt: 0.158316507935524\n",
      "epocht 18, batch_num 400, step 677441, time: 15.930397987365723 s, accu: 0.8635299205780029, loss_yt: 0.25377288460731506\n",
      "epocht 18, batch_num 600, step 677641, time: 23.30168652534485 s, accu: 0.8635321855545044, loss_yt: 0.10416456311941147\n",
      "epocht 18, batch_num 800, step 677841, time: 31.00312328338623 s, accu: 0.8635320663452148, loss_yt: 0.2976803779602051\n",
      "epocht 18, batch_num 1000, step 678041, time: 38.502082109451294 s, accu: 0.8635336756706238, loss_yt: 0.1569817215204239\n",
      "epocht 18, batch_num 1200, step 678241, time: 46.118671894073486 s, accu: 0.8635331988334656, loss_yt: 0.4510841369628906\n",
      "epocht 18, batch_num 1400, step 678441, time: 53.79913687705994 s, accu: 0.8635324835777283, loss_yt: 0.27300962805747986\n",
      "epocht 18, batch_num 1600, step 678641, time: 61.34196448326111 s, accu: 0.8635326623916626, loss_yt: 0.3759571313858032\n",
      "epocht 18, batch_num 1800, step 678841, time: 68.86484885215759 s, accu: 0.8635327219963074, loss_yt: 0.3991031050682068\n",
      "epocht 18, batch_num 2000, step 679041, time: 76.31193661689758 s, accu: 0.8635329008102417, loss_yt: 0.2716045379638672\n",
      "epocht 18, batch_num 2200, step 679241, time: 83.88368701934814 s, accu: 0.863532304763794, loss_yt: 0.2602960467338562\n",
      "epocht 18, batch_num 2400, step 679441, time: 91.37269330024719 s, accu: 0.8635326027870178, loss_yt: 0.32840678095817566\n",
      "epocht 18, batch_num 2600, step 679641, time: 98.94840264320374 s, accu: 0.8635323643684387, loss_yt: 0.4265390932559967\n",
      "epocht 18, batch_num 2800, step 679841, time: 106.76250791549683 s, accu: 0.8635308742523193, loss_yt: 0.2927393615245819\n",
      "epocht 18, batch_num 3000, step 680041, time: 114.54373335838318 s, accu: 0.8635303974151611, loss_yt: 0.32612985372543335\n",
      "epocht 18, batch_num 3200, step 680241, time: 122.09654378890991 s, accu: 0.8635297417640686, loss_yt: 0.42084962129592896\n",
      "epocht 18, batch_num 3400, step 680441, time: 129.7510690689087 s, accu: 0.8635305166244507, loss_yt: 0.3551682233810425\n",
      "epocht 18, batch_num 3600, step 680641, time: 137.51129484176636 s, accu: 0.863531768321991, loss_yt: 0.42090776562690735\n",
      "epocht 18, batch_num 3800, step 680841, time: 145.17878413200378 s, accu: 0.8635321259498596, loss_yt: 0.3212054669857025\n",
      "epocht 18, batch_num 4000, step 681041, time: 152.8114082813263 s, accu: 0.8635333180427551, loss_yt: 0.35022956132888794\n",
      "epocht 18, batch_num 4200, step 681241, time: 160.6643726825714 s, accu: 0.8635324239730835, loss_yt: 0.2423398196697235\n",
      "epocht 18, batch_num 4400, step 681441, time: 168.46252179145813 s, accu: 0.8635329604148865, loss_yt: 0.36413466930389404\n",
      "epocht 18, batch_num 4600, step 681641, time: 176.1399917602539 s, accu: 0.8635331988334656, loss_yt: 0.269552618265152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epocht 18, batch_num 4800, step 681841, time: 183.75861811637878 s, accu: 0.8635333180427551, loss_yt: 0.28763097524642944\n",
      "epocht 18, batch_num 5000, step 682041, time: 191.452045917511 s, accu: 0.8635337948799133, loss_yt: 0.3786075711250305\n",
      "epocht 18, batch_num 5200, step 682241, time: 199.05870723724365 s, accu: 0.8635343313217163, loss_yt: 0.2664293348789215\n",
      "epocht 18, batch_num 5400, step 682441, time: 206.71127557754517 s, accu: 0.8635351657867432, loss_yt: 0.37143048644065857\n",
      "epocht 18, batch_num 5600, step 682641, time: 214.24709224700928 s, accu: 0.8635345697402954, loss_yt: 0.319668173789978\n",
      "epocht 18, batch_num 5800, step 682841, time: 222.00235390663147 s, accu: 0.8635349869728088, loss_yt: 0.2879188060760498\n",
      "epocht 18, batch_num 6000, step 683041, time: 229.7187533378601 s, accu: 0.8635357022285461, loss_yt: 0.2536905109882355\n",
      "epocht 18, batch_num 6200, step 683241, time: 237.3303678035736 s, accu: 0.8635374307632446, loss_yt: 0.5349134802818298\n",
      "epocht 18, batch_num 6400, step 683441, time: 244.87921404838562 s, accu: 0.863537609577179, loss_yt: 0.29030025005340576\n",
      "epocht 18, batch_num 6600, step 683641, time: 252.3911428451538 s, accu: 0.8635388612747192, loss_yt: 0.22322307527065277\n",
      "epocht 18, batch_num 6800, step 683841, time: 260.3189506530762 s, accu: 0.8635363578796387, loss_yt: 0.40415605902671814\n",
      "epocht 18, batch_num 7000, step 684041, time: 267.9804973602295 s, accu: 0.8635365962982178, loss_yt: 0.23589695990085602\n",
      "epocht 18, batch_num 7200, step 684241, time: 275.90128469467163 s, accu: 0.8635381460189819, loss_yt: 0.21295179426670074\n",
      "epocht 18, batch_num 7400, step 684441, time: 283.4271924495697 s, accu: 0.8635395169258118, loss_yt: 0.3181125819683075\n",
      "iter_validnum 1860\n",
      "epochv 18, step 684480, stop_n 0, time: 337.29810786247253 s, accu_va: 0.8635392199600896, loss_yv: 0.302908835243634\n",
      "iter_trainnum 7440\n",
      "epocht 18, batch_num 0, step 684481, time: 0.32416534423828125 s, accu: 0.8635385632514954, loss_yt: 0.2943519651889801\n",
      "epocht 18, batch_num 200, step 684681, time: 8.110344886779785 s, accu: 0.8635382056236267, loss_yt: 0.2743339538574219\n",
      "epocht 18, batch_num 400, step 684881, time: 15.559393167495728 s, accu: 0.8635383248329163, loss_yt: 0.6035890579223633\n",
      "epocht 18, batch_num 600, step 685081, time: 23.25182294845581 s, accu: 0.8635377287864685, loss_yt: 0.420085072517395\n",
      "epocht 18, batch_num 800, step 685281, time: 30.831620454788208 s, accu: 0.8635388016700745, loss_yt: 0.22201403975486755\n",
      "epocht 18, batch_num 1000, step 685481, time: 38.51407837867737 s, accu: 0.8635378479957581, loss_yt: 0.24309413135051727\n",
      "epocht 18, batch_num 1200, step 685681, time: 46.00305366516113 s, accu: 0.8635371923446655, loss_yt: 0.3544572591781616\n",
      "epocht 18, batch_num 1400, step 685881, time: 53.666593074798584 s, accu: 0.8635374903678894, loss_yt: 0.31105849146842957\n",
      "epocht 18, batch_num 1600, step 686081, time: 61.445760011672974 s, accu: 0.863538920879364, loss_yt: 0.29311877489089966\n",
      "epocht 18, batch_num 1800, step 686281, time: 69.02249765396118 s, accu: 0.8635398745536804, loss_yt: 0.2346343696117401\n",
      "epocht 18, batch_num 2000, step 686481, time: 76.5443856716156 s, accu: 0.8635398149490356, loss_yt: 0.48098766803741455\n",
      "epocht 18, batch_num 2200, step 686681, time: 84.39442920684814 s, accu: 0.8635388016700745, loss_yt: 0.4580398499965668\n",
      "epocht 18, batch_num 2400, step 686881, time: 91.88238739967346 s, accu: 0.8635385632514954, loss_yt: 0.23774120211601257\n",
      "epocht 18, batch_num 2600, step 687081, time: 99.62769412994385 s, accu: 0.8635389804840088, loss_yt: 0.18971028923988342\n",
      "epocht 18, batch_num 2800, step 687281, time: 107.18445348739624 s, accu: 0.8635390996932983, loss_yt: 0.48777350783348083\n",
      "epocht 18, batch_num 3000, step 687481, time: 115.78874349594116 s, accu: 0.863539457321167, loss_yt: 0.10836236923933029\n",
      "epocht 18, batch_num 3200, step 687681, time: 124.00574254989624 s, accu: 0.863538384437561, loss_yt: 0.31893298029899597\n",
      "epocht 18, batch_num 3400, step 687881, time: 131.86372590065002 s, accu: 0.8635392785072327, loss_yt: 0.4204047918319702\n",
      "epocht 18, batch_num 3600, step 688081, time: 139.84538221359253 s, accu: 0.8635395765304565, loss_yt: 0.253966748714447\n",
      "epocht 18, batch_num 3800, step 688281, time: 147.66749739646912 s, accu: 0.8635398149490356, loss_yt: 0.4086139500141144\n",
      "epocht 18, batch_num 4000, step 688481, time: 155.76082277297974 s, accu: 0.8635388612747192, loss_yt: 0.44162440299987793\n",
      "epocht 18, batch_num 4200, step 688681, time: 163.66568756103516 s, accu: 0.8635388016700745, loss_yt: 0.2643175423145294\n",
      "epocht 18, batch_num 4400, step 688881, time: 172.08720135688782 s, accu: 0.8635374307632446, loss_yt: 0.35436320304870605\n",
      "epocht 18, batch_num 4600, step 689081, time: 179.57816791534424 s, accu: 0.8635375499725342, loss_yt: 0.2873631417751312\n",
      "epocht 18, batch_num 4800, step 689281, time: 187.06611394882202 s, accu: 0.8635382652282715, loss_yt: 0.12413571774959564\n",
      "epocht 18, batch_num 5000, step 689481, time: 194.7874677181244 s, accu: 0.8635377883911133, loss_yt: 0.3142024576663971\n",
      "epocht 18, batch_num 5200, step 689681, time: 202.75817823410034 s, accu: 0.8635368347167969, loss_yt: 0.3197382986545563\n",
      "epocht 18, batch_num 5400, step 689881, time: 210.3279092311859 s, accu: 0.8635386228561401, loss_yt: 0.3425082564353943\n",
      "epocht 18, batch_num 5600, step 690081, time: 218.19687056541443 s, accu: 0.8635374307632446, loss_yt: 0.28632017970085144\n",
      "epocht 18, batch_num 5800, step 690281, time: 226.00599336624146 s, accu: 0.8635383248329163, loss_yt: 0.14655528962612152\n",
      "epocht 18, batch_num 6000, step 690481, time: 233.7871799468994 s, accu: 0.8635387420654297, loss_yt: 0.17138060927391052\n",
      "epocht 18, batch_num 6200, step 690681, time: 241.6102592945099 s, accu: 0.863540530204773, loss_yt: 0.36959826946258545\n",
      "epocht 18, batch_num 6400, step 690881, time: 249.12616276741028 s, accu: 0.8635411858558655, loss_yt: 0.23742565512657166\n",
      "epocht 18, batch_num 6600, step 691081, time: 257.04003381729126 s, accu: 0.8635408282279968, loss_yt: 0.34307342767715454\n",
      "epocht 18, batch_num 6800, step 691281, time: 264.61474680900574 s, accu: 0.8635417819023132, loss_yt: 0.34449878334999084\n",
      "epocht 18, batch_num 7000, step 691481, time: 272.27130460739136 s, accu: 0.863542914390564, loss_yt: 0.24922208487987518\n",
      "epocht 18, batch_num 7200, step 691681, time: 280.14422059059143 s, accu: 0.8635437488555908, loss_yt: 0.3845507800579071\n",
      "epocht 18, batch_num 7400, step 691881, time: 287.7508807182312 s, accu: 0.8635451197624207, loss_yt: 0.27890992164611816\n",
      "iter_validnum 1860\n",
      "epochv 18, step 691920, stop_n 1, time: 345.34788823127747 s, accu_va: 0.8635467581851508, loss_yv: 0.2975748107398069\n",
      "iter_trainnum 7440\n",
      "epocht 18, batch_num 0, step 691921, time: 0.33311009407043457 s, accu: 0.8635486364364624, loss_yt: 0.2244700938463211\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3f1475b1c5dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mglobalstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelcrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainpd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-45454b8a0314>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, trainpd, labels, batch_size, num_epochs, retrain)\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meventindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                             \u001b[1;31m# 获取数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                             \u001b[0mthisindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainpd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainpd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrainevenidlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meventindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m                             \u001b[0mr_inputs_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthisindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                             \u001b[0mr_output_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthisindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3037\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3039\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3040\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "batch_size, num_epochs = 4096, 10000\n",
    "print(trainpd.head())\n",
    "globalstep = modelcrnn.batch_train(trainpd, labels, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "INFO:tensorflow:Restoring parameters from ..\\data\\particles\\model\\modelevery_nomul_modeltail\\v2-20881\n"
     ]
    }
   ],
   "source": [
    "y_pred = modelcrnn.predict(testpd[feature])\n",
    "y_pred = np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6aed27cc546a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestpd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag_pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthre\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"subsample.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    354\u001b[0m         )\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mlibwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#阈值大概在0.2-0.4之间 本题对召回率较敏感，可适当降低一下阈值\n",
    "thre = 0.5\n",
    "#生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['hit_id'] = testpd['hit_id']\n",
    "sub['flag_pred'] = y_pred\n",
    "sub['event_id'] = testpd['event_id']\n",
    "sub['flag_pred'] = sub['flag_pred'].apply(lambda x: 1 if x >= thre else 0)\n",
    "sub.to_csv(os.path.join(pathf, \"subsample.csv\").format(sub['flag_pred'].mean()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}